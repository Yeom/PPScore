Automatic_NNP Extraction_NNP of_IN Titles_NNP from_IN General_NNP Documents_NNS using_VBG Machine_NN Learning_NNP Yunhua_NNP Hu1_NNP Computer_NNP Science_NNP Department_NNP Xi_NN ''_'' an_DT Jiaotong_NNP University_NNP No_NNP ##_NN ,_, Xianning_NNP West_NNP Road_NNP Xi_NN '_'' an_DT ,_, China_NNP ,_, ######_CD yunhuahu_NN @_IN mail_NN ._.
xjtu_NN ._.
edu_NN ._.
cn_NN Hang_NNP Li_NNP ,_, Yunbo_NNP Cao_NNP Microsoft_NNP Research_NNP Asia_NNP 5F_NNP Sigma_NNP Center_NNP ,_, No_NNP ._.
##_NN Zhichun_NNP Road_NNP ,_, Haidian_NNP ,_, Beijing_NNP ,_, China_NNP ,_, ######_CD -LCB-_-LRB- hangli_NN ,_, yucao_NN -RCB-_-RRB- @_SYM microsoft_NN ._.
com_NN Qinghua_NNP Zheng_NNP Computer_NNP Science_NNP Department_NNP Xi_NN ''_'' an_DT Jiaotong_NNP University_NNP No_NNP ##_NN ,_, Xianning_NNP West_NNP Road_NNP Xi_NN '_'' an_DT ,_, China_NNP ,_, ######_CD qhzheng_NN @_IN mail_NN ._.
xjtu_NN ._.
edu_NN ._.
cn_NN Dmitriy_NNP Meyerzon_NNP Microsoft_NNP Corporation_NNP One_CD Microsoft_NNP Way_NNP Redmond_NNP ,_, WA_NNP ,_, USA_NNP ,_, #####_CD dmitriym_NN @_IN microsoft_NN ._.
com_NN ABSTRACT_NN In_IN this_DT paper_NN ,_, we_PRP propose_VBP a_DT machine_NN learning_VBG approach_NN to_TO title_NN extraction_NN from_IN general_JJ documents_NNS ._.
By_IN general_JJ documents_NNS ,_, we_PRP mean_VBP documents_NNS that_WDT can_MD belong_VB to_TO any_DT one_CD of_IN a_DT number_NN of_IN specific_JJ genres_NNS ,_, including_VBG presentations_NNS ,_, book_NN chapters_NNS ,_, technical_JJ papers_NNS ,_, brochures_NNS ,_, reports_NNS ,_, and_CC letters_NNS ._.
Previously_RB ,_, methods_NNS have_VBP been_VBN proposed_VBN mainly_RB for_IN title_NN extraction_NN from_IN research_NN papers_NNS ._.
It_PRP has_VBZ not_RB been_VBN clear_JJ whether_IN it_PRP could_MD be_VB possible_JJ to_TO conduct_VB automatic_JJ title_NN extraction_NN from_IN general_JJ documents_NNS ._.
As_IN a_DT case_NN study_NN ,_, we_PRP consider_VBP extraction_NN from_IN Office_NNP including_VBG Word_NN and_CC PowerPoint_NN ._.
In_IN our_PRP$ approach_NN ,_, we_PRP annotate_VBP titles_NNS in_IN sample_NN documents_NNS -LRB-_-LRB- for_IN Word_NN and_CC PowerPoint_NN respectively_RB -RRB-_-RRB- and_CC take_VB them_PRP as_IN training_NN data_NNS ,_, train_NN machine_NN learning_VBG models_NNS ,_, and_CC perform_VB title_NN extraction_NN using_VBG the_DT trained_JJ models_NNS ._.
Our_PRP$ method_NN is_VBZ unique_JJ in_IN that_IN we_PRP mainly_RB utilize_VBP formatting_VBG information_NN such_JJ as_IN font_NN size_NN as_IN features_NNS in_IN the_DT models_NNS ._.
It_PRP turns_VBZ out_RP that_IN the_DT use_NN of_IN formatting_VBG information_NN can_MD lead_VB to_TO quite_RB accurate_JJ extraction_NN from_IN general_JJ documents_NNS ._.
Precision_NN and_CC recall_NN for_IN title_NN extraction_NN from_IN Word_NN is_VBZ 0_CD ._.
###_NN and_CC #_# ._.
###_NN respectively_RB ,_, and_CC precision_NN and_CC recall_NN for_IN title_NN extraction_NN from_IN PowerPoint_NNP is_VBZ #_# ._.
###_NN and_CC #_# ._.
###_NN respectively_RB in_IN an_DT experiment_NN on_IN intranet_NN data_NNS ._.
Other_JJ important_JJ new_JJ findings_NNS in_IN this_DT work_NN include_VBP that_IN we_PRP can_MD train_VB models_NNS in_IN one_CD domain_NN and_CC apply_VB them_PRP to_TO another_DT domain_NN ,_, and_CC more_RBR surprisingly_RB we_PRP can_MD even_RB train_VB models_NNS in_IN one_CD language_NN and_CC apply_VB them_PRP to_TO another_DT language_NN ._.
Moreover_RB ,_, we_PRP can_MD significantly_RB improve_VB search_NN ranking_JJ results_NNS in_IN document_NN retrieval_NN by_IN using_VBG the_DT extracted_VBN titles_NNS ._.
Categories_NNS and_CC Subject_NNP Descriptors_NNPS H_NN ._.
#_# ._.
#_# -LSB-_-LRB- Information_NNP Storage_NNP and_CC Retrieval_NNP -RSB-_-RRB- :_: Information_NNP Search_VB and_CC Retrieval_NNP -_: Search_VB Process_VB ;_: H_NN ._.
#_# ._.
#_# -LSB-_-LRB- Information_NNP Systems_NNP Applications_NNS -RSB-_-RRB- :_: Office_NNP Automation_NN -_: Word_NN processing_NN ;_: D_NN ._.
#_# ._.
#_# -LSB-_-LRB- Software_NNP Engineering_NNP -RSB-_-RRB- :_: Metrics_NNS -_: complexity_NN measures_NNS ,_, performance_NN measures_NNS General_NNP Terms_NNS Algorithms_NNS ,_, Experimentation_NN ,_, Performance_NNP ._.
1_LS ._.
INTRODUCTION_NN Metadata_NN of_IN documents_NNS is_VBZ useful_JJ for_IN many_JJ kinds_NNS of_IN document_NN processing_NN such_JJ as_IN search_NN ,_, browsing_VBG ,_, and_CC filtering_VBG ._.
Ideally_RB ,_, metadata_NN is_VBZ defined_VBN by_IN the_DT authors_NNS of_IN documents_NNS and_CC is_VBZ then_RB used_VBN by_IN various_JJ systems_NNS ._.
However_RB ,_, people_NNS seldom_RB define_VBP document_NN metadata_NN by_IN themselves_PRP ,_, even_RB when_WRB they_PRP have_VBP convenient_JJ metadata_NN definition_NN tools_NNS -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
Thus_RB ,_, how_WRB to_TO automatically_RB extract_VB metadata_NN from_IN the_DT bodies_NNS of_IN documents_NNS turns_VBZ out_RP to_TO be_VB an_DT important_JJ research_NN issue_NN ._.
Methods_NNS for_IN performing_VBG the_DT task_NN have_VBP been_VBN proposed_VBN ._.
However_RB ,_, the_DT focus_NN was_VBD mainly_RB on_IN extraction_NN from_IN research_NN papers_NNS ._.
For_IN instance_NN ,_, Han_NNP et_FW al_FW ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- proposed_VBD a_DT machine_NN learning_NN based_VBN method_NN to_TO conduct_VB extraction_NN from_IN research_NN papers_NNS ._.
They_PRP formalized_VBD the_DT problem_NN as_IN that_DT of_IN classification_NN and_CC employed_VBN Support_NN Vector_NNP Machines_NNP as_IN the_DT classifier_NN ._.
They_PRP mainly_RB used_VBD linguistic_JJ features_NNS in_IN the_DT model_NN ._.
#_# In_IN this_DT paper_NN ,_, we_PRP consider_VBP metadata_JJ extraction_NN from_IN general_JJ documents_NNS ._.
By_IN general_JJ documents_NNS ,_, we_PRP mean_VBP documents_NNS that_WDT may_MD belong_VB to_TO any_DT one_CD of_IN a_DT number_NN of_IN specific_JJ genres_NNS ._.
General_NNP documents_NNS are_VBP more_RBR widely_RB available_JJ in_IN digital_JJ libraries_NNS ,_, intranets_NNS and_CC the_DT internet_NN ,_, and_CC thus_RB investigation_NN on_IN extraction_NN from_IN them_PRP is_VBZ sorely_RB needed_VBN ._.
Research_NNP papers_NNS usually_RB have_VBP well-formed_JJ styles_NNS and_CC noticeable_JJ characteristics_NNS ._.
In_IN contrast_NN ,_, the_DT styles_NNS of_IN general_JJ documents_NNS can_MD vary_VB greatly_RB ._.
It_PRP has_VBZ not_RB been_VBN clarified_VBN whether_IN a_DT machine_NN learning_NN based_VBN approach_NN can_MD work_VB well_RB for_IN this_DT task_NN ._.
There_EX are_VBP many_JJ types_NNS of_IN metadata_NN :_: title_NN ,_, author_NN ,_, date_NN of_IN creation_NN ,_, etc_FW ._.
As_IN a_DT case_NN study_NN ,_, we_PRP consider_VBP title_NN extraction_NN in_IN this_DT paper_NN ._.
General_NNP documents_NNS can_MD be_VB in_IN many_JJ different_JJ file_NN formats_NNS :_: Microsoft_NNP Office_NNP ,_, PDF_NNP -LRB-_-LRB- PS_NNP -RRB-_-RRB- ,_, etc_FW ._.
As_IN a_DT case_NN study_NN ,_, we_PRP consider_VBP extraction_NN from_IN Office_NNP including_VBG Word_NN and_CC PowerPoint_NN ._.
We_PRP take_VBP a_DT machine_NN learning_VBG approach_NN ._.
We_PRP annotate_VBP titles_NNS in_IN sample_NN documents_NNS -LRB-_-LRB- for_IN Word_NN and_CC PowerPoint_NN respectively_RB -RRB-_-RRB- and_CC take_VB them_PRP as_IN training_NN data_NNS to_TO train_VB several_JJ types_NNS of_IN models_NNS ,_, and_CC perform_VB title_NN extraction_NN using_VBG any_DT one_CD type_NN of_IN the_DT trained_JJ models_NNS ._.
In_IN the_DT models_NNS ,_, we_PRP mainly_RB utilize_VBP formatting_VBG information_NN such_JJ as_IN font_NN size_NN as_IN features_NNS ._.
We_PRP employ_VBP the_DT following_VBG models_NNS :_: Maximum_NNP Entropy_NNP Model_NNP ,_, Perceptron_NNP with_IN Uneven_JJ Margins_NNS ,_, Maximum_NNP Entropy_NNP Markov_NNP Model_NNP ,_, and_CC Voted_VBD Perceptron_NNP ._.
In_IN this_DT paper_NN ,_, we_PRP also_RB investigate_VBP the_DT following_VBG three_CD problems_NNS ,_, which_WDT did_VBD not_RB seem_VB to_TO have_VB been_VBN examined_VBN previously_RB ._.
-LRB-_-LRB- #_# -RRB-_-RRB- Comparison_NN between_IN models_NNS :_: among_IN the_DT models_NNS above_IN ,_, which_WDT model_VBP performs_VBZ best_JJS for_IN title_NN extraction_NN ;_: -LRB-_-LRB- #_# -RRB-_-RRB- Generality_NN of_IN model_NN :_: whether_IN it_PRP is_VBZ possible_JJ to_TO train_VB a_DT model_NN on_IN one_CD domain_NN and_CC apply_VB it_PRP to_TO another_DT domain_NN ,_, and_CC whether_IN it_PRP is_VBZ possible_JJ to_TO train_VB a_DT model_NN in_IN one_CD language_NN and_CC apply_VB it_PRP to_TO another_DT language_NN ;_: -LRB-_-LRB- #_# -RRB-_-RRB- Usefulness_NN of_IN extracted_VBN titles_NNS :_: whether_IN extracted_VBN titles_NNS can_MD improve_VB document_NN processing_NN such_JJ as_IN search_NN ._.
Experimental_JJ results_NNS indicate_VBP that_IN our_PRP$ approach_NN works_VBZ well_RB for_IN title_NN extraction_NN from_IN general_JJ documents_NNS ._.
Our_PRP$ method_NN can_MD significantly_RB outperform_VB the_DT baselines_NNS :_: one_CD that_WDT always_RB uses_VBZ the_DT first_JJ lines_NNS as_IN titles_NNS and_CC the_DT other_JJ that_IN always_RB uses_VBZ the_DT lines_NNS in_IN the_DT largest_JJS font_JJ sizes_NNS as_IN titles_NNS ._.
Precision_NN and_CC recall_NN for_IN title_NN extraction_NN from_IN Word_NN are_VBP #_# ._.
###_NN and_CC #_# ._.
###_NN respectively_RB ,_, and_CC precision_NN and_CC recall_NN for_IN title_NN extraction_NN from_IN PowerPoint_NNP are_VBP #_# ._.
###_NN and_CC #_# ._.
###_NN respectively_RB ._.
It_PRP turns_VBZ out_RP that_IN the_DT use_NN of_IN format_NN features_NNS is_VBZ the_DT key_JJ to_TO successful_JJ title_NN extraction_NN ._.
-LRB-_-LRB- #_# -RRB-_-RRB- We_PRP have_VBP observed_VBN that_IN Perceptron_NNP based_VBN models_NNS perform_VB better_JJR in_IN terms_NNS of_IN extraction_NN accuracies_NNS ._.
-LRB-_-LRB- #_# -RRB-_-RRB- We_PRP have_VBP empirically_RB verified_VBN that_IN the_DT models_NNS trained_VBN with_IN our_PRP$ approach_NN are_VBP generic_JJ in_IN the_DT sense_NN that_IN they_PRP can_MD be_VB trained_VBN on_IN one_CD domain_NN and_CC applied_VBD to_TO another_DT ,_, and_CC they_PRP can_MD be_VB trained_VBN in_IN one_CD language_NN and_CC applied_VBD to_TO another_DT ._.
-LRB-_-LRB- #_# -RRB-_-RRB- We_PRP have_VBP found_VBN that_IN using_VBG the_DT extracted_VBN titles_NNS we_PRP can_MD significantly_RB improve_VB precision_NN of_IN document_NN retrieval_NN -LRB-_-LRB- by_IN ##_CD %_NN -RRB-_-RRB- ._.
We_PRP conclude_VBP that_IN we_PRP can_MD indeed_RB conduct_VB reliable_JJ title_NN extraction_NN from_IN general_JJ documents_NNS and_CC use_VB the_DT extracted_VBN results_NNS to_TO improve_VB real_JJ applications_NNS ._.
The_DT rest_NN of_IN the_DT paper_NN is_VBZ organized_VBN as_IN follows_VBZ ._.
In_IN section_NN #_# ,_, we_PRP introduce_VBP related_JJ work_NN ,_, and_CC in_IN section_NN #_# ,_, we_PRP explain_VBP the_DT motivation_NN and_CC problem_NN setting_NN of_IN our_PRP$ work_NN ._.
In_IN section_NN #_# ,_, we_PRP describe_VBP our_PRP$ method_NN of_IN title_NN extraction_NN ,_, and_CC in_IN section_NN #_# ,_, we_PRP describe_VBP our_PRP$ method_NN of_IN document_NN retrieval_NN using_VBG extracted_VBN titles_NNS ._.
Section_NN #_# gives_VBZ our_PRP$ experimental_JJ results_NNS ._.
We_PRP make_VBP concluding_VBG remarks_NNS in_IN section_NN #_# ._.
2_LS ._.
RELATED_JJ WORK_VBP 2_CD ._.
#_# Document_NNP Metadata_NNP Extraction_NNP Methods_NNS have_VBP been_VBN proposed_VBN for_IN performing_VBG automatic_JJ metadata_NN extraction_NN from_IN documents_NNS ;_: however_RB ,_, the_DT main_JJ focus_NN was_VBD on_IN extraction_NN from_IN research_NN papers_NNS ._.
The_DT proposed_VBN methods_NNS fall_VBP into_IN two_CD categories_NNS :_: the_DT rule_NN based_VBN approach_NN and_CC the_DT machine_NN learning_NN based_VBN approach_NN ._.
Giuffrida_NNP et_FW al_FW ._.
-LSB-_-LRB- #_# -RSB-_-RRB- ,_, for_IN instance_NN ,_, developed_VBD a_DT rule-based_JJ system_NN for_IN automatically_RB extracting_VBG metadata_NN from_IN research_NN papers_NNS in_IN Postscript_NNP ._.
They_PRP used_VBD rules_NNS like_IN titles_NNS are_VBP usually_RB located_VBN on_IN the_DT upper_JJ portions_NNS of_IN the_DT first_JJ pages_NNS and_CC they_PRP are_VBP usually_RB in_IN the_DT largest_JJS font_JJ sizes_NNS ._.
Liddy_NNP et_FW al_FW ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- and_CC Yilmazel_NNP el_NNP al_NNP ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- performed_VBD metadata_JJ extraction_NN from_IN educational_JJ materials_NNS using_VBG rule-based_JJ natural_JJ language_NN processing_NN technologies_NNS ._.
Mao_NNP et_FW al_FW ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- also_RB conducted_VBN automatic_JJ metadata_NN extraction_NN from_IN research_NN papers_NNS using_VBG rules_NNS on_IN formatting_VBG information_NN ._.
The_DT rule-based_JJ approach_NN can_MD achieve_VB high_JJ performance_NN ._.
However_RB ,_, it_PRP also_RB has_VBZ disadvantages_NNS ._.
It_PRP is_VBZ less_RBR adaptive_JJ and_CC robust_JJ when_WRB compared_VBN with_IN the_DT machine_NN learning_VBG approach_NN ._.
Han_NNP et_FW al_FW ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- ,_, for_IN instance_NN ,_, conducted_VBN metadata_NN extraction_NN with_IN the_DT machine_NN learning_VBG approach_NN ._.
They_PRP viewed_VBD the_DT problem_NN as_IN that_DT of_IN classifying_VBG the_DT lines_NNS in_IN a_DT document_NN into_IN the_DT categories_NNS of_IN metadata_NN and_CC proposed_VBN using_VBG Support_NN Vector_NNP Machines_NNP as_IN the_DT classifier_NN ._.
They_PRP mainly_RB used_VBD linguistic_JJ information_NN as_IN features_NNS ._.
They_PRP reported_VBD high_JJ extraction_NN accuracy_NN from_IN research_NN papers_NNS in_IN terms_NNS of_IN precision_NN and_CC recall_NN ._.
2_LS ._.
#_# Information_NNP Extraction_NNP Metadata_NNP extraction_NN can_MD be_VB viewed_VBN as_IN an_DT application_NN of_IN information_NN extraction_NN ,_, in_IN which_WDT given_VBN a_DT sequence_NN of_IN instances_NNS ,_, we_PRP identify_VBP a_DT subsequence_NN that_WDT represents_VBZ information_NN in_IN which_WDT we_PRP are_VBP interested_JJ ._.
Hidden_NNP Markov_NNP Model_NNP -LSB-_-LRB- #_# -RSB-_-RRB- ,_, Maximum_NNP Entropy_NNP Model_NNP -LSB-_-LRB- #_# ,_, #_# -RSB-_-RRB- ,_, Maximum_NNP Entropy_NNP Markov_NNP Model_NNP -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, Support_NN Vector_NNP Machines_NNP -LSB-_-LRB- #_# -RSB-_-RRB- ,_, Conditional_JJ Random_NNP Field_NNP -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, and_CC Voted_VBD Perceptron_NNP -LSB-_-LRB- #_# -RSB-_-RRB- are_VBP widely_RB used_VBN information_NN extraction_NN models_NNS ._.
Information_NNP extraction_NN has_VBZ been_VBN applied_VBN ,_, for_IN instance_NN ,_, to_TO part-ofspeech_JJ tagging_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, named_VBN entity_NN recognition_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- and_CC table_NN extraction_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
2_LS ._.
#_# Search_VB Using_VBG Title_NNP Information_NNP Title_NNP information_NN is_VBZ useful_JJ for_IN document_NN retrieval_NN ._.
In_IN the_DT system_NN Citeseer_NNP ,_, for_IN instance_NN ,_, Giles_NNP et_FW al_FW ._.
managed_VBN to_TO extract_VB titles_NNS from_IN research_NN papers_NNS and_CC make_VB use_NN of_IN the_DT extracted_VBN titles_NNS in_IN metadata_NN search_NN of_IN papers_NNS -LSB-_-LRB- #_# -RSB-_-RRB- ._.
In_IN web_NN search_NN ,_, the_DT title_NN fields_NNS -LRB-_-LRB- i_FW ._.
e_LS ._.
,_, file_NN properties_NNS -RRB-_-RRB- and_CC anchor_NN texts_NNS of_IN web_NN pages_NNS -LRB-_-LRB- HTML_NNP documents_NNS -RRB-_-RRB- can_MD be_VB viewed_VBN as_IN titles_NNS ''_'' of_IN the_DT pages_NNS -LSB-_-LRB- #_# -RSB-_-RRB- ._.
Many_JJ search_NN engines_NNS seem_VBP to_TO utilize_VB them_PRP for_IN web_NN page_NN retrieval_NN -LSB-_-LRB- #_# ,_, ##_NN ,_, ##_NN ,_, ##_NN -RSB-_-RRB- ._.
Zhang_NNP et_FW al_FW ._.
,_, found_VBD that_IN web_NN pages_NNS with_IN well-defined_JJ metadata_NN are_VBP more_RBR easily_RB retrieved_VBN than_IN those_DT without_IN well-defined_JJ metadata_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
To_TO the_DT best_JJS of_IN our_PRP$ knowledge_NN ,_, no_DT research_NN has_VBZ been_VBN conducted_VBN on_IN using_VBG extracted_VBN titles_NNS from_IN general_JJ documents_NNS -LRB-_-LRB- e_LS ._.
g_NN ._.
,_, Office_NNP documents_NNS -RRB-_-RRB- for_IN search_NN of_IN the_DT documents_NNS ._.
146_CD 3_CD ._.
MOTIVATION_NN AND_CC PROBLEM_NN SETTING_VBG We_PRP consider_VBP the_DT issue_NN of_IN automatically_RB extracting_VBG titles_NNS from_IN general_JJ documents_NNS ._.
By_IN general_JJ documents_NNS ,_, we_PRP mean_VBP documents_NNS that_IN belong_VBP to_TO one_CD of_IN any_DT number_NN of_IN specific_JJ genres_NNS ._.
The_DT documents_NNS can_MD be_VB presentations_NNS ,_, books_NNS ,_, book_NN chapters_NNS ,_, technical_JJ papers_NNS ,_, brochures_NNS ,_, reports_NNS ,_, memos_NNS ,_, specifications_NNS ,_, letters_NNS ,_, announcements_NNS ,_, or_CC resumes_VBZ ._.
General_NNP documents_NNS are_VBP more_RBR widely_RB available_JJ in_IN digital_JJ libraries_NNS ,_, intranets_NNS ,_, and_CC internet_NN ,_, and_CC thus_RB investigation_NN on_IN title_NN extraction_NN from_IN them_PRP is_VBZ sorely_RB needed_VBN ._.
Figure_NNP #_# shows_VBZ an_DT estimate_NN on_IN distributions_NNS of_IN file_NN formats_NNS on_IN intranet_NN and_CC internet_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
Office_NNP and_CC PDF_NNP are_VBP the_DT main_JJ file_NN formats_NNS on_IN the_DT intranet_NN ._.
Even_RB on_IN the_DT internet_NN ,_, the_DT documents_NNS in_IN the_DT formats_NNS are_VBP still_RB not_RB negligible_JJ ,_, given_VBN its_PRP$ extremely_RB large_JJ size_NN ._.
In_IN this_DT paper_NN ,_, without_IN loss_NN of_IN generality_NN ,_, we_PRP take_VBP Office_NNP documents_NNS as_IN an_DT example_NN ._.
Figure_NNP #_# ._.
Distributions_NNS of_IN file_NN formats_NNS in_IN internet_NN and_CC intranet_NN ._.
For_IN Office_NNP documents_NNS ,_, users_NNS can_MD define_VB titles_NNS as_IN file_NN properties_NNS using_VBG a_DT feature_NN provided_VBN by_IN Office_NNP ._.
We_PRP found_VBD in_IN an_DT experiment_NN ,_, however_RB ,_, that_IN users_NNS seldom_RB use_VBP the_DT feature_NN and_CC thus_RB titles_NNS in_IN file_NN properties_NNS are_VBP usually_RB very_RB inaccurate_JJ ._.
That_DT is_VBZ to_TO say_VB ,_, titles_NNS in_IN file_NN properties_NNS are_VBP usually_RB inconsistent_JJ with_IN the_DT true_JJ ''_'' titles_NNS in_IN the_DT file_NN bodies_NNS that_WDT are_VBP created_VBN by_IN the_DT authors_NNS and_CC are_VBP visible_JJ to_TO readers_NNS ._.
We_PRP collected_VBD #_# ,_, ###_CD Word_NN and_CC #_# ,_, ###_CD PowerPoint_NNP documents_NNS from_IN an_DT intranet_NN and_CC the_DT internet_NN and_CC examined_VBD how_WRB many_JJ titles_NNS in_IN the_DT file_NN properties_NNS are_VBP correct_JJ ._.
We_PRP found_VBD that_IN surprisingly_RB the_DT accuracy_NN was_VBD only_RB #_# ._.
###_NN -LRB-_-LRB- cf_NN ._.
,_, Section_NNP #_# ._.
#_# for_IN details_NNS -RRB-_-RRB- ._.
A_DT number_NN of_IN reasons_NNS can_MD be_VB considered_VBN ._.
For_IN example_NN ,_, if_IN one_CD creates_VBZ a_DT new_JJ file_NN by_IN copying_VBG an_DT old_JJ file_NN ,_, then_RB the_DT file_NN property_NN of_IN the_DT new_JJ file_NN will_MD also_RB be_VB copied_VBN from_IN the_DT old_JJ file_NN ._.
In_IN another_DT experiment_NN ,_, we_PRP found_VBD that_IN Google_NNP uses_VBZ the_DT titles_NNS in_IN file_NN properties_NNS of_IN Office_NNP documents_NNS in_IN search_NN and_CC browsing_NN ,_, but_CC the_DT titles_NNS are_VBP not_RB very_RB accurate_JJ ._.
We_PRP created_VBD ##_CD queries_NNS to_TO search_VB Word_NN and_CC PowerPoint_NN documents_NNS and_CC examined_VBD the_DT top_JJ ##_CD results_NNS of_IN each_DT query_NN returned_VBN by_IN Google_NNP ._.
We_PRP found_VBD that_IN nearly_RB all_PDT the_DT titles_NNS presented_VBN in_IN the_DT search_NN results_NNS were_VBD from_IN the_DT file_NN properties_NNS of_IN the_DT documents_NNS ._.
However_RB ,_, only_RB #_# ._.
###_NN of_IN them_PRP were_VBD correct_JJ ._.
Actually_RB ,_, true_JJ ''_'' titles_NNS usually_RB exist_VBP at_IN the_DT beginnings_NNS of_IN the_DT bodies_NNS of_IN documents_NNS ._.
If_IN we_PRP can_MD accurately_RB extract_VB the_DT titles_NNS from_IN the_DT bodies_NNS of_IN documents_NNS ,_, then_RB we_PRP can_MD exploit_VB reliable_JJ title_NN information_NN in_IN document_NN processing_NN ._.
This_DT is_VBZ exactly_RB the_DT problem_NN we_PRP address_VBP in_IN this_DT paper_NN ._.
More_RBR specifically_RB ,_, given_VBN a_DT Word_NN document_NN ,_, we_PRP are_VBP to_TO extract_VB the_DT title_NN from_IN the_DT top_JJ region_NN of_IN the_DT first_JJ page_NN ._.
Given_VBN a_DT PowerPoint_NNP document_NN ,_, we_PRP are_VBP to_TO extract_VB the_DT title_NN from_IN the_DT first_JJ slide_NN ._.
A_DT title_NN sometimes_RB consists_VBZ of_IN a_DT main_JJ title_NN and_CC one_CD or_CC two_CD subtitles_NNS ._.
We_PRP only_RB consider_VBP extraction_NN of_IN the_DT main_JJ title_NN ._.
As_IN baselines_NNS for_IN title_NN extraction_NN ,_, we_PRP use_VBP that_IN of_IN always_RB using_VBG the_DT first_JJ lines_NNS as_IN titles_NNS and_CC that_IN of_IN always_RB using_VBG the_DT lines_NNS with_IN largest_JJS font_JJ sizes_NNS as_IN titles_NNS ._.
Figure_NNP #_# ._.
Title_NNP extraction_NN from_IN Word_NN document_NN ._.
Figure_NNP #_# ._.
Title_NNP extraction_NN from_IN PowerPoint_NNP document_NN ._.
Next_RB ,_, we_PRP define_VBP a_DT specification_NN ''_'' for_IN human_JJ judgments_NNS in_IN title_NN data_NNS annotation_NN ._.
The_DT annotated_JJ data_NNS will_MD be_VB used_VBN in_IN training_NN and_CC testing_NN of_IN the_DT title_NN extraction_NN methods_NNS ._.
Summary_NN of_IN the_DT specification_NN :_: The_DT title_NN of_IN a_DT document_NN should_MD be_VB identified_VBN on_IN the_DT basis_NN of_IN common_JJ sense_NN ,_, if_IN there_EX is_VBZ no_DT difficulty_NN in_IN the_DT identification_NN ._.
However_RB ,_, there_EX are_VBP many_JJ cases_NNS in_IN which_WDT the_DT identification_NN is_VBZ not_RB easy_JJ ._.
There_EX are_VBP some_DT rules_NNS defined_VBN in_IN the_DT specification_NN that_WDT guide_VBP identification_NN for_IN such_JJ cases_NNS ._.
The_DT rules_NNS include_VBP a_DT title_NN is_VBZ usually_RB in_IN consecutive_JJ lines_NNS in_IN the_DT same_JJ format_NN ,_, a_DT document_NN can_MD have_VB no_DT title_NN ,_, titles_NNS in_IN images_NNS are_VBP not_RB considered_VBN ,_, a_DT title_NN should_MD not_RB contain_VB words_NNS like_IN draft_NN ''_'' ,_, 147_CD whitepaper_NN ''_'' ,_, etc_NN ,_, if_IN it_PRP is_VBZ difficult_JJ to_TO determine_VB which_WDT is_VBZ the_DT title_NN ,_, select_VBP the_DT one_CD in_IN the_DT largest_JJS font_NN size_NN ,_, and_CC if_IN it_PRP is_VBZ still_RB difficult_JJ to_TO determine_VB which_WDT is_VBZ the_DT title_NN ,_, select_VBP the_DT first_JJ candidate_NN ._.
-LRB-_-LRB- The_DT specification_NN covers_VBZ all_PDT the_DT cases_NNS we_PRP have_VBP encountered_VBN in_IN data_NNS annotation_NN ._. -RRB-_-RRB-
Figures_NNS #_# and_CC #_# show_VBP examples_NNS of_IN Office_NNP documents_NNS from_IN which_WDT we_PRP conduct_VBP title_NN extraction_NN ._.
In_IN Figure_NNP #_# ,_, Differences_NNS in_IN Win32_NN API_NN Implementations_NNS among_IN Windows_NNP Operating_NNP Systems_NNPS ''_'' is_VBZ the_DT title_NN of_IN the_DT Word_NN document_NN ._.
Microsoft_NNP Windows_NNP ''_'' on_IN the_DT top_NN of_IN this_DT page_NN is_VBZ a_DT picture_NN and_CC thus_RB is_VBZ ignored_VBN ._.
In_IN Figure_NNP #_# ,_, Building_NN Competitive_JJ Advantages_NNS through_IN an_DT Agile_NNP Infrastructure_NNP ''_'' is_VBZ the_DT title_NN of_IN the_DT PowerPoint_NNP document_NN ._.
We_PRP have_VBP developed_VBN a_DT tool_NN for_IN annotation_NN of_IN titles_NNS by_IN human_JJ annotators_NNS ._.
Figure_NNP #_# shows_VBZ a_DT snapshot_NN of_IN the_DT tool_NN ._.
Figure_NNP #_# ._.
Title_NN annotation_NN tool_NN ._.
4_LS ._.
TITLE_NN EXTRACTION_NN METHOD_NN 4_CD ._.
#_# Outline_NNP Title_NNP extraction_NN based_VBN on_IN machine_NN learning_NN consists_VBZ of_IN training_NN and_CC extraction_NN ._.
The_DT same_JJ pre-processing_JJ step_NN occurs_VBZ before_IN training_NN and_CC extraction_NN ._.
During_IN pre-processing_JJ ,_, from_IN the_DT top_JJ region_NN of_IN the_DT first_JJ page_NN of_IN a_DT Word_NN document_NN or_CC the_DT first_JJ slide_NN of_IN a_DT PowerPoint_NNP document_VBP a_DT number_NN of_IN units_NNS for_IN processing_NN are_VBP extracted_VBN ._.
If_IN a_DT line_NN -LRB-_-LRB- lines_NNS are_VBP separated_VBN by_IN return_NN ''_'' symbols_NNS -RRB-_-RRB- only_RB has_VBZ a_DT single_JJ format_NN ,_, then_RB the_DT line_NN will_MD become_VB a_DT unit_NN ._.
If_IN a_DT line_NN has_VBZ several_JJ parts_NNS and_CC each_DT of_IN them_PRP has_VBZ its_PRP$ own_JJ format_NN ,_, then_RB each_DT part_NN will_MD become_VB a_DT unit_NN ._.
Each_DT unit_NN will_MD be_VB treated_VBN as_IN an_DT instance_NN in_IN learning_NN ._.
A_DT unit_NN contains_VBZ not_RB only_RB content_JJ information_NN -LRB-_-LRB- linguistic_JJ information_NN -RRB-_-RRB- but_CC also_RB formatting_VBG information_NN ._.
The_DT input_NN to_TO pre-processing_NN is_VBZ a_DT document_NN and_CC the_DT output_NN of_IN pre-processing_JJ is_VBZ a_DT sequence_NN of_IN units_NNS -LRB-_-LRB- instances_NNS -RRB-_-RRB- ._.
Figure_NNP #_# shows_VBZ the_DT units_NNS obtained_VBN from_IN the_DT document_NN in_IN Figure_NNP #_# ._.
Figure_NNP #_# ._.
Example_NN of_IN units_NNS ._.
In_IN learning_NN ,_, the_DT input_NN is_VBZ sequences_NNS of_IN units_NNS where_WRB each_DT sequence_NN corresponds_VBZ to_TO a_DT document_NN ._.
We_PRP take_VBP labeled_VBN units_NNS -LRB-_-LRB- labeled_VBN as_IN title_NN __NN begin_VB ,_, title_NN __CD end_NN ,_, or_CC other_JJ -RRB-_-RRB- in_IN the_DT sequences_NNS as_IN training_NN data_NNS and_CC construct_NN models_NNS for_IN identifying_VBG whether_IN a_DT unit_NN is_VBZ title_NN __NN begin_VB title_NN __NN end_NN ,_, or_CC other_JJ ._.
We_PRP employ_VBP four_CD types_NNS of_IN models_NNS :_: Perceptron_NNP ,_, Maximum_NNP Entropy_NNP -LRB-_-LRB- ME_NNP -RRB-_-RRB- ,_, Perceptron_NNP Markov_NNP Model_NNP -LRB-_-LRB- PMM_NNP -RRB-_-RRB- ,_, and_CC Maximum_NNP Entropy_NNP Markov_NNP Model_NNP -LRB-_-LRB- MEMM_NNP -RRB-_-RRB- ._.
In_IN extraction_NN ,_, the_DT input_NN is_VBZ a_DT sequence_NN of_IN units_NNS from_IN one_CD document_NN ._.
We_PRP employ_VBP one_CD type_NN of_IN model_NN to_TO identify_VB whether_IN a_DT unit_NN is_VBZ title_NN __NN begin_VB ,_, title_NN __CD end_NN ,_, or_CC other_JJ ._.
We_PRP then_RB extract_VBP units_NNS from_IN the_DT unit_NN labeled_VBN with_IN title_NN __NN begin_VB ''_'' to_TO the_DT unit_NN labeled_VBN with_IN title_NN __CD end_NN ''_'' ._.
The_DT result_NN is_VBZ the_DT extracted_VBN title_NN of_IN the_DT document_NN ._.
The_DT unique_JJ characteristic_NN of_IN our_PRP$ approach_NN is_VBZ that_IN we_PRP mainly_RB utilize_VBP formatting_VBG information_NN for_IN title_NN extraction_NN ._.
Our_PRP$ assumption_NN is_VBZ that_IN although_IN general_JJ documents_NNS vary_VBP in_IN styles_NNS ,_, their_PRP$ formats_NNS have_VBP certain_JJ patterns_NNS and_CC we_PRP can_MD learn_VB and_CC utilize_VB the_DT patterns_NNS for_IN title_NN extraction_NN ._.
This_DT is_VBZ in_IN contrast_NN to_TO the_DT work_NN by_IN Han_NNP et_FW al_FW ._.
,_, in_IN which_WDT only_RB linguistic_JJ features_NNS are_VBP used_VBN for_IN extraction_NN from_IN research_NN papers_NNS ._.
4_LS ._.
#_# Models_NNS The_DT four_CD models_NNS actually_RB can_MD be_VB considered_VBN in_IN the_DT same_JJ metadata_NN extraction_NN framework_NN ._.
That_DT is_VBZ why_WRB we_PRP apply_VBP them_PRP together_RB to_TO our_PRP$ current_JJ problem_NN ._.
Each_DT input_NN is_VBZ a_DT sequence_NN of_IN instances_NNS kxxx_VBP L21_NN together_RB with_IN a_DT sequence_NN of_IN labels_NNS kyyy_VBP L21_NN ._.
ix_NN and_CC iy_NN represents_VBZ an_DT instance_NN and_CC its_PRP$ label_NN ,_, respectively_RB -LRB-_-LRB- ki_NN ,_, ,_, #_# ,_, #_# L_NN =_JJ -RRB-_-RRB- ._.
Recall_VB that_IN an_DT instance_NN here_RB represents_VBZ a_DT unit_NN ._.
A_DT label_NN represents_VBZ title_NN __NN begin_VB ,_, title_NN __CD end_NN ,_, or_CC other_JJ ._.
Here_RB ,_, k_NN is_VBZ the_DT number_NN of_IN units_NNS in_IN a_DT document_NN ._.
In_IN learning_NN ,_, we_PRP train_VBP a_DT model_NN which_WDT can_MD be_VB generally_RB denoted_VBN as_IN a_DT conditional_JJ probability_NN distribution_NN -RRB-_-RRB- |_NN -LRB-_-LRB- ##_CD kk_NN XXYYP_NN LL_NN where_WRB iX_NNP and_CC iY_NNP denote_VBP random_JJ variables_NNS taking_VBG instance_NN ix_NN and_CC label_NN iy_NN as_IN values_NNS ,_, respectively_RB -LRB-_-LRB- ki_NN ,_, ,_, #_# ,_, #_# L_NN =_JJ -RRB-_-RRB- ._.
Learning_NNP Tool_NNP Extraction_NNP Tool_NNP 21121_CD 2222122221_CD 1121111211_CD nknnknn_NN kk_NN kk_NN yyyxxx_NN yyyxxx_NN yyyxxx_NN LL_NN LL_NN LL_NN LL_NN -RRB-_-RRB- |_NN -LRB-_-LRB- maxarg_NN ##_CD mkmmkm_NN xxyyP_NN LL_NN -RRB-_-RRB- |_NN -LRB-_-LRB- ##_CD kk_NN XXYYP_NN LL_NN Conditional_JJ Distribution_NN mkmm_NN xxx_NN L21_NN Figure_NN #_# ._.
Metadata_NNP extraction_NN model_NN ._.
We_PRP can_MD make_VB assumptions_NNS about_IN the_DT general_JJ model_NN in_IN order_NN to_TO make_VB it_PRP simple_JJ enough_RB for_IN training_NN ._.
148_CD For_IN example_NN ,_, we_PRP can_MD assume_VB that_IN kYY_NN ,_, ,_, #_# L_NN are_VBP independent_JJ of_IN each_DT other_JJ given_VBN kXX_NN ,_, ,_, #_# L_NN ._.
Thus_RB ,_, we_PRP have_VBP -RRB-_-RRB- |_NN -LRB-_-LRB- -RRB-_-RRB- |_NN -LRB-_-LRB- -RRB-_-RRB- |_NN -LRB-_-LRB- 11_CD 11_CD kk_NN kk_NN XYPXYP_NN XXYYP_NN L_NN LL_NN =_JJ In_IN this_DT way_NN ,_, we_PRP decompose_VBP the_DT model_NN into_IN a_DT number_NN of_IN classifiers_NNS ._.
We_PRP train_VBP the_DT classifiers_NNS locally_RB using_VBG the_DT labeled_VBN data_NNS ._.
As_IN the_DT classifier_NN ,_, we_PRP employ_VBP the_DT Perceptron_NNP or_CC Maximum_NNP Entropy_NNP model_NN ._.
We_PRP can_MD also_RB assume_VB that_IN the_DT first_JJ order_NN Markov_NNP property_NN holds_VBZ for_IN kYY_NN ,_, ,_, #_# L_NN given_VBN kXX_NNP ,_, ,_, #_# L_NN ._.
Thus_RB ,_, we_PRP have_VBP -RRB-_-RRB- |_NN -LRB-_-LRB- -RRB-_-RRB- |_NN -LRB-_-LRB- -RRB-_-RRB- |_NN -LRB-_-LRB- 111_CD 11_CD kkk_NN kk_NN XYYPXYP_NN XXYYP_NN =_JJ L_NN LL_NN Again_RB ,_, we_PRP obtain_VBP a_DT number_NN of_IN classifiers_NNS ._.
However_RB ,_, the_DT classifiers_NNS are_VBP conditioned_VBN on_IN the_DT previous_JJ label_NN ._.
When_WRB we_PRP employ_VBP the_DT Percepton_NNP or_CC Maximum_NNP Entropy_NNP model_NN as_IN a_DT classifier_NN ,_, the_DT models_NNS become_VBP a_DT Percepton_NNP Markov_NNP Model_NNP or_CC Maximum_NNP Entropy_NNP Markov_NNP Model_NNP ,_, respectively_RB ._.
That_DT is_VBZ to_TO say_VB ,_, the_DT two_CD models_NNS are_VBP more_RBR precise_JJ ._.
In_IN extraction_NN ,_, given_VBN a_DT new_JJ sequence_NN of_IN instances_NNS ,_, we_PRP resort_VBP to_TO one_CD of_IN the_DT constructed_VBN models_NNS to_TO assign_VB a_DT sequence_NN of_IN labels_NNS to_TO the_DT sequence_NN of_IN instances_NNS ,_, i_FW ._.
e_LS ._.
,_, perform_VB extraction_NN ._.
For_IN Perceptron_NNP and_CC ME_NNP ,_, we_PRP assign_VBP labels_NNS locally_RB and_CC combine_VB the_DT results_NNS globally_RB later_RB using_VBG heuristics_NNS ._.
Specifically_RB ,_, we_PRP first_RB identify_VB the_DT most_RBS likely_JJ title_NN __NN begin_VB ._.
Then_RB we_PRP find_VBP the_DT most_RBS likely_JJ title_NN __NN end_NN within_IN three_CD units_NNS after_IN the_DT title_NN __NN begin_VB ._.
Finally_RB ,_, we_PRP extract_VBP as_IN a_DT title_NN the_DT units_NNS between_IN the_DT title_NN __NN begin_VB and_CC the_DT title_NN __NN end_NN ._.
For_IN PMM_NN and_CC MEMM_NN ,_, we_PRP employ_VBP the_DT Viterbi_NNP algorithm_NN to_TO find_VB the_DT globally_RB optimal_JJ label_NN sequence_NN ._.
In_IN this_DT paper_NN ,_, for_IN Perceptron_NNP ,_, we_PRP actually_RB employ_VBP an_DT improved_VBN variant_NN of_IN it_PRP ,_, called_VBN Perceptron_NNP with_IN Uneven_JJ Margin_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
This_DT version_NN of_IN Perceptron_NNP can_MD work_VB well_RB especially_RB when_WRB the_DT number_NN of_IN positive_JJ instances_NNS and_CC the_DT number_NN of_IN negative_JJ instances_NNS differ_VBP greatly_RB ,_, which_WDT is_VBZ exactly_RB the_DT case_NN in_IN our_PRP$ problem_NN ._.
We_PRP also_RB employ_VBP an_DT improved_VBN version_NN of_IN Perceptron_NNP Markov_NNP Model_NNP in_IN which_WDT the_DT Perceptron_NNP model_NN is_VBZ the_DT so-called_JJ Voted_NNP Perceptron_NNP -LSB-_-LRB- #_# -RSB-_-RRB- ._.
In_IN addition_NN ,_, in_IN training_NN ,_, the_DT parameters_NNS of_IN the_DT model_NN are_VBP updated_VBN globally_RB rather_RB than_IN locally_RB ._.
4_LS ._.
#_# Features_VBZ There_EX are_VBP two_CD types_NNS of_IN features_NNS :_: format_NN features_NNS and_CC linguistic_JJ features_NNS ._.
We_PRP mainly_RB use_VBP the_DT former_JJ ._.
The_DT features_NNS are_VBP used_VBN for_IN both_CC the_DT title-begin_NN and_CC the_DT title-end_JJ classifiers_NNS ._.
4_LS ._.
#_# ._.
#_# Format_NNP Features_VBZ Font_NNP Size_NN :_: There_EX are_VBP four_CD binary_JJ features_NNS that_WDT represent_VBP the_DT normalized_VBN font_NN size_NN of_IN the_DT unit_NN -LRB-_-LRB- recall_NN that_IN a_DT unit_NN has_VBZ only_RB one_CD type_NN of_IN font_NN -RRB-_-RRB- ._.
If_IN the_DT font_NN size_NN of_IN the_DT unit_NN is_VBZ the_DT largest_JJS in_IN the_DT document_NN ,_, then_RB the_DT first_JJ feature_NN will_MD be_VB #_# ,_, otherwise_RB #_# ._.
If_IN the_DT font_NN size_NN is_VBZ the_DT smallest_JJS in_IN the_DT document_NN ,_, then_RB the_DT fourth_JJ feature_NN will_MD be_VB #_# ,_, otherwise_RB #_# ._.
If_IN the_DT font_NN size_NN is_VBZ above_IN the_DT average_JJ font_NN size_NN and_CC not_RB the_DT largest_JJS in_IN the_DT document_NN ,_, then_RB the_DT second_JJ feature_NN will_MD be_VB #_# ,_, otherwise_RB #_# ._.
If_IN the_DT font_NN size_NN is_VBZ below_IN the_DT average_JJ font_NN size_NN and_CC not_RB the_DT smallest_JJS ,_, the_DT third_JJ feature_NN will_MD be_VB #_# ,_, otherwise_RB #_# ._.
It_PRP is_VBZ necessary_JJ to_TO conduct_VB normalization_NN on_IN font_NN sizes_NNS ._.
For_IN example_NN ,_, in_IN one_CD document_NN the_DT largest_JJS font_NN size_NN might_MD be_VB 12pt_JJ ''_'' ,_, while_IN in_IN another_DT the_DT smallest_JJS one_NN might_MD be_VB 18pt_JJ ''_'' ._.
Boldface_NNP :_: This_DT binary_JJ feature_NN represents_VBZ whether_IN or_CC not_RB the_DT current_JJ unit_NN is_VBZ in_IN boldface_NN ._.
Alignment_NN :_: There_EX are_VBP four_CD binary_JJ features_NNS that_WDT respectively_RB represent_VBP the_DT location_NN of_IN the_DT current_JJ unit_NN :_: left_VBN ''_'' ,_, center_NN ''_'' ,_, right_NN ''_'' ,_, and_CC unknown_JJ alignment_NN ''_'' ._.
The_DT following_VBG format_NN features_NNS with_IN respect_NN to_TO context_NN ''_'' play_VB an_DT important_JJ role_NN in_IN title_NN extraction_NN ._.
Empty_JJ Neighboring_VBG Unit_NN :_: There_EX are_VBP two_CD binary_JJ features_NNS that_WDT represent_VBP ,_, respectively_RB ,_, whether_IN or_CC not_RB the_DT previous_JJ unit_NN and_CC the_DT current_JJ unit_NN are_VBP blank_JJ lines_NNS ._.
Font_NNP Size_NN Change_NNP :_: There_EX are_VBP two_CD binary_JJ features_NNS that_WDT represent_VBP ,_, respectively_RB ,_, whether_IN or_CC not_RB the_DT font_NN size_NN of_IN the_DT previous_JJ unit_NN and_CC the_DT font_NN size_NN of_IN the_DT next_JJ unit_NN differ_VBP from_IN that_DT of_IN the_DT current_JJ unit_NN ._.
Alignment_NN Change_NNP :_: There_EX are_VBP two_CD binary_JJ features_NNS that_WDT represent_VBP ,_, respectively_RB ,_, whether_IN or_CC not_RB the_DT alignment_NN of_IN the_DT previous_JJ unit_NN and_CC the_DT alignment_NN of_IN the_DT next_JJ unit_NN differ_VBP from_IN that_DT of_IN the_DT current_JJ one_CD ._.
Same_JJ Paragraph_NN :_: There_EX are_VBP two_CD binary_JJ features_NNS that_WDT represent_VBP ,_, respectively_RB ,_, whether_IN or_CC not_RB the_DT previous_JJ unit_NN and_CC the_DT next_JJ unit_NN are_VBP in_IN the_DT same_JJ paragraph_NN as_IN the_DT current_JJ unit_NN ._.
4_LS ._.
#_# ._.
#_# Linguistic_NNP Features_VBZ The_DT linguistic_JJ features_NNS are_VBP based_VBN on_IN key_JJ words_NNS ._.
Positive_JJ Word_NN :_: This_DT binary_JJ feature_NN represents_VBZ whether_IN or_CC not_RB the_DT current_JJ unit_NN begins_VBZ with_IN one_CD of_IN the_DT positive_JJ words_NNS ._.
The_DT positive_JJ words_NNS include_VBP title_NN :_: ''_'' ,_, subject_NN :_: ''_'' ,_, subject_JJ line_NN :_: ''_'' For_IN example_NN ,_, in_IN some_DT documents_NNS the_DT lines_NNS of_IN titles_NNS and_CC authors_NNS have_VBP the_DT same_JJ formats_NNS ._.
However_RB ,_, if_IN lines_NNS begin_VBP with_IN one_CD of_IN the_DT positive_JJ words_NNS ,_, then_RB it_PRP is_VBZ likely_JJ that_IN they_PRP are_VBP title_NN lines_NNS ._.
Negative_JJ Word_NN :_: This_DT binary_JJ feature_NN represents_VBZ whether_IN or_CC not_RB the_DT current_JJ unit_NN begins_VBZ with_IN one_CD of_IN the_DT negative_JJ words_NNS ._.
The_DT negative_JJ words_NNS include_VBP To_TO ''_'' ,_, By_IN ''_'' ,_, created_VBN by_IN ''_'' ,_, updated_VBN by_IN ''_'' ,_, etc_FW ._.
There_EX are_VBP more_RBR negative_JJ words_NNS than_IN positive_JJ words_NNS ._.
The_DT above_JJ linguistic_JJ features_NNS are_VBP language_NN dependent_JJ ._.
Word_NN Count_NN :_: A_DT title_NN should_MD not_RB be_VB too_RB long_RB ._.
We_PRP heuristically_RB create_VBP four_CD intervals_NNS :_: -LSB-_-LRB- #_# ,_, #_# -RSB-_-RRB- ,_, -LSB-_-LRB- #_# ,_, #_# -RSB-_-RRB- ,_, -LSB-_-LRB- #_# ,_, #_# -RSB-_-RRB- and_CC -LSB-_-LRB- #_# ,_, -RRB-_-RRB- and_CC define_VB one_CD feature_NN for_IN each_DT interval_NN ._.
If_IN the_DT number_NN of_IN words_NNS in_IN a_DT title_NN falls_VBZ into_IN an_DT interval_NN ,_, then_RB the_DT corresponding_JJ feature_NN will_MD be_VB #_# ;_: otherwise_RB #_# ._.
Ending_VBG Character_NN :_: This_DT feature_NN represents_VBZ whether_IN the_DT unit_NN ends_VBZ with_IN :_: ''_'' ,_, -_: ''_'' ,_, or_CC other_JJ special_JJ characters_NNS ._.
A_DT title_NN usually_RB does_VBZ not_RB end_VB with_IN such_PDT a_DT character_NN ._.
5_CD ._.
DOCUMENT_NNP RETRIEVAL_NNP METHOD_NN We_PRP describe_VBP our_PRP$ method_NN of_IN document_NN retrieval_NN using_VBG extracted_VBN titles_NNS ._.
Typically_RB ,_, in_IN information_NN retrieval_NN a_DT document_NN is_VBZ split_VBN into_IN a_DT number_NN of_IN fields_NNS including_VBG body_NN ,_, title_NN ,_, and_CC anchor_NN text_NN ._.
A_DT ranking_JJ function_NN in_IN search_NN can_MD use_VB different_JJ weights_NNS for_IN different_JJ fields_NNS of_IN 149_CD the_DT document_NN ._.
Also_RB ,_, titles_NNS are_VBP typically_RB assigned_VBN high_JJ weights_NNS ,_, indicating_VBG that_IN they_PRP are_VBP important_JJ for_IN document_NN retrieval_NN ._.
As_IN explained_VBN previously_RB ,_, our_PRP$ experiment_NN has_VBZ shown_VBN that_IN a_DT significant_JJ number_NN of_IN documents_NNS actually_RB have_VBP incorrect_JJ titles_NNS in_IN the_DT file_NN properties_NNS ,_, and_CC thus_RB in_IN addition_NN of_IN using_VBG them_PRP we_PRP use_VBP the_DT extracted_VBN titles_NNS as_IN one_CD more_JJR field_NN of_IN the_DT document_NN ._.
By_IN doing_VBG this_DT ,_, we_PRP attempt_VBP to_TO improve_VB the_DT overall_JJ precision_NN ._.
In_IN this_DT paper_NN ,_, we_PRP employ_VBP a_DT modification_NN of_IN BM25_NN that_WDT allows_VBZ field_NN weighting_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
As_IN fields_NNS ,_, we_PRP make_VBP use_NN of_IN body_NN ,_, title_NN ,_, extracted_VBN title_NN and_CC anchor_NN ._.
First_RB ,_, for_IN each_DT term_NN in_IN the_DT query_NN we_PRP count_VBP the_DT term_NN frequency_NN in_IN each_DT field_NN of_IN the_DT document_NN ;_: each_DT field_NN frequency_NN is_VBZ then_RB weighted_JJ according_VBG to_TO the_DT corresponding_JJ weight_NN parameter_NN :_: =_JJ f_FW tfft_FW tfwwtf_FW Similarly_RB ,_, we_PRP compute_VBP the_DT document_NN length_NN as_IN a_DT weighted_JJ sum_NN of_IN lengths_NNS of_IN each_DT field_NN ._.
Average_JJ document_NN length_NN in_IN the_DT corpus_NN becomes_VBZ the_DT average_NN of_IN all_DT weighted_JJ document_NN lengths_NNS ._.
=_JJ f_FW ff_FW dlwwdl_FW In_IN our_PRP$ experiments_NNS we_PRP used_VBD ##_CD ._.
#_# ,_, #_# ._.
##_NN =_JJ =_JJ bk_NN ._.
Weight_NNP for_IN content_NN was_VBD #_# ._.
#_# ,_, title_NN was_VBD ##_CD ._.
#_# ,_, anchor_NN was_VBD ##_CD ._.
#_# ,_, and_CC extracted_VBN title_NN was_VBD 5_CD ._.
#_# ._.
6_CD ._.
EXPERIMENTAL_JJ RESULTS_NNS 6_CD ._.
#_# Data_NNPS Sets_NNPS and_CC Evaluation_NN Measures_NNS We_PRP used_VBD two_CD data_NNS sets_NNS in_IN our_PRP$ experiments_NNS ._.
First_RB ,_, we_PRP downloaded_VBD and_CC randomly_RB selected_VBN #_# ,_, ###_CD Word_NN documents_NNS and_CC #_# ,_, ###_CD PowerPoint_NNP documents_NNS from_IN an_DT intranet_NN of_IN Microsoft_NNP ._.
We_PRP call_VBP it_PRP MS_NN hereafter_RB ._.
Second_RB ,_, we_PRP downloaded_VBD and_CC randomly_RB selected_VBN ###_CD Word_NN and_CC ###_CD PowerPoint_NNP documents_NNS from_IN the_DT DotGov_NNP and_CC DotCom_NNP domains_NNS on_IN the_DT internet_NN ,_, respectively_RB ._.
Figure_NNP #_# shows_VBZ the_DT distributions_NNS of_IN the_DT genres_NNS of_IN the_DT documents_NNS ._.
We_PRP see_VBP that_IN the_DT documents_NNS are_VBP indeed_RB general_JJ documents_NNS ''_'' as_IN we_PRP define_VBP them_PRP ._.
Figure_NNP #_# ._.
Distributions_NNS of_IN document_NN genres_NNS ._.
Third_NNP ,_, a_DT data_NN set_NN in_IN Chinese_NNP was_VBD also_RB downloaded_VBN from_IN the_DT internet_NN ._.
It_PRP includes_VBZ ###_CD Word_NN documents_NNS and_CC ###_CD PowerPoint_NNP documents_NNS in_IN Chinese_JJ ._.
We_PRP manually_RB labeled_VBD the_DT titles_NNS of_IN all_PDT the_DT documents_NNS ,_, on_IN the_DT basis_NN of_IN our_PRP$ specification_NN ._.
Not_RB all_PDT the_DT documents_NNS in_IN the_DT two_CD data_NNS sets_NNS have_VBP titles_NNS ._.
Table_NNP #_# shows_VBZ the_DT percentages_NNS of_IN the_DT documents_NNS having_VBG titles_NNS ._.
We_PRP see_VBP that_IN DotCom_NNP and_CC DotGov_NNP have_VBP more_RBR PowerPoint_JJ documents_NNS with_IN titles_NNS than_IN MS_NN ._.
This_DT might_MD be_VB because_IN PowerPoint_NNP documents_NNS published_VBN on_IN the_DT internet_NN are_VBP more_RBR formal_JJ than_IN those_DT on_IN the_DT intranet_NN ._.
Table_NNP #_# ._.
The_DT portion_NN of_IN documents_NNS with_IN titles_NNS Domain_NN Type_NN MS_NN DotCom_NNP DotGov_NNP Word_VBD ##_CD ._.
#_# %_NN ##_CD ._.
#_# %_NN ##_CD ._.
#_# %_NN PowerPoint_NNP ##_NNP ._.
#_# %_NN ##_CD ._.
#_# %_NN ##_CD ._.
#_# %_NN In_IN our_PRP$ experiments_NNS ,_, we_PRP conducted_VBD evaluations_NNS on_IN title_NN extraction_NN in_IN terms_NNS of_IN precision_NN ,_, recall_NN ,_, and_CC F-measure_NN ._.
The_DT evaluation_NN measures_NNS are_VBP defined_VBN as_IN follows_VBZ :_: Precision_NN :_: P_NN =_JJ A_NN /_: -LRB-_-LRB- A_NN +_CC B_NN -RRB-_-RRB- Recall_VBP :_: R_NN =_JJ A_NN /_: -LRB-_-LRB- A_NN +_CC C_NN -RRB-_-RRB- F-measure_NN :_: F1_NN =_JJ 2PR_NN /_: -LRB-_-LRB- P_NN +_CC R_NN -RRB-_-RRB- Here_RB ,_, A_DT ,_, B_NN ,_, C_NN ,_, and_CC D_NN are_VBP numbers_NNS of_IN documents_NNS as_IN those_DT defined_VBN in_IN Table_NNP #_# ._.
Table_NNP #_# ._.
Contingence_NN table_NN with_IN regard_NN to_TO title_NN extraction_NN Is_VBZ title_NN Is_VBZ not_RB title_JJ Extracted_VBN A_NN B_NN Not_RB extracted_VBN C_NN D_NN 6_CD ._.
#_# Baselines_NNPS We_PRP test_VBP the_DT accuracies_NNS of_IN the_DT two_CD baselines_NNS described_VBN in_IN section_NN 4_CD ._.
#_# ._.
They_PRP are_VBP denoted_VBN as_RB largest_JJS font_JJ size_NN ''_'' and_CC first_JJ line_NN ''_'' respectively_RB ._.
6_CD ._.
#_# Accuracy_NNP of_IN Titles_NNP in_IN File_NNP Properties_NNP We_PRP investigate_VBP how_WRB many_JJ titles_NNS in_IN the_DT file_NN properties_NNS of_IN the_DT documents_NNS are_VBP reliable_JJ ._.
We_PRP view_VBP the_DT titles_NNS annotated_JJ by_IN humans_NNS as_IN true_JJ titles_NNS and_CC test_NN how_WRB many_JJ titles_NNS in_IN the_DT file_NN properties_NNS can_MD approximately_RB match_VB with_IN the_DT true_JJ titles_NNS ._.
We_PRP use_VBP Edit_NNP Distance_NNP to_TO conduct_VB the_DT approximate_JJ match_NN ._.
-LRB-_-LRB- Approximate_JJ match_NN is_VBZ only_RB used_VBN in_IN this_DT evaluation_NN -RRB-_-RRB- ._.
This_DT is_VBZ because_IN sometimes_RB human_JJ annotated_JJ titles_NNS can_MD be_VB slightly_RB different_JJ from_IN the_DT titles_NNS in_IN file_NN properties_NNS on_IN the_DT surface_NN ,_, e_LS ._.
g_NN ._.
,_, contain_VBP extra_JJ spaces_NNS -RRB-_-RRB- ._.
Given_VBN string_NN A_NN and_CC string_NN B_NN :_: if_IN -LRB-_-LRB- -LRB-_-LRB- D_NN =_JJ =_JJ #_# -RRB-_-RRB- or_CC -LRB-_-LRB- D_NN /_: -LRB-_-LRB- La_NN +_CC Lb_NN -RRB-_-RRB- <_JJR -RRB-_-RRB- -RRB-_-RRB- then_RB string_NN A_NN =_JJ string_NN B_NN D_NN :_: Edit_VB Distance_NNP between_IN string_NN A_NN and_CC string_NN B_NN La_NN :_: length_NN of_IN string_NN A_NN Lb_NN :_: length_NN of_IN string_NN B_NN :_: #_# ._.
#_# +_CC +_CC +_CC =_JJ t_NN t_NN n_NN N_NN wtf_NN avwdl_NN wdl_NN bbk_NN kwtf_NN FBM_NN -RRB-_-RRB- log_NN -LRB-_-LRB- -RRB-_-RRB- -RRB-_-RRB- #_# -LRB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- #_# -LRB-_-LRB- 25_CD 1_CD 1_CD 150_CD Table_NNP #_# ._.
Accuracies_NNS of_IN titles_NNS in_IN file_NN properties_NNS File_VBP Type_NN Domain_NN Precision_NNP Recall_VB F1_NN MS_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD DotCom_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
212Word_NN DotGov_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_NN MS_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD DotCom_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
186PowerPoint_NNP DotGov_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_NN 6_CD ._.
#_# Comparison_NN with_IN Baselines_NNS We_PRP conducted_VBD title_NN extraction_NN from_IN the_DT first_JJ data_NN set_NN -LRB-_-LRB- Word_NN and_CC PowerPoint_NN in_IN MS_NN -RRB-_-RRB- ._.
As_IN the_DT model_NN ,_, we_PRP used_VBD Perceptron_NNP ._.
We_PRP conduct_VBP 4-fold_JJ cross_NN validation_NN ._.
Thus_RB ,_, all_PDT the_DT results_NNS reported_VBN here_RB are_VBP those_DT averaged_VBN over_IN #_# trials_NNS ._.
Tables_NNS #_# and_CC #_# show_VBP the_DT results_NNS ._.
We_PRP see_VBP that_IN Perceptron_NNP significantly_RB outperforms_VBZ the_DT baselines_NNS ._.
In_IN the_DT evaluation_NN ,_, we_PRP use_VBP exact_JJ matching_NN between_IN the_DT true_JJ titles_NNS annotated_JJ by_IN humans_NNS and_CC the_DT extracted_VBN titles_NNS ._.
Table_NNP #_# ._.
Accuracies_NNS of_IN title_NN extraction_NN with_IN Word_NN Precision_NN Recall_VB F1_NN Model_NNP Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD Largest_JJ font_NN size_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_RB Baselines_NNP First_NNP line_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_RB Table_NNP #_# ._.
Accuracies_NNS of_IN title_NN extraction_NN with_IN PowerPoint_NNP Precision_NNP Recall_VB F1_NN Model_NNP Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD Largest_JJ font_NN size_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_RB Baselines_NNP First_NNP line_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD We_PRP see_VBP that_IN the_DT machine_NN learning_VBG approach_NN can_MD achieve_VB good_JJ performance_NN in_IN title_NN extraction_NN ._.
For_IN Word_NN documents_NNS both_CC precision_NN and_CC recall_NN of_IN the_DT approach_NN are_VBP #_# percent_NN higher_JJR than_IN those_DT of_IN the_DT baselines_NNS ._.
For_IN PowerPoint_NNP both_CC precision_NN and_CC recall_NN of_IN the_DT approach_NN are_VBP #_# percent_NN higher_JJR than_IN those_DT of_IN the_DT baselines_NNS ._.
We_PRP conduct_VBP significance_NN tests_NNS ._.
The_DT results_NNS are_VBP shown_VBN in_IN Table_NNP #_# ._.
Here_RB ,_, Largest_NNP ''_'' denotes_VBZ the_DT baseline_NN of_IN using_VBG the_DT largest_JJS font_NN size_NN ,_, First_NNP ''_'' denotes_VBZ the_DT baseline_NN of_IN using_VBG the_DT first_JJ line_NN ._.
The_DT results_NNS indicate_VBP that_IN the_DT improvements_NNS of_IN machine_NN learning_NN over_IN baselines_NNS are_VBP statistically_RB significant_JJ -LRB-_-LRB- in_IN the_DT sense_NN p-value_NN <_JJR #_# ._.
##_NN -RRB-_-RRB- Table_NNP #_# ._.
Sign_VB test_NN results_NNS Documents_NNS Type_NN Sign_NN test_NN between_IN p-value_JJ Perceptron_NNP vs_CC ._.
Largest_JJS #_# ._.
59e-26_JJ Word_NN Perceptron_NNP vs_CC ._.
First_JJ #_# ._.
12e-10_JJ Perceptron_NNP vs_CC ._.
Largest_JJS #_# ._.
###_CD PowerPoint_NNP Perceptron_NNP vs_CC ._.
First_JJ #_# ._.
13e-40_JJ We_PRP see_VBP ,_, from_IN the_DT results_NNS ,_, that_IN the_DT two_CD baselines_NNS can_MD work_VB well_RB for_IN title_NN extraction_NN ,_, suggesting_VBG that_IN font_NN size_NN and_CC position_NN information_NN are_VBP most_RBS useful_JJ features_NNS for_IN title_NN extraction_NN ._.
However_RB ,_, it_PRP is_VBZ also_RB obvious_JJ that_IN using_VBG only_RB these_DT two_CD features_NNS is_VBZ not_RB enough_RB ._.
There_EX are_VBP cases_NNS in_IN which_WDT all_PDT the_DT lines_NNS have_VBP the_DT same_JJ font_NN size_NN -LRB-_-LRB- i_FW ._.
e_LS ._.
,_, the_DT largest_JJS font_NN size_NN -RRB-_-RRB- ,_, or_CC cases_NNS in_IN which_WDT the_DT lines_NNS with_IN the_DT largest_JJS font_NN size_NN only_RB contain_VBP general_JJ descriptions_NNS like_IN Confidential_NNP ''_'' ,_, White_NNP paper_NN ''_'' ,_, etc_FW ._.
For_IN those_DT cases_NNS ,_, the_DT largest_JJS font_NN size_NN ''_'' method_NN can_MD not_RB work_VB well_RB ._.
For_IN similar_JJ reasons_NNS ,_, the_DT first_JJ line_NN ''_'' method_NN alone_RB can_MD not_RB work_VB well_RB ,_, either_CC ._.
With_IN the_DT combination_NN of_IN different_JJ features_NNS -LRB-_-LRB- evidence_NN in_IN title_NN judgment_NN -RRB-_-RRB- ,_, Perceptron_NNP can_MD outperform_VB Largest_NNP and_CC First_NNP ._.
We_PRP investigate_VBP the_DT performance_NN of_IN solely_RB using_VBG linguistic_JJ features_NNS ._.
We_PRP found_VBD that_IN it_PRP does_VBZ not_RB work_VB well_RB ._.
It_PRP seems_VBZ that_IN the_DT format_NN features_NNS play_VBP important_JJ roles_NNS and_CC the_DT linguistic_JJ features_NNS are_VBP supplements_NNS ._. ._.
Figure_NNP #_# ._.
An_DT example_NN Word_NN document_NN ._.
Figure_NNP #_# ._.
An_DT example_NN PowerPoint_NNP document_NN ._.
We_PRP conducted_VBD an_DT error_NN analysis_NN on_IN the_DT results_NNS of_IN Perceptron_NNP ._.
We_PRP found_VBD that_IN the_DT errors_NNS fell_VBD into_IN three_CD categories_NNS ._.
-LRB-_-LRB- #_# -RRB-_-RRB- About_IN one_CD third_NN of_IN the_DT errors_NNS were_VBD related_VBN to_TO hard_JJ cases_NNS ''_'' ._.
In_IN these_DT documents_NNS ,_, the_DT layouts_NNS of_IN the_DT first_JJ pages_NNS were_VBD difficult_JJ to_TO understand_VB ,_, even_RB for_IN humans_NNS ._.
Figure_NNP #_# and_CC #_# shows_VBZ examples_NNS ._.
-LRB-_-LRB- #_# -RRB-_-RRB- Nearly_RB one_CD fourth_JJ of_IN the_DT errors_NNS were_VBD from_IN the_DT documents_NNS which_WDT do_VBP not_RB have_VB true_JJ titles_NNS but_CC only_RB contain_VBP bullets_NNS ._.
Since_IN we_PRP conduct_VBP extraction_NN from_IN the_DT top_JJ regions_NNS ,_, it_PRP is_VBZ difficult_JJ to_TO get_VB rid_JJ of_IN these_DT errors_NNS with_IN the_DT current_JJ approach_NN ._.
-LRB-_-LRB- #_# -RRB-_-RRB- ._.
Confusions_NNS between_IN main_JJ titles_NNS and_CC subtitles_NNS were_VBD another_DT type_NN of_IN error_NN ._.
Since_IN we_PRP only_RB labeled_VBD the_DT main_JJ titles_NNS as_IN titles_NNS ,_, the_DT extractions_NNS of_IN both_DT titles_NNS were_VBD considered_VBN incorrect_JJ ._.
This_DT type_NN of_IN error_NN does_VBZ little_JJ harm_NN to_TO document_NN processing_NN like_IN search_NN ,_, however_RB ._.
6_CD ._.
#_# Comparison_NN between_IN Models_NNS To_TO compare_VB the_DT performance_NN of_IN different_JJ machine_NN learning_VBG models_NNS ,_, we_PRP conducted_VBD another_DT experiment_NN ._.
Again_RB ,_, we_PRP perform_VBP 4-fold_JJ cross_NN 151_CD validation_NN on_IN the_DT first_JJ data_NN set_NN -LRB-_-LRB- MS_NN -RRB-_-RRB- ._.
Table_NNP #_# ,_, #_# shows_VBZ the_DT results_NNS of_IN all_PDT the_DT four_CD models_NNS ._.
It_PRP turns_VBZ out_RP that_IN Perceptron_NNP and_CC PMM_NNP perform_VBP the_DT best_JJS ,_, followed_VBN by_IN MEMM_NN ,_, and_CC ME_NN performs_VBZ the_DT worst_JJS ._.
In_IN general_JJ ,_, the_DT Markovian_NNP models_NNS perform_VB better_JJR than_IN or_CC as_RB well_RB as_IN their_PRP$ classifier_NN counterparts_NNS ._.
This_DT seems_VBZ to_TO be_VB because_IN the_DT Markovian_NNP models_NNS are_VBP trained_VBN globally_RB ,_, while_IN the_DT classifiers_NNS are_VBP trained_VBN locally_RB ._.
The_DT Perceptron_NNP based_VBN models_NNS perform_VB better_JJR than_IN the_DT ME_NN based_VBN counterparts_NNS ._.
This_DT seems_VBZ to_TO be_VB because_IN the_DT Perceptron_NNP based_VBN models_NNS are_VBP created_VBN to_TO make_VB better_JJR classifications_NNS ,_, while_IN ME_NN models_NNS are_VBP constructed_VBN for_IN better_JJR prediction_NN ._.
Table_NNP #_# ._.
Comparison_NN between_IN different_JJ learning_NN models_NNS for_IN title_NN extraction_NN with_IN Word_NN Model_NNP Precision_NNP Recall_VB F1_NN Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_SYM MEMM_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_NN PMM_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD ME_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_RB Table_NNP #_# ._.
Comparison_NN between_IN different_JJ learning_NN models_NNS for_IN title_NN extraction_NN with_IN PowerPoint_NNP Model_NNP Precision_NNP Recall_VB F1_NN Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_SYM MEMM_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_NN PMM_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD ME_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_NN 6_CD ._.
#_# Domain_NN Adaptation_NN We_PRP apply_VBP the_DT model_NN trained_VBN with_IN the_DT first_JJ data_NN set_NN -LRB-_-LRB- MS_NN -RRB-_-RRB- to_TO the_DT second_JJ data_NN set_NN -LRB-_-LRB- DotCom_NN and_CC DotGov_NN -RRB-_-RRB- ._.
Tables_NNS 9-12_CD show_VBP the_DT results_NNS ._.
Table_NNP #_# ._.
Accuracies_NNS of_IN title_NN extraction_NN with_IN Word_NN in_IN DotGov_NNP Precision_NNP Recall_VB F1_NN Model_NNP Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD Largest_JJ font_NN size_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
582Baselines_NNS First_JJ line_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_RB Table_NNP ##_CD ._.
Accuracies_NNS of_IN title_NN extraction_NN with_IN PowerPoint_NNP in_IN DotGov_NNP Precision_NNP Recall_VB F1_NN Model_NNP Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD Largest_JJ font_NN size_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
879Baselines_NNS First_JJ line_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_RB Table_NNP ##_CD ._.
Accuracies_NNS of_IN title_NN extraction_NN with_IN Word_NN in_IN DotCom_NNP Precisio_NNP n_NN Recall_VB F1_NN Model_NNP Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD Largest_JJ font_NN size_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
712Baselines_NNP First_NNP line_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_RB Table_NNP ##_CD ._.
Performance_NNP of_IN PowerPoint_NNP document_NN title_NN extraction_NN in_IN DotCom_NNP Precisio_NNP n_NN Recall_VB F1_NN Model_NNP Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD Largest_JJ font_NN size_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
875Baselines_NNS First_JJ line_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD From_IN the_DT results_NNS ,_, we_PRP see_VBP that_IN the_DT models_NNS can_MD be_VB adapted_VBN to_TO different_JJ domains_NNS well_RB ._.
There_EX is_VBZ almost_RB no_DT drop_NN in_IN accuracy_NN ._.
The_DT results_NNS indicate_VBP that_IN the_DT patterns_NNS of_IN title_NN formats_NNS exist_VBP across_IN different_JJ domains_NNS ,_, and_CC it_PRP is_VBZ possible_JJ to_TO construct_VB a_DT domain_NN independent_JJ model_NN by_IN mainly_RB using_VBG formatting_VBG information_NN ._.
6_CD ._.
#_# Language_NNP Adaptation_NNP We_PRP apply_VBP the_DT model_NN trained_VBN with_IN the_DT data_NNS in_IN English_NNP -LRB-_-LRB- MS_NN -RRB-_-RRB- to_TO the_DT data_NNS set_VBN in_IN Chinese_JJ ._.
Tables_NNS 13-14_CD show_VBP the_DT results_NNS ._.
Table_NNP ##_NNP ._.
Accuracies_NNS of_IN title_NN extraction_NN with_IN Word_NN in_IN Chinese_JJ Precision_NN Recall_VB F1_NN Model_NNP Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD Largest_JJ font_NN size_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
738Baselines_NNP First_NNP line_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_RB Table_NNP ##_CD ._.
Accuracies_NNS of_IN title_NN extraction_NN with_IN PowerPoint_NNP in_IN Chinese_NNP Precision_NNP Recall_VB F1_NN Model_NNP Perceptron_NNP #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD Largest_JJ font_NN size_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
782Baselines_NNP First_NNP line_NN #_# ._.
###_NN #_# ._.
###_NN #_# ._.
###_CD We_PRP see_VBP that_IN the_DT models_NNS can_MD be_VB adapted_VBN to_TO a_DT different_JJ language_NN ._.
There_EX are_VBP only_RB small_JJ drops_NNS in_IN accuracy_NN ._.
Obviously_RB ,_, the_DT linguistic_JJ features_NNS do_VBP not_RB work_VB for_IN Chinese_JJ ,_, but_CC the_DT effect_NN of_IN not_RB using_VBG them_PRP is_VBZ negligible_JJ ._.
The_DT results_NNS indicate_VBP that_IN the_DT patterns_NNS of_IN title_NN formats_NNS exist_VBP across_IN different_JJ languages_NNS ._.
From_IN the_DT domain_NN adaptation_NN and_CC language_NN adaptation_NN results_VBZ ,_, we_PRP conclude_VBP that_IN the_DT use_NN of_IN formatting_VBG information_NN is_VBZ the_DT key_JJ to_TO a_DT successful_JJ extraction_NN from_IN general_JJ documents_NNS ._.
6_CD ._.
#_# Search_VB with_IN Extracted_NNP Titles_NNP We_PRP performed_VBD experiments_NNS on_IN using_VBG title_NN extraction_NN for_IN document_NN retrieval_NN ._.
As_IN a_DT baseline_NN ,_, we_PRP employed_VBD BM25_NN without_IN using_VBG extracted_VBN titles_NNS ._.
The_DT ranking_JJ mechanism_NN was_VBD as_IN described_VBN in_IN Section_NN #_# ._.
The_DT weights_NNS were_VBD heuristically_RB set_VBN ._.
We_PRP did_VBD not_RB conduct_VB optimization_NN on_IN the_DT weights_NNS ._.
The_DT evaluation_NN was_VBD conducted_VBN on_IN a_DT corpus_NN of_IN #_# ._.
#_# M_NN documents_NNS crawled_VBD from_IN the_DT intranet_NN of_IN Microsoft_NNP using_VBG ###_CD evaluation_NN queries_NNS obtained_VBN from_IN this_DT intranet_NN ''_'' s_VBZ search_NN engine_NN query_NN logs_NNS ._.
##_NN queries_NNS were_VBD from_IN the_DT most_RBS popular_JJ set_NN ,_, while_IN ##_CD queries_NNS other_JJ were_VBD chosen_VBN randomly_RB ._.
Users_NNS were_VBD asked_VBN to_TO provide_VB judgments_NNS of_IN the_DT degree_NN of_IN document_NN relevance_NN from_IN a_DT scale_NN of_IN 1to_JJ #_# -LRB-_-LRB- #_# meaning_VBG detrimental_JJ ,_, #_# -_: bad_JJ ,_, #_# -_: fair_JJ ,_, #_# -_: good_JJ and_CC #_# -_: excellent_JJ -RRB-_-RRB- ._.
152_CD Figure_NN ##_NN shows_VBZ the_DT results_NNS ._.
In_IN the_DT chart_NN two_CD sets_NNS of_IN precision_NN results_NNS were_VBD obtained_VBN by_IN either_CC considering_VBG good_JJ or_CC excellent_JJ documents_NNS as_IN relevant_JJ -LRB-_-LRB- left_JJ #_# bars_NNS with_IN relevance_NN threshold_NN #_# ._.
#_# -RRB-_-RRB- ,_, or_CC by_IN considering_VBG only_RB excellent_JJ documents_NNS as_IN relevant_JJ -LRB-_-LRB- right_JJ #_# bars_NNS with_IN relevance_NN threshold_NN #_# ._.
#_# -RRB-_-RRB- 0_CD 0_CD ._.
##_NN 0_CD ._.
#_# 0_CD ._.
##_NN 0_CD ._.
#_# 0_CD ._.
##_NN 0_CD ._.
#_# 0_CD ._.
##_NN 0_CD ._.
#_# 0_CD ._.
##_NN P_NN @_IN ##_CD P_NN @_IN #_# Reciprocal_JJ P_NN @_IN ##_CD P_NN @_IN #_# Reciprocal_JJ 0_CD ._.
#_# #_# BM25_CD Anchor_NNP ,_, Title_NNP ,_, Body_NNP BM25_NNP Anchor_NNP ,_, Title_NNP ,_, Body_NNP ,_, ExtractedTitle_NNP Name_VB All_DT RelevanceThreshold_NNP Data_NNP Description_NN Figure_NN ##_NN ._.
Search_VB ranking_JJ results_NNS ._.
Figure_NNP ##_NN shows_VBZ different_JJ document_NN retrieval_NN results_VBZ with_IN different_JJ ranking_JJ functions_NNS in_IN terms_NNS of_IN precision_NN @_IN ##_CD ,_, precision_NN @_IN #_# and_CC reciprocal_JJ rank_NN :_: Blue_NNP bar_NN -_: BM25_NN including_VBG the_DT fields_NNS body_NN ,_, title_NN -LRB-_-LRB- file_NN property_NN -RRB-_-RRB- ,_, and_CC anchor_NN text_NN ._.
Purple_NNP bar_NN -_: BM25_NN including_VBG the_DT fields_NNS body_NN ,_, title_NN -LRB-_-LRB- file_NN property_NN -RRB-_-RRB- ,_, anchor_NN text_NN ,_, and_CC extracted_VBN title_NN ._.
With_IN the_DT additional_JJ field_NN of_IN extracted_VBN title_NN included_VBD in_IN BM25_NN the_DT precision_NN @_IN ##_CD increased_VBN from_IN #_# ._.
###_CD to_TO #_# ._.
###_NN ,_, or_CC by_IN ~_CD ##_CD %_NN ._.
Thus_RB ,_, it_PRP is_VBZ safe_JJ to_TO say_VB that_IN the_DT use_NN of_IN extracted_VBN title_NN can_MD indeed_RB improve_VB the_DT precision_NN of_IN document_NN retrieval_NN ._.
7_CD ._.
CONCLUSION_NN In_IN this_DT paper_NN ,_, we_PRP have_VBP investigated_VBN the_DT problem_NN of_IN automatically_RB extracting_VBG titles_NNS from_IN general_JJ documents_NNS ._.
We_PRP have_VBP tried_VBN using_VBG a_DT machine_NN learning_VBG approach_NN to_TO address_VB the_DT problem_NN ._.
Previous_JJ work_NN showed_VBD that_IN the_DT machine_NN learning_VBG approach_NN can_MD work_VB well_RB for_IN metadata_NN extraction_NN from_IN research_NN papers_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP showed_VBD that_IN the_DT approach_NN can_MD work_VB for_IN extraction_NN from_IN general_JJ documents_NNS as_IN well_RB ._.
Our_PRP$ experimental_JJ results_NNS indicated_VBD that_IN the_DT machine_NN learning_VBG approach_NN can_MD work_VB significantly_RB better_JJR than_IN the_DT baselines_NNS in_IN title_NN extraction_NN from_IN Office_NNP documents_NNS ._.
Previous_JJ work_NN on_IN metadata_NN extraction_NN mainly_RB used_VBD linguistic_JJ features_NNS in_IN documents_NNS ,_, while_IN we_PRP mainly_RB used_VBD formatting_VBG information_NN ._.
It_PRP appeared_VBD that_IN using_VBG formatting_VBG information_NN is_VBZ a_DT key_NN for_IN successfully_RB conducting_VBG title_NN extraction_NN from_IN general_JJ documents_NNS ._.
We_PRP tried_VBD different_JJ machine_NN learning_VBG models_NNS including_VBG Perceptron_NNP ,_, Maximum_NNP Entropy_NNP ,_, Maximum_NNP Entropy_NNP Markov_NNP Model_NNP ,_, and_CC Voted_VBD Perceptron_NNP ._.
We_PRP found_VBD that_IN the_DT performance_NN of_IN the_DT Perceptorn_NNP models_NNS was_VBD the_DT best_JJS ._.
We_PRP applied_VBD models_NNS constructed_VBN in_IN one_CD domain_NN to_TO another_DT domain_NN and_CC applied_VBD models_NNS trained_VBN in_IN one_CD language_NN to_TO another_DT language_NN ._.
We_PRP found_VBD that_IN the_DT accuracies_NNS did_VBD not_RB drop_VB substantially_RB across_IN different_JJ domains_NNS and_CC across_IN different_JJ languages_NNS ,_, indicating_VBG that_IN the_DT models_NNS were_VBD generic_JJ ._.
We_PRP also_RB attempted_VBD to_TO use_VB the_DT extracted_VBN titles_NNS in_IN document_NN retrieval_NN ._.
We_PRP observed_VBD a_DT significant_JJ improvement_NN in_IN document_NN ranking_JJ performance_NN for_IN search_NN when_WRB using_VBG extracted_VBN title_NN information_NN ._.
All_PDT the_DT above_JJ investigations_NNS were_VBD not_RB conducted_VBN in_IN previous_JJ work_NN ,_, and_CC through_IN our_PRP$ investigations_NNS we_PRP verified_VBD the_DT generality_NN and_CC the_DT significance_NN of_IN the_DT title_NN extraction_NN approach_NN ._.
8_CD ._.
ACKNOWLEDGEMENTS_NNS We_PRP thank_VBP Chunyu_NNP Wei_NNP and_CC Bojuan_NNP Zhao_NNP for_IN their_PRP$ work_NN on_IN data_NNS annotation_NN ._.
We_PRP acknowledge_VBP Jinzhu_NNP Li_NNP for_IN his_PRP$ assistance_NN in_IN conducting_VBG the_DT experiments_NNS ._.
We_PRP thank_VBP Ming_NNP Zhou_NNP ,_, John_NNP Chen_NNP ,_, Jun_NNP Xu_NNP ,_, and_CC the_DT anonymous_JJ reviewers_NNS of_IN JCDL_NN ''_'' ##_NN for_IN their_PRP$ valuable_JJ comments_NNS on_IN this_DT paper_NN ._.
9_CD ._.
REFERENCES_NNS -LSB-_-LRB- #_# -RSB-_-RRB- Berger_NNP ,_, A_NNP ._.
L_NN ._.
,_, Della_NNP Pietra_NNP ,_, S_NN ._.
A_DT ._.
,_, and_CC Della_NNP Pietra_NNP ,_, V_NNP ._.
J_NN ._.
A_DT maximum_NN entropy_JJ approach_NN to_TO natural_JJ language_NN processing_NN ._.
Computational_JJ Linguistics_NNS ,_, ##_CD :_: 39-71_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Collins_NNP ,_, M_NN ._.
Discriminative_JJ training_NN methods_NNS for_IN hidden_JJ markov_NN models_NNS :_: theory_NN and_CC experiments_NNS with_IN perceptron_NN algorithms_NNS ._.
In_IN Proceedings_NNP of_IN Conference_NN on_IN Empirical_JJ Methods_NNS in_IN Natural_JJ Language_NN Processing_NN ,_, 1-8_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Cortes_NNP ,_, C_NNP ._.
and_CC Vapnik_NNP ,_, V_NNP ._.
Support-vector_JJ networks_NNS ._.
Machine_NN Learning_NNP ,_, ##_CD :_: 273-297_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Chieu_NNP ,_, H_NN ._.
L_NN ._.
and_CC Ng_NN ,_, H_NN ._.
T_NN ._.
A_DT maximum_NN entropy_JJ approach_NN to_TO information_NN extraction_NN from_IN semi-structured_JJ and_CC free_JJ text_NN ._.
In_IN Proceedings_NNP of_IN the_DT Eighteenth_NNP National_NNP Conference_NNP on_IN Artificial_NNP Intelligence_NNP ,_, 768-791_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Evans_NNP ,_, D_NNP ._.
K_NN ._.
,_, Klavans_NNP ,_, J_NNP ._.
L_NN ._.
,_, and_CC McKeown_NNP ,_, K_NNP ._.
R_NN ._.
Columbia_NNP newsblaster_NNP :_: multilingual_JJ news_NN summarization_NN on_IN the_DT Web_NN ._.
In_IN Proceedings_NNP of_IN Human_JJ Language_NNP Technology_NNP conference_NN /_: North_JJ American_JJ chapter_NN of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP annual_JJ meeting_NN ,_, 1-4_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Ghahramani_NNP ,_, Z_NN ._.
and_CC Jordan_NNP ,_, M_NN ._.
I_PRP ._.
Factorial_JJ hidden_JJ markov_NN models_NNS ._.
Machine_NN Learning_NNP ,_, ##_CD :_: 245-273_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Gheel_NNP ,_, J_NNP ._.
and_CC Anderson_NNP ,_, T_NN ._.
Data_NNS and_CC metadata_NN for_IN finding_NN and_CC reminding_VBG ,_, In_IN Proceedings_NNP of_IN the_DT ####_NNP International_NNP Conference_NNP on_IN Information_NNP Visualization_NN ,_, 446-451_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Giles_NNP ,_, C_NNP ._.
L_NN ._.
,_, Petinot_NNP ,_, Y_NN ._.
,_, Teregowda_NNP P_NN ._.
B_NN ._.
,_, Han_NNP ,_, H_NN ._.
,_, Lawrence_NNP ,_, S_NN ._.
,_, Rangaswamy_NNP ,_, A_NNP ._.
,_, and_CC Pal_NN ,_, N_NN ._.
eBizSearch_NNP :_: a_DT niche_NN search_NN engine_NN for_IN e-Business_NN ._.
In_IN Proceedings_NNP of_IN the_DT 26th_JJ Annual_JJ International_NNP ACM_NNP SIGIR_NNP Conference_NNP on_IN Research_NNP and_CC Development_NNP in_IN Information_NNP Retrieval_NNP ,_, 413414_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Giuffrida_NNP ,_, G_NNP ._.
,_, Shek_NNP ,_, E_NNP ._.
C_NN ._.
,_, and_CC Yang_NNP ,_, J_NNP ._.
Knowledge-based_JJ metadata_JJ extraction_NN from_IN PostScript_NNP files_NNS ._.
In_IN Proceedings_NNP of_IN the_DT Fifth_JJ ACM_NNP Conference_NN on_IN Digital_NNP Libraries_NNPS ,_, 77-84_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Han_NN ,_, H_NN ._.
,_, Giles_NNP ,_, C_NNP ._.
L_NN ._.
,_, Manavoglu_NNP ,_, E_NNP ._.
,_, Zha_NNP ,_, H_NN ._.
,_, Zhang_NNP ,_, Z_NN ._.
,_, and_CC Fox_NNP ,_, E_NNP ._.
A_DT ._.
Automatic_NNP document_NN metadata_NN extraction_NN using_VBG support_NN vector_NN machines_NNS ._.
In_IN Proceedings_NNP of_IN the_DT Third_NNP ACM_NNP /_: IEEE-CS_NNP Joint_NNP Conference_NNP on_IN Digital_NNP Libraries_NNPS ,_, 37-48_CD ,_, 2003_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Kobayashi_NNP ,_, M_NN ._.
,_, and_CC Takeda_NNP ,_, K_NNP ._.
Information_NNP retrieval_NN on_IN the_DT Web_NN ._.
ACM_NNP Computing_NNP Surveys_NNS ,_, ##_CD :_: 144-173_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Lafferty_NN ,_, J_NN ._.
,_, McCallum_NNP ,_, A_NNP ._.
,_, and_CC Pereira_NNP ,_, F_NN ._.
Conditional_JJ random_JJ fields_NNS :_: probabilistic_JJ models_NNS for_IN segmenting_VBG and_CC 153_CD labeling_NN sequence_NN data_NNS ._.
In_IN Proceedings_NNP of_IN the_DT Eighteenth_NNP International_NNP Conference_NNP on_IN Machine_NNP Learning_NNP ,_, 282-289_CD ,_, 2001_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Li_NNP ,_, Y_NN ._.
,_, Zaragoza_NNP ,_, H_NN ._.
,_, Herbrich_NNP ,_, R_NN ._.
,_, Shawe-Taylor_NNP J_NNP ._.
,_, and_CC Kandola_NNP ,_, J_NNP ._.
S_NN ._.
The_DT perceptron_NN algorithm_NN with_IN uneven_JJ margins_NNS ._.
In_IN Proceedings_NNP of_IN the_DT Nineteenth_NNP International_NNP Conference_NNP on_IN Machine_NNP Learning_NNP ,_, 379-386_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Liddy_NNP ,_, E_NNP ._.
D_NN ._.
,_, Sutton_NNP ,_, S_NN ._.
,_, Allen_NNP ,_, E_NNP ._.
,_, Harwell_NNP ,_, S_NN ._.
,_, Corieri_NNP ,_, S_NN ._.
,_, Yilmazel_NNP ,_, O_NNP ._.
,_, Ozgencil_NN ,_, N_NN ._.
E_NN ._.
,_, Diekema_NNP ,_, A_NNP ._.
,_, McCracken_NNP ,_, N_NNP ._.
,_, and_CC Silverstein_NNP ,_, J_NNP ._.
Automatic_NNP Metadata_NNP generation_NN &_CC evaluation_NN ._.
In_IN Proceedings_NNP of_IN the_DT 25th_JJ Annual_JJ International_NNP ACM_NNP SIGIR_NNP Conference_NNP on_IN Research_NNP and_CC Development_NNP in_IN Information_NNP Retrieval_NNP ,_, 401-402_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Littlefield_NNP ,_, A_NNP ._.
Effective_JJ enterprise_NN information_NN retrieval_NN across_IN new_JJ content_NN formats_NNS ._.
In_IN Proceedings_NNP of_IN the_DT Seventh_NNP Search_VB Engine_NNP Conference_NNP ,_, http_NN :_: /_: /_: www_NN ._.
infonortics_NNS ._.
com_NN /_: searchengines_NNS /_: sh02_NN /_: 02prog_NN ._.
html_NN ,_, 2002_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Mao_NNP ,_, S_NN ._.
,_, Kim_NNP ,_, J_NNP ._.
W_NN ._.
,_, and_CC Thoma_NNP ,_, G_NNP ._.
R_NN ._.
A_DT dynamic_JJ feature_NN generation_NN system_NN for_IN automated_VBN metadata_NN extraction_NN in_IN preservation_NN of_IN digital_JJ materials_NNS ._.
In_IN Proceedings_NNP of_IN the_DT First_NNP International_NNP Workshop_NNP on_IN Document_NNP Image_NN Analysis_NN for_IN Libraries_NNS ,_, 225-232_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- McCallum_NNP ,_, A_NNP ._.
,_, Freitag_NNP ,_, D_NNP ._.
,_, and_CC Pereira_NNP ,_, F_NN ._.
Maximum_NNP entropy_JJ markov_NN models_NNS for_IN information_NN extraction_NN and_CC segmentation_NN ._.
In_IN Proceedings_NNP of_IN the_DT Seventeenth_NNP International_NNP Conference_NNP on_IN Machine_NNP Learning_NNP ,_, 591-598_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Murphy_NNP ,_, L_NNP ._.
D_NN ._.
Digital_NNP document_NN metadata_NN in_IN organizations_NNS :_: roles_NNS ,_, analytical_JJ approaches_NNS ,_, and_CC future_JJ research_NN directions_NNS ._.
In_IN Proceedings_NNP of_IN the_DT Thirty-First_NNP Annual_JJ Hawaii_NNP International_NNP Conference_NNP on_IN System_NNP Sciences_NNPS ,_, 267-276_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Pinto_NNP ,_, D_NNP ._.
,_, McCallum_NNP ,_, A_NNP ._.
,_, Wei_NNP ,_, X_NN ._.
,_, and_CC Croft_NNP ,_, W_NNP ._.
B_NN ._.
Table_NNP extraction_NN using_VBG conditional_JJ random_JJ fields_NNS ._.
In_IN Proceedings_NNP of_IN the_DT 26th_JJ Annual_JJ International_NNP ACM_NNP SIGIR_NNP Conference_NNP on_IN Research_NNP and_CC Development_NNP in_IN Information_NNP Retrieval_NNP ,_, 235242_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_CD -RSB-_-RRB- Ratnaparkhi_NNP ,_, A_NNP ._.
Unsupervised_JJ statistical_JJ models_NNS for_IN prepositional_JJ phrase_NN attachment_NN ._.
In_IN Proceedings_NNP of_IN the_DT Seventeenth_NNP International_NNP Conference_NNP on_IN Computational_NNP Linguistics_NNP ._.
1079-1085_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Robertson_NNP ,_, S_NN ._.
,_, Zaragoza_NNP ,_, H_NN ._.
,_, and_CC Taylor_NNP ,_, M_NN ._.
Simple_JJ BM25_NN extension_NN to_TO multiple_JJ weighted_JJ fields_NNS ,_, In_IN Proceedings_NNP of_IN ACM_NNP Thirteenth_NNP Conference_NNP on_IN Information_NNP and_CC Knowledge_NNP Management_NNP ,_, 42-49_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_CD -RSB-_-RRB- Yi_NNP ,_, J_NNP ._.
and_CC Sundaresan_NNP ,_, N_NNP ._.
Metadata_NNP based_VBN Web_NN mining_NN for_IN relevance_NN ,_, In_IN Proceedings_NNP of_IN the_DT ####_NNP International_NNP Symposium_NNP on_IN Database_NNP Engineering_NNP &_CC Applications_NNS ,_, 113121_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Yilmazel_NN ,_, O_NN ._.
,_, Finneran_NNP ,_, C_NNP ._.
M_NN ._.
,_, and_CC Liddy_NNP ,_, E_NNP ._.
D_NN ._.
MetaExtract_NNP :_: An_DT NLP_NN system_NN to_TO automatically_RB assign_VB metadata_NN ._.
In_IN Proceedings_NNP of_IN the_DT ####_CD Joint_NNP ACM_NNP /_: IEEE_NNP Conference_NNP on_IN Digital_NNP Libraries_NNPS ,_, 241-242_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Zhang_NNP ,_, J_NNP ._.
and_CC Dimitroff_NNP ,_, A_NNP ._.
Internet_NNP search_NN engines_NNS '_POS response_NN to_TO metadata_VB Dublin_NNP Core_NNP implementation_NN ._.
Journal_NNP of_IN Information_NNP Science_NNP ,_, ##_CD :_: 310-320_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Zhang_NNP ,_, L_NNP ._.
,_, Pan_NNP ,_, Y_NN ._.
,_, and_CC Zhang_NNP ,_, T_NN ._.
Recognising_VBG and_CC using_VBG named_VBN entities_NNS :_: focused_VBD named_VBN entity_NN recognition_NN using_VBG machine_NN learning_NN ._.
In_IN Proceedings_NNP of_IN the_DT 27th_JJ Annual_JJ International_NNP ACM_NNP SIGIR_NNP Conference_NNP on_IN Research_NNP and_CC Development_NNP in_IN Information_NNP Retrieval_NNP ,_, 281-288_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- http_NN :_: /_: /_: dublincore_NN ._.
org_NN /_: groups_NNS /_: corporate_JJ /_: Seattle_NNP /_: 154_CD
