On_IN Opportunistic_JJ Techniques_NNS for_IN Solving_VBG Decentralized_NNP Markov_NNP Decision_NNP Processes_NNS with_IN Temporal_JJ Constraints_NNS Janusz_NNP Marecki_NNP and_CC Milind_NNP Tambe_NNP Computer_NNP Science_NNP Department_NNP University_NNP of_IN Southern_NNP California_NNP 941_CD W_NNP 37th_JJ Place_NN ,_, Los_NNP Angeles_NNP ,_, CA_NNP #####_NNP -LCB-_-LRB- marecki_NNS ,_, tambe_NN -RCB-_-RRB- @_IN usc_NN ._.
edu_NN ABSTRACT_NN Decentralized_JJ Markov_NNP Decision_NNP Processes_NNP -LRB-_-LRB- DEC-MDPs_NNS -RRB-_-RRB- are_VBP a_DT popular_JJ model_NN of_IN agent-coordination_JJ problems_NNS in_IN domains_NNS with_IN uncertainty_NN and_CC time_NN constraints_NNS but_CC very_RB difficult_JJ to_TO solve_VB ._.
In_IN this_DT paper_NN ,_, we_PRP improve_VBP a_DT state-of-the-art_JJ heuristic_NN solution_NN method_NN for_IN DEC-MDPs_NNS ,_, called_VBN OC-DEC-MDP_NN ,_, that_WDT has_VBZ recently_RB been_VBN shown_VBN to_TO scale_VB up_RP to_TO larger_JJR DEC-MDPs_NNS ._.
Our_PRP$ heuristic_NN solution_NN method_NN ,_, called_VBN Value_NNP Function_NN Propagation_NN -LRB-_-LRB- VFP_NN -RRB-_-RRB- ,_, combines_VBZ two_CD orthogonal_JJ improvements_NNS of_IN OC-DEC-MDP_NN ._.
First_RB ,_, it_PRP speeds_VBZ up_RP OC-DECMDP_NN by_IN an_DT order_NN of_IN magnitude_NN by_IN maintaining_VBG and_CC manipulating_VBG a_DT value_NN function_NN for_IN each_DT state_NN -LRB-_-LRB- as_IN a_DT function_NN of_IN time_NN -RRB-_-RRB- rather_RB than_IN a_DT separate_JJ value_NN for_IN each_DT pair_NN of_IN sate_NN and_CC time_NN interval_NN ._.
Furthermore_RB ,_, it_PRP achieves_VBZ better_JJR solution_NN qualities_NNS than_IN OC-DEC-MDP_NN because_IN ,_, as_IN our_PRP$ analytical_JJ results_NNS show_VBP ,_, it_PRP does_VBZ not_RB overestimate_VB the_DT expected_VBN total_JJ reward_NN like_IN OC-DEC_NN -_: MDP_NN ._.
We_PRP test_VBP both_DT improvements_NNS independently_RB in_IN a_DT crisis-management_NN domain_NN as_RB well_RB as_IN for_IN other_JJ types_NNS of_IN domains_NNS ._.
Our_PRP$ experimental_JJ results_NNS demonstrate_VBP a_DT significant_JJ speedup_NN of_IN VFP_NN over_IN OC-DEC-MDP_NN as_RB well_RB as_IN higher_JJR solution_NN qualities_NNS in_IN a_DT variety_NN of_IN situations_NNS ._.
Categories_NNS and_CC Subject_NNP Descriptors_NNS I_PRP ._.
#_# ._.
##_NN -LSB-_-LRB- Artificial_NNP Intelligence_NNP -RSB-_-RRB- :_: Distributed_VBN Artificial_NNP IntelligenceMulti-agent_NNP Systems_NNP General_NNP Terms_NNS Algorithms_NNS ,_, Theory_NNP 1_CD ._.
INTRODUCTION_NN The_DT development_NN of_IN algorithms_NNS for_IN effective_JJ coordination_NN of_IN multiple_JJ agents_NNS acting_VBG as_IN a_DT team_NN in_IN uncertain_JJ and_CC time_NN critical_JJ domains_NNS has_VBZ recently_RB become_VBN a_DT very_RB active_JJ research_NN field_NN with_IN potential_JJ applications_NNS ranging_VBG from_IN coordination_NN of_IN agents_NNS during_IN a_DT hostage_NN rescue_NN mission_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- to_TO the_DT coordination_NN of_IN Autonomous_NNP Mars_NNP Exploration_NNP Rovers_NNPS -LSB-_-LRB- #_# -RSB-_-RRB- ._.
Because_IN of_IN the_DT uncertain_JJ and_CC dynamic_JJ characteristics_NNS of_IN such_JJ domains_NNS ,_, decision-theoretic_JJ models_NNS have_VBP received_VBN a_DT lot_NN of_IN attention_NN in_IN recent_JJ years_NNS ,_, mainly_RB thanks_NNS to_TO their_PRP$ expressiveness_NN and_CC the_DT ability_NN to_TO reason_NN about_IN the_DT utility_NN of_IN actions_NNS over_IN time_NN ._.
Key_NN decision-theoretic_JJ models_NNS that_WDT have_VBP become_VBN popular_JJ in_IN the_DT literature_NN include_VBP Decentralized_NNP Markov_NNP Decision_NNP Processes_NNP -LRB-_-LRB- DECMDPs_NNS -RRB-_-RRB- and_CC Decentralized_JJ ,_, Partially_RB Observable_JJ Markov_NNP Decision_NNP Processes_NNP -LRB-_-LRB- DEC-POMDPs_NNS -RRB-_-RRB- ._.
Unfortunately_RB ,_, solving_VBG these_DT models_NNS optimally_RB has_VBZ been_VBN proven_VBN to_TO be_VB NEXP-complete_JJ -LSB-_-LRB- #_# -RSB-_-RRB- ,_, hence_RB more_RBR tractable_JJ subclasses_NNS of_IN these_DT models_NNS have_VBP been_VBN the_DT subject_NN of_IN intensive_JJ research_NN ._.
In_IN particular_JJ ,_, Network_NNP Distributed_VBD POMDP_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- which_WDT assume_VBP that_IN not_RB all_DT the_DT agents_NNS interact_VBP with_IN each_DT other_JJ ,_, Transition_NN Independent_NNP DEC-MDP_NN -LSB-_-LRB- #_# -RSB-_-RRB- which_WDT assume_VBP that_IN transition_NN function_NN is_VBZ decomposable_JJ into_IN local_JJ transition_NN functions_NNS or_CC DEC-MDP_NN with_IN Event_NNP Driven_NNP Interactions_NNS -LSB-_-LRB- #_# -RSB-_-RRB- which_WDT assume_VBP that_IN interactions_NNS between_IN agents_NNS happen_VB at_IN fixed_JJ time_NN points_NNS constitute_VBP good_JJ examples_NNS of_IN such_JJ subclasses_NNS ._.
Although_IN globally_RB optimal_JJ algorithms_NNS for_IN these_DT subclasses_NNS have_VBP demonstrated_VBN promising_JJ results_NNS ,_, domains_NNS on_IN which_WDT these_DT algorithms_NNS run_VBP are_VBP still_RB small_JJ and_CC time_NN horizons_NNS are_VBP limited_VBN to_TO only_RB a_DT few_JJ time_NN ticks_VBZ ._.
To_TO remedy_VB that_IN ,_, locally_RB optimal_JJ algorithms_NNS have_VBP been_VBN proposed_VBN -LSB-_-LRB- ##_CD -RSB-_-RRB- -LSB-_-LRB- #_# -RSB-_-RRB- -LSB-_-LRB- #_# -RSB-_-RRB- ._.
In_IN particular_JJ ,_, Opportunity_NNP Cost_NN DEC-MDP_NN -LSB-_-LRB- #_# -RSB-_-RRB- -LSB-_-LRB- #_# -RSB-_-RRB- ,_, referred_VBN to_TO as_IN OC-DEC-MDP_NN ,_, is_VBZ particularly_RB notable_JJ ,_, as_IN it_PRP has_VBZ been_VBN shown_VBN to_TO scale_VB up_RP to_TO domains_NNS with_IN hundreds_NNS of_IN tasks_NNS and_CC double_JJ digit_NN time_NN horizons_NNS ._.
Additionally_RB ,_, OC-DEC-MDP_NN is_VBZ unique_JJ in_IN its_PRP$ ability_NN to_TO address_VB both_CC temporal_JJ constraints_NNS and_CC uncertain_JJ method_NN execution_NN durations_NNS ,_, which_WDT is_VBZ an_DT important_JJ factor_NN for_IN real-world_JJ domains_NNS ._.
OC-DEC-MDP_NN is_VBZ able_JJ to_TO scale_VB up_RP to_TO such_JJ domains_NNS mainly_RB because_IN instead_RB of_IN searching_VBG for_IN the_DT globally_RB optimal_JJ solution_NN ,_, it_PRP carries_VBZ out_RP a_DT series_NN of_IN policy_NN iterations_NNS ;_: in_IN each_DT iteration_NN it_PRP performs_VBZ a_DT value_NN iteration_NN that_WDT reuses_VBZ the_DT data_NNS computed_VBN during_IN the_DT previous_JJ policy_NN iteration_NN ._.
However_RB ,_, OC-DEC-MDP_NN is_VBZ still_RB slow_JJ ,_, especially_RB as_IN the_DT time_NN horizon_NN and_CC the_DT number_NN of_IN methods_NNS approach_VBP large_JJ values_NNS ._.
The_DT reason_NN for_IN high_JJ runtimes_NNS of_IN OC-DEC-MDP_NN for_IN such_JJ domains_NNS is_VBZ a_DT consequence_NN of_IN its_PRP$ huge_JJ state_NN space_NN ,_, i_FW ._.
e_LS ._.
,_, OC-DEC-MDP_NN introduces_VBZ a_DT separate_JJ state_NN for_IN each_DT possible_JJ pair_NN of_IN method_NN and_CC method_NN execution_NN interval_NN ._.
Furthermore_RB ,_, OC-DEC-MDP_NN overestimates_VBZ the_DT reward_NN that_IN a_DT method_NN expects_VBZ to_TO receive_VB for_IN enabling_VBG the_DT execution_NN of_IN future_JJ methods_NNS ._.
This_DT reward_NN ,_, also_RB referred_VBN to_TO as_IN the_DT opportunity_NN cost_NN ,_, plays_VBZ a_DT crucial_JJ role_NN in_IN agent_NN decision_NN making_NN ,_, and_CC as_IN we_PRP show_VBP later_RB ,_, its_PRP$ overestimation_NN leads_VBZ to_TO highly_RB suboptimal_JJ policies_NNS ._.
In_IN this_DT context_NN ,_, we_PRP present_VBP VFP_NN -LRB-_-LRB- =_JJ Value_NN Function_NN P_NN ropagation_NN -RRB-_-RRB- ,_, an_DT efficient_JJ solution_NN technique_NN for_IN the_DT DEC-MDP_NN model_NN with_IN temporal_JJ constraints_NNS and_CC uncertain_JJ method_NN execution_NN durations_NNS ,_, that_IN builds_VBZ on_IN the_DT success_NN of_IN OC-DEC-MDP_NN ._.
VFP_NN introduces_VBZ our_PRP$ two_CD orthogonal_JJ ideas_NNS :_: First_NNP ,_, similarly_RB to_TO -LSB-_-LRB- #_# -RSB-_-RRB- -LSB-_-LRB- #_# -RSB-_-RRB- and_CC -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, we_PRP maintain_VBP 830_CD 978-81-904262-7-5_CD -LRB-_-LRB- RPS_NN -RRB-_-RRB- c_NN ####_CD IFAAMAS_NNP and_CC manipulate_VB a_DT value_NN function_NN over_IN time_NN for_IN each_DT method_NN rather_RB than_IN a_DT separate_JJ value_NN for_IN each_DT pair_NN of_IN method_NN and_CC time_NN interval_NN ._.
Such_JJ representation_NN allows_VBZ us_PRP to_TO group_VB the_DT time_NN points_NNS for_IN which_WDT the_DT value_NN function_NN changes_NNS at_IN the_DT same_JJ rate_NN -LRB-_-LRB- =_JJ its_PRP$ slope_NN is_VBZ constant_JJ -RRB-_-RRB- ,_, which_WDT results_VBZ in_IN fast_RB ,_, functional_JJ propagation_NN of_IN value_NN functions_NNS ._.
Second_RB ,_, we_PRP prove_VBP -LRB-_-LRB- both_CC theoretically_RB and_CC empirically_RB -RRB-_-RRB- that_WDT OC-DEC_NN -_: MDP_NN overestimates_VBZ the_DT opportunity_NN cost_NN ,_, and_CC to_TO remedy_VB that_IN ,_, we_PRP introduce_VBP a_DT set_NN of_IN heuristics_NNS ,_, that_IN correct_JJ the_DT opportunity_NN cost_NN overestimation_NN problem_NN ._.
This_DT paper_NN is_VBZ organized_VBN as_IN follows_VBZ :_: In_IN section_NN #_# we_PRP motivate_VBP this_DT research_NN by_IN introducing_VBG a_DT civilian_JJ rescue_NN domain_NN where_WRB a_DT team_NN of_IN fire_NN -_: brigades_NNS must_MD coordinate_VB in_IN order_NN to_TO rescue_NN civilians_NNS trapped_VBN in_IN a_DT burning_NN building_NN ._.
In_IN section_NN #_# we_PRP provide_VBP a_DT detailed_JJ description_NN of_IN our_PRP$ DEC-MDP_NN model_NN with_IN Temporal_JJ Constraints_NNS and_CC in_IN section_NN #_# we_PRP discuss_VBP how_WRB one_CD could_MD solve_VB the_DT problems_NNS encoded_VBN in_IN our_PRP$ model_NN using_VBG globally_RB optimal_JJ and_CC locally_RB optimal_JJ solvers_NNS ._.
Sections_NNS #_# and_CC 6_CD discuss_VBP the_DT two_CD orthogonal_JJ improvements_NNS to_TO the_DT state-of-the-art_JJ OC-DEC-MDP_NN algorithm_NN that_WDT our_PRP$ VFP_NN algorithm_NN implements_VBZ ._.
Finally_RB ,_, in_IN section_NN #_# we_PRP demonstrate_VBP empirically_RB the_DT impact_NN of_IN our_PRP$ two_CD orthogonal_JJ improvements_NNS ,_, i_FW ._.
e_LS ._.
,_, we_PRP show_VBP that_IN :_: -LRB-_-LRB- i_LS -RRB-_-RRB- The_DT new_JJ heuristics_NNS correct_VBP the_DT opportunity_NN cost_NN overestimation_NN problem_NN leading_VBG to_TO higher_JJR quality_NN policies_NNS ,_, and_CC -LRB-_-LRB- ii_LS -RRB-_-RRB- By_IN allowing_VBG for_IN a_DT systematic_JJ tradeoff_NN of_IN solution_NN quality_NN for_IN time_NN ,_, the_DT VFP_NNP algorithm_NN runs_VBZ much_JJ faster_JJR than_IN the_DT OC-DEC-MDP_NN algorithm_NN 2_CD ._.
MOTIVATING_VBG EXAMPLE_NN We_PRP are_VBP interested_JJ in_IN domains_NNS where_WRB multiple_JJ agents_NNS must_MD coordinate_VB their_PRP$ plans_NNS over_IN time_NN ,_, despite_IN uncertainty_NN in_IN plan_NN execution_NN duration_NN and_CC outcome_NN ._.
One_CD example_NN domain_NN is_VBZ large-scale_JJ disaster_NN ,_, like_IN a_DT fire_NN in_IN a_DT skyscraper_NN ._.
Because_IN there_EX can_MD be_VB hundreds_NNS of_IN civilians_NNS scattered_VBN across_IN numerous_JJ floors_NNS ,_, multiple_JJ rescue_NN teams_NNS have_VBP to_TO be_VB dispatched_VBN ,_, and_CC radio_NN communication_NN channels_NNS can_MD quickly_RB get_VB saturated_JJ and_CC useless_JJ ._.
In_IN particular_JJ ,_, small_JJ teams_NNS of_IN fire-brigades_NNS must_MD be_VB sent_VBN on_IN separate_JJ missions_NNS to_TO rescue_VB the_DT civilians_NNS trapped_VBN in_IN dozens_NNS of_IN different_JJ locations_NNS ._.
Picture_NNP a_DT small_JJ mission_NN plan_NN from_IN Figure_NN -LRB-_-LRB- #_# -RRB-_-RRB- ,_, where_WRB three_CD firebrigades_NNS have_VBP been_VBN assigned_VBN a_DT task_NN to_TO rescue_VB the_DT civilians_NNS trapped_VBN at_IN site_NN B_NN ,_, accessed_VBN from_IN site_NN A_NN -LRB-_-LRB- e_LS ._.
g_NN ._.
an_DT office_NN accessed_VBN from_IN the_DT floor_NN -RRB-_-RRB- #_# ._.
General_NNP fire_NN fighting_VBG procedures_NNS involve_VBP both_CC :_: -LRB-_-LRB- i_LS -RRB-_-RRB- putting_VBG out_RP the_DT flames_NNS ,_, and_CC -LRB-_-LRB- ii_LS -RRB-_-RRB- ventilating_VBG the_DT site_NN to_TO let_VB the_DT toxic_JJ ,_, high_JJ temperature_NN gases_NNS escape_VBP ,_, with_IN the_DT restriction_NN that_WDT ventilation_NN should_MD not_RB be_VB performed_VBN too_RB fast_RB in_IN order_NN to_TO prevent_VB the_DT fire_NN from_IN spreading_NN ._.
The_DT team_NN estimates_VBZ that_IN the_DT civilians_NNS have_VBP ##_VBN minutes_NNS before_IN the_DT fire_NN at_IN site_NN B_NN becomes_VBZ unbearable_JJ ,_, and_CC that_IN the_DT fire_NN at_IN site_NN A_NN has_VBZ to_TO be_VB put_VBN out_RP in_IN order_NN to_TO open_VB the_DT access_NN to_TO site_NN B_NN ._.
As_IN has_VBZ happened_VBN in_IN the_DT past_NN in_IN large_JJ scale_NN disasters_NNS ,_, communication_NN often_RB breaks_VBZ down_RP ;_: and_CC hence_RB we_PRP assume_VB in_IN this_DT domain_NN that_IN there_EX is_VBZ no_DT communication_NN between_IN the_DT fire-brigades_NNS #_# ,_, #_# and_CC #_# -LRB-_-LRB- denoted_VBN as_IN FB1_NN ,_, FB2_NN and_CC FB3_NN -RRB-_-RRB- ._.
Consequently_RB ,_, FB2_NN does_VBZ not_RB know_VB if_IN it_PRP is_VBZ already_RB safe_JJ to_TO ventilate_VB site_NN A_NN ,_, FB1_NN does_VBZ not_RB know_VB if_IN it_PRP is_VBZ already_RB safe_JJ to_TO enter_VB site_NN A_NN and_CC start_VB fighting_VBG fire_NN at_IN site_NN B_NN ,_, etc_FW ._.
We_PRP assign_VBP the_DT reward_NN ##_NN for_IN evacuating_VBG the_DT civilians_NNS from_IN site_NN B_NN ,_, and_CC a_DT smaller_JJR reward_NN ##_NN for_IN the_DT successful_JJ ventilation_NN of_IN site_NN A_NN ,_, since_IN the_DT civilians_NNS themselves_PRP might_MD succeed_VB in_IN breaking_VBG out_RP from_IN site_NN B_NN ._.
One_PRP can_MD clearly_RB see_VB the_DT dilemma_NN ,_, that_WDT FB2_NN faces_VBZ :_: It_PRP can_MD only_RB estimate_VB the_DT durations_NNS of_IN the_DT Fight_NN fire_NN at_IN site_NN A_DT methods_NNS to_TO be_VB executed_VBN by_IN FB1_NN and_CC FB3_NN ,_, and_CC at_IN the_DT same_JJ time_NN FB2_NN knows_VBZ that_IN time_NN is_VBZ running_VBG out_RP for_IN civilians_NNS ._.
If_IN FB2_NN ventilates_VBZ site_NN A_NN too_RB early_RB ,_, the_DT fire_NN will_MD spread_VB out_IN of_IN control_NN ,_, whereas_IN if_IN FB2_NN waits_VBZ with_IN the_DT ventilation_NN method_NN for_IN too_RB long_RB ,_, fire_NN at_IN site_NN B_NN will_MD become_VB unbearable_JJ for_IN the_DT civilians_NNS ._.
In_IN general_JJ ,_, agents_NNS have_VBP to_TO perform_VB a_DT sequence_NN of_IN such_JJ 1_CD We_PRP explain_VBP the_DT EST_NN and_CC LET_NN notation_NN in_IN section_NN #_# Figure_NNP #_# :_: Civilian_JJ rescue_NN domain_NN and_CC a_DT mission_NN plan_NN ._.
Dotted_VBN arrows_NNS represent_VBP implicit_JJ precedence_NN constraints_NNS within_IN an_DT agent_NN ._.
difficult_JJ decisions_NNS ;_: in_IN particular_JJ ,_, decision_NN process_NN of_IN FB2_NN involves_VBZ first_RB choosing_VBG when_WRB to_TO start_VB ventilating_VBG site_NN A_NN ,_, and_CC then_RB -LRB-_-LRB- depending_VBG on_IN the_DT time_NN it_PRP took_VBD to_TO ventilate_VB site_NN A_NN -RRB-_-RRB- ,_, choosing_VBG when_WRB to_TO start_VB evacuating_VBG the_DT civilians_NNS from_IN site_NN B_NN ._.
Such_JJ sequence_NN of_IN decisions_NNS constitutes_VBZ the_DT policy_NN of_IN an_DT agent_NN ,_, and_CC it_PRP must_MD be_VB found_VBN fast_RB because_IN time_NN is_VBZ running_VBG out_RP ._.
3_LS ._.
MODEL_NN DESCRIPTION_NN We_PRP encode_VBP our_PRP$ decision_NN problems_NNS in_IN a_DT model_NN which_WDT we_PRP refer_VBP to_TO as_IN Decentralized_JJ MDP_NN with_IN Temporal_JJ Constraints_NNS #_# ._.
Each_DT instance_NN of_IN our_PRP$ decision_NN problems_NNS can_MD be_VB described_VBN as_IN a_DT tuple_NN M_NN ,_, A_NN ,_, C_NN ,_, P_NN ,_, R_NN where_WRB M_NN =_JJ -LCB-_-LRB- mi_FW -RCB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# is_VBZ the_DT set_NN of_IN methods_NNS ,_, and_CC A_NN =_JJ -LCB-_-LRB- Ak_NN -RCB-_-RRB- |_CD A_DT |_NN k_NN =_JJ #_# is_VBZ the_DT set_NN of_IN agents_NNS ._.
Agents_NNS can_MD not_RB communicate_VB during_IN mission_NN execution_NN ._.
Each_DT agent_NN Ak_NN is_VBZ assigned_VBN to_TO a_DT set_VBN Mk_NN of_IN methods_NNS ,_, such_JJ that_IN S_NN |_CD A_DT |_NN k_NN =_JJ #_# Mk_NN =_JJ M_NN and_CC i_FW ,_, j_NN ;_: i_LS =_JJ jMi_NN Mj_NN =_JJ ._.
Also_RB ,_, each_DT method_NN of_IN agent_NN Ak_NN can_MD be_VB executed_VBN only_RB once_RB ,_, and_CC agent_NN Ak_NN can_MD execute_VB only_RB one_CD method_NN at_IN a_DT time_NN ._.
Method_NN execution_NN times_NNS are_VBP uncertain_JJ and_CC P_NN =_JJ -LCB-_-LRB- pi_NN -RCB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# is_VBZ the_DT set_NN of_IN distributions_NNS of_IN method_NN execution_NN durations_NNS ._.
In_IN particular_JJ ,_, pi_NN -LRB-_-LRB- t_NN -RRB-_-RRB- is_VBZ the_DT probability_NN that_IN the_DT execution_NN of_IN method_NN mi_NN consumes_VBZ time_NN t_NN ._.
C_NN is_VBZ a_DT set_NN of_IN temporal_JJ constraints_NNS in_IN the_DT system_NN ._.
Methods_NNS are_VBP partially_RB ordered_VBN and_CC each_DT method_NN has_VBZ fixed_VBN time_NN windows_NNS inside_IN which_WDT it_PRP can_MD be_VB executed_VBN ,_, i_FW ._.
e_LS ._.
,_, C_NN =_JJ C_NN C_NN -LSB-_-LRB- -RSB-_-RRB- where_WRB C_NN is_VBZ the_DT set_NN of_IN predecessor_NN constraints_NNS and_CC C_NN -LSB-_-LRB- -RSB-_-RRB- is_VBZ the_DT set_NN of_IN time_NN window_NN constraints_NNS ._.
For_IN c_NN C_NN ,_, c_NN =_JJ mi_FW ,_, mj_NN means_VBZ that_IN method_NN mi_NN precedes_VBZ method_NN mj_NN i_FW ._.
e_LS ._.
,_, execution_NN of_IN mj_NN can_MD not_RB start_VB before_IN mi_FW terminates_VBZ ._.
In_IN particular_JJ ,_, for_IN an_DT agent_NN Ak_NN ,_, all_DT its_PRP$ methods_NNS form_VBP a_DT chain_NN linked_VBN by_IN predecessor_NN constraints_NNS ._.
We_PRP assume_VBP ,_, that_IN the_DT graph_NN G_NN =_JJ M_NN ,_, C_NN is_VBZ acyclic_JJ ,_, does_VBZ not_RB have_VB disconnected_VBN nodes_NNS -LRB-_-LRB- the_DT problem_NN can_MD not_RB be_VB decomposed_VBN into_IN independent_JJ subproblems_NNS -RRB-_-RRB- ,_, and_CC its_PRP$ source_NN and_CC sink_NN vertices_NNS identify_VBP the_DT source_NN and_CC sink_NN methods_NNS of_IN the_DT system_NN ._.
For_IN c_NN C_NN -LSB-_-LRB- -RSB-_-RRB- ,_, c_NN =_JJ mi_FW ,_, EST_NNP ,_, LET_NNP means_VBZ that_IN execution_NN of_IN mi_FW can_MD only_RB start_VB after_IN the_DT Earliest_JJS Starting_VBG Time_NNP EST_NNP and_CC must_MD finish_VB before_IN the_DT Latest_JJS End_NN Time_NNP LET_NNP ;_: we_PRP allow_VBP methods_NNS to_TO have_VB multiple_JJ disjoint_NN time_NN window_NN constraints_NNS ._.
Although_IN distributions_NNS pi_NN can_MD extend_VB to_TO infinite_JJ time_NN horizons_NNS ,_, given_VBN the_DT time_NN window_NN constraints_NNS ,_, the_DT planning_NN horizon_NN =_JJ max_NN m_NN ,_, ,_, C_NN -LSB-_-LRB- -RSB-_-RRB- is_VBZ considered_VBN as_IN the_DT mission_NN deadline_NN ._.
Finally_RB ,_, R_NN =_JJ -LCB-_-LRB- ri_NN -RCB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# is_VBZ the_DT set_NN of_IN non-negative_JJ rewards_NNS ,_, i_FW ._.
e_LS ._.
,_, ri_NN is_VBZ obtained_VBN upon_IN successful_JJ execution_NN of_IN mi_FW ._.
Since_IN there_EX is_VBZ no_DT communication_NN allowed_VBN ,_, an_DT agent_NN can_MD only_RB estimate_VB the_DT probabilities_NNS that_IN its_PRP$ methods_NNS have_VBP already_RB been_VBN enabled_VBN 2_CD One_CD could_MD also_RB use_VB the_DT OC-DEC-MDP_NN framework_NN ,_, which_WDT models_NNS both_CC time_NN and_CC resource_NN constraints_NNS The_DT Sixth_NNP Intl_NNP ._.
Joint_NNP Conf_NNP ._.
on_IN Autonomous_NNP Agents_NNPS and_CC Multi-Agent_NNP Systems_NNP -LRB-_-LRB- AAMAS_NNP ##_CD -RRB-_-RRB- ###_CD by_IN other_JJ agents_NNS ._.
Consequently_RB ,_, if_IN mj_NN Mk_NN is_VBZ the_DT next_JJ method_NN to_TO be_VB executed_VBN by_IN the_DT agent_NN Ak_NN and_CC the_DT current_JJ time_NN is_VBZ t_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- ,_, the_DT agent_NN has_VBZ to_TO make_VB a_DT decision_NN whether_IN to_TO Execute_VB the_DT method_NN mj_NN -LRB-_-LRB- denoted_VBN as_IN E_NN -RRB-_-RRB- ,_, or_CC to_TO Wait_VB -LRB-_-LRB- denoted_VBN as_IN W_NN -RRB-_-RRB- ._.
In_IN case_NN agent_NN Ak_NN decides_VBZ to_TO wait_VB ,_, it_PRP remains_VBZ idle_JJ for_IN an_DT arbitrary_JJ small_JJ time_NN ,_, and_CC resumes_VBZ operation_NN at_IN the_DT same_JJ place_NN -LRB-_-LRB- =_JJ about_IN to_TO execute_VB method_NN mj_NN -RRB-_-RRB- at_IN time_NN t_NN +_CC ._.
In_IN case_NN agent_NN Ak_NN decides_VBZ to_TO Execute_VB the_DT next_JJ method_NN ,_, two_CD outcomes_NNS are_VBP possible_JJ :_: Success_NN :_: The_DT agent_NN Ak_NN receives_VBZ reward_NN rj_NN and_CC moves_NNS on_IN to_TO its_PRP$ next_JJ method_NN -LRB-_-LRB- if_IN such_JJ method_NN exists_VBZ -RRB-_-RRB- so_RB long_RB as_IN the_DT following_JJ conditions_NNS hold_VBP :_: -LRB-_-LRB- i_LS -RRB-_-RRB- All_PDT the_DT methods_NNS -LCB-_-LRB- mi_FW |_FW mi_FW ,_, mj_NN C_NN -RCB-_-RRB- that_WDT directly_RB enable_VBP method_NN mj_NN have_VBP already_RB been_VBN completed_VBN ,_, -LRB-_-LRB- ii_LS -RRB-_-RRB- Execution_NN of_IN method_NN mj_NN started_VBD in_IN some_DT time_NN window_NN of_IN method_NN mj_NN ,_, i_FW ._.
e_LS ._.
,_, mj_NN ,_, ,_, C_NN -LSB-_-LRB- -RSB-_-RRB- such_JJ that_IN t_NN -LSB-_-LRB- ,_, -RSB-_-RRB- ,_, and_CC -LRB-_-LRB- iii_LS -RRB-_-RRB- Execution_NN of_IN method_NN mj_NN finished_VBD inside_IN the_DT same_JJ time_NN window_NN ,_, i_FW ._.
e_LS ._.
,_, agent_NN Ak_NN completed_VBD method_NN mj_NN in_IN time_NN less_RBR than_IN or_CC equal_JJ to_TO t_NN ._.
Failure_NN :_: If_IN any_DT of_IN the_DT above-mentioned_JJ conditions_NNS does_VBZ not_RB hold_VB ,_, agent_NN Ak_NN stops_VBZ its_PRP$ execution_NN ._.
Other_JJ agents_NNS may_MD continue_VB their_PRP$ execution_NN ,_, but_CC methods_NNS mk_NN -LCB-_-LRB- m_NN |_CD mj_NN ,_, m_NN C_NN -RCB-_-RRB- will_MD never_RB become_VB enabled_VBN ._.
The_DT policy_NN k_NN of_IN an_DT agent_NN Ak_NN is_VBZ a_DT function_NN k_NN :_: Mk_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- -LCB-_-LRB- W_NN ,_, E_NN -RCB-_-RRB- ,_, and_CC k_NN -LRB-_-LRB- m_NN ,_, t_NN -RRB-_-RRB- =_JJ a_DT means_NN ,_, that_IN if_IN Ak_NN is_VBZ at_IN method_NN m_NN at_IN time_NN t_NN ,_, it_PRP will_MD choose_VB to_TO perform_VB the_DT action_NN a_DT ._.
A_DT joint_JJ policy_NN =_JJ -LSB-_-LRB- k_NN -RSB-_-RRB- |_CD A_DT |_NN k_NN =_JJ #_# is_VBZ considered_VBN to_TO be_VB optimal_JJ -LRB-_-LRB- denoted_VBN as_IN -RRB-_-RRB- ,_, if_IN it_PRP maximizes_VBZ the_DT sum_NN of_IN expected_VBN rewards_NNS for_IN all_PDT the_DT agents_NNS ._.
4_LS ._.
SOLUTION_NN TECHNIQUES_NNS 4_CD ._.
#_# Optimal_JJ Algorithms_NNS Optimal_JJ joint_JJ policy_NN is_VBZ usually_RB found_VBN by_IN using_VBG the_DT Bellman_NNP update_VBP principle_NN ,_, i_FW ._.
e_LS ._.
,_, in_IN order_NN to_TO determine_VB the_DT optimal_JJ policy_NN for_IN method_NN mj_NN ,_, optimal_JJ policies_NNS for_IN methods_NNS mk_NN -LCB-_-LRB- m_NN |_CD mj_NN ,_, m_NN C_NN -RCB-_-RRB- are_VBP used_VBN ._.
Unfortunately_RB ,_, for_IN our_PRP$ model_NN ,_, the_DT optimal_JJ policy_NN for_IN method_NN mj_NN also_RB depends_VBZ on_IN policies_NNS for_IN methods_NNS mi_FW -LCB-_-LRB- m_NN |_CD m_NN ,_, mj_NN C_NN -RCB-_-RRB- ._.
This_DT double_JJ dependency_NN results_VBZ from_IN the_DT fact_NN ,_, that_IN the_DT expected_VBN reward_NN for_IN starting_VBG the_DT execution_NN of_IN method_NN mj_NN at_IN time_NN t_NN also_RB depends_VBZ on_IN the_DT probability_NN that_WDT method_NN mj_NN will_MD be_VB enabled_VBN by_IN time_NN t_NN ._.
Consequently_RB ,_, if_IN time_NN is_VBZ discretized_VBN ,_, one_CD needs_VBZ to_TO consider_VB |_CD M_NN |_CD candidate_NN policies_NNS in_IN order_NN to_TO find_VB ._.
Thus_RB ,_, globally_RB optimal_JJ algorithms_NNS used_VBN for_IN solving_VBG real-world_JJ problems_NNS are_VBP unlikely_JJ to_TO terminate_VB in_IN reasonable_JJ time_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
The_DT complexity_NN of_IN our_PRP$ model_NN could_MD be_VB reduced_VBN if_IN we_PRP considered_VBD its_PRP$ more_JJR restricted_JJ version_NN ;_: in_IN particular_JJ ,_, if_IN each_DT method_NN mj_NN was_VBD allowed_VBN to_TO be_VB enabled_VBN at_IN time_NN points_NNS t_NN Tj_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- ,_, the_DT Coverage_NNP Set_VB Algorithm_NN -LRB-_-LRB- CSA_NN -RRB-_-RRB- -LSB-_-LRB- #_# -RSB-_-RRB- could_MD be_VB used_VBN ._.
However_RB ,_, CSA_NNP complexity_NN is_VBZ double_JJ exponential_JJ in_IN the_DT size_NN of_IN Ti_NNP ,_, and_CC for_IN our_PRP$ domains_NNS Tj_NNP can_MD store_VB all_DT values_NNS ranging_VBG from_IN #_# to_TO ._.
4_LS ._.
#_# Locally_RB Optimal_JJ Algorithms_NNS Following_VBG the_DT limited_JJ applicability_NN of_IN globally_RB optimal_JJ algorithms_NNS for_IN DEC-MDPs_NNS with_IN Temporal_JJ Constraints_NNS ,_, locally_RB optimal_JJ algorithms_NNS appear_VBP more_JJR promising_JJ ._.
Specially_RB ,_, the_DT OC-DEC-MDP_NN algorithm_NN -LSB-_-LRB- #_# -RSB-_-RRB- is_VBZ particularly_RB significant_JJ ,_, as_IN it_PRP has_VBZ shown_VBN to_TO easily_RB scale_VB up_RP to_TO domains_NNS with_IN hundreds_NNS of_IN methods_NNS ._.
The_DT idea_NN of_IN the_DT OC-DECMDP_NN algorithm_NN is_VBZ to_TO start_VB with_IN the_DT earliest_JJS starting_VBG time_NN policy_NN #_# -LRB-_-LRB- according_VBG to_TO which_WDT an_DT agent_NN will_MD start_VB executing_VBG the_DT method_NN m_NN as_RB soon_RB as_IN m_NN has_VBZ a_DT non-zero_JJ chance_NN of_IN being_VBG already_RB enabled_VBD -RRB-_-RRB- ,_, and_CC then_RB improve_VB it_PRP iteratively_RB ,_, until_IN no_DT further_JJ improvement_NN is_VBZ possible_JJ ._.
At_IN each_DT iteration_NN ,_, the_DT algorithm_NN starts_VBZ with_IN some_DT policy_NN ,_, which_WDT uniquely_RB determines_VBZ the_DT probabilities_NNS Pi_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- that_WDT method_NN mi_NN will_MD be_VB performed_VBN in_IN the_DT time_NN interval_JJ -LSB-_-LRB- ,_, -RSB-_-RRB- ._.
It_PRP then_RB performs_VBZ two_CD steps_NNS :_: Step_VB #_# :_: It_PRP propagates_VBZ from_IN sink_NN methods_NNS to_TO source_NN methods_NNS the_DT values_NNS Vi_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- ,_, that_WDT represent_VBP the_DT expected_VBN utility_NN for_IN executing_VBG method_NN mi_NN in_IN the_DT time_NN interval_JJ -LSB-_-LRB- ,_, -RSB-_-RRB- ._.
This_DT propagation_NN uses_VBZ the_DT probabilities_NNS Pi_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- from_IN previous_JJ algorithm_NN iteration_NN ._.
We_PRP call_VBP this_DT step_NN a_DT value_NN propagation_NN phase_NN ._.
Step_NN #_# :_: Given_VBN the_DT values_NNS Vi_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- from_IN Step_NN #_# ,_, the_DT algorithm_NN chooses_VBZ the_DT most_RBS profitable_JJ method_NN execution_NN intervals_NNS which_WDT are_VBP stored_VBN in_IN a_DT new_JJ policy_NN ._.
It_PRP then_RB propagates_VBZ the_DT new_JJ probabilities_NNS Pi_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- from_IN source_NN methods_NNS to_TO sink_VB methods_NNS ._.
We_PRP call_VBP this_DT step_NN a_DT probability_NN propagation_NN phase_NN ._.
If_IN policy_NN does_VBZ not_RB improve_VB ,_, the_DT algorithm_NN terminates_VBZ ._.
There_EX are_VBP two_CD shortcomings_NNS of_IN the_DT OC-DEC-MDP_NN algorithm_NN that_IN we_PRP address_VBP in_IN this_DT paper_NN ._.
First_RB ,_, each_DT of_IN OC-DEC-MDP_NN states_NNS is_VBZ a_DT pair_NN mj_NN ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- ,_, where_WRB -LSB-_-LRB- ,_, -RSB-_-RRB- is_VBZ a_DT time_NN interval_NN in_IN which_WDT method_NN mj_NN can_MD be_VB executed_VBN ._.
While_IN such_JJ state_NN representation_NN is_VBZ beneficial_JJ ,_, in_IN that_IN the_DT problem_NN can_MD be_VB solved_VBN with_IN a_DT standard_JJ value_NN iteration_NN algorithm_NN ,_, it_PRP blurs_VBZ the_DT intuitive_JJ mapping_NN from_IN time_NN t_NN to_TO the_DT expected_VBN total_JJ reward_NN for_IN starting_VBG the_DT execution_NN of_IN mj_NN at_IN time_NN t_NN ._.
Consequently_RB ,_, if_IN some_DT method_NN mi_NN enables_VBZ method_NN mj_NN ,_, and_CC the_DT values_NNS Vj_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- ,_, -LSB-_-LRB- #_# ,_, -RSB-_-RRB- are_VBP known_VBN ,_, the_DT operation_NN that_WDT calculates_VBZ the_DT values_NNS Vi_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- ,_, -LSB-_-LRB- #_# ,_, -RSB-_-RRB- -LRB-_-LRB- during_IN the_DT value_NN propagation_NN phase_NN -RRB-_-RRB- ,_, runs_VBZ in_IN time_NN O_NN -LRB-_-LRB- I2_NN -RRB-_-RRB- ,_, where_WRB I_PRP is_VBZ the_DT number_NN of_IN time_NN intervals_NNS #_# ._.
Since_IN the_DT runtime_NN of_IN the_DT whole_JJ algorithm_NN is_VBZ proportional_JJ to_TO the_DT runtime_NN of_IN this_DT operation_NN ,_, especially_RB for_IN big_JJ time_NN horizons_NNS ,_, the_DT OC_NNP -_: DECMDP_NN algorithm_NN runs_VBZ slow_JJ ._.
Second_RB ,_, while_IN OC-DEC-MDP_NN emphasizes_VBZ on_IN precise_JJ calculation_NN of_IN values_NNS Vj_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- ,_, it_PRP fails_VBZ to_TO address_VB a_DT critical_JJ issue_NN that_WDT determines_VBZ how_WRB the_DT values_NNS Vj_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- are_VBP split_JJ given_VBN that_IN the_DT method_NN mj_NN has_VBZ multiple_JJ enabling_VBG methods_NNS ._.
As_IN we_PRP show_VBP later_RB ,_, OC-DEC-MDP_NN splits_VBZ Vj_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- into_IN parts_NNS that_WDT may_MD overestimate_VB Vj_NNP ,_, -LSB-_-LRB- ,_, -RSB-_-RRB- when_WRB summed_VBN up_RP again_RB ._.
As_IN a_DT result_NN ,_, methods_NNS that_WDT precede_VBP the_DT method_NN mj_NN overestimate_VBP the_DT value_NN for_IN enabling_VBG mj_NN which_WDT ,_, as_IN we_PRP show_VBP later_RB ,_, can_MD have_VB disastrous_JJ consequences_NNS ._.
In_IN the_DT next_JJ two_CD sections_NNS ,_, we_PRP address_VBP both_DT of_IN these_DT shortcomings_NNS ._.
5_CD ._.
VALUE_NN FUNCTION_NN PROPAGATION_NN -LRB-_-LRB- VFP_NN -RRB-_-RRB- The_DT general_JJ scheme_NN of_IN the_DT VFP_NN algorithm_NN is_VBZ identical_JJ to_TO the_DT OCDEC-MDP_NN algorithm_NN ,_, in_IN that_IN it_PRP performs_VBZ a_DT series_NN of_IN policy_NN improvement_NN iterations_NNS ,_, each_DT one_CD involving_VBG a_DT Value_NN and_CC Probability_NN Propagation_NN Phase_NN ._.
However_RB ,_, instead_RB of_IN propagating_VBG separate_JJ values_NNS ,_, VFP_NN maintains_VBZ and_CC propagates_VBZ the_DT whole_JJ functions_NNS ,_, we_PRP therefore_RB refer_VBP to_TO these_DT phases_NNS as_IN the_DT value_NN function_NN propagation_NN phase_NN and_CC the_DT probability_NN function_NN propagation_NN phase_NN ._.
To_TO this_DT end_NN ,_, for_IN each_DT method_NN mi_NN M_NN ,_, we_PRP define_VBP three_CD new_JJ functions_NNS :_: Value_NNP Function_NN ,_, denoted_VBN as_IN vi_LS -LRB-_-LRB- t_NN -RRB-_-RRB- ,_, that_WDT maps_VBZ time_NN t_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- to_TO the_DT expected_VBN total_JJ reward_NN for_IN starting_VBG the_DT execution_NN of_IN method_NN mi_NN at_IN time_NN t_NN ._.
Opportunity_NNP Cost_NN Function_NN ,_, denoted_VBN as_IN Vi_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- ,_, that_WDT maps_VBZ time_NN t_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- to_TO the_DT expected_VBN total_JJ reward_NN for_IN starting_VBG the_DT execution_NN of_IN method_NN mi_NN at_IN time_NN t_NN assuming_VBG that_IN mi_FW is_VBZ enabled_VBN ._.
Probability_NN Function_NN ,_, denoted_VBN as_IN Pi_NN -LRB-_-LRB- t_NN -RRB-_-RRB- ,_, that_WDT maps_VBZ time_NN t_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- to_TO the_DT probability_NN that_WDT method_NN mi_NN will_MD be_VB completed_VBN before_IN time_NN t_NN ._.
Such_JJ functional_JJ representation_NN allows_VBZ us_PRP to_TO easily_RB read_VB the_DT current_JJ policy_NN ,_, i_FW ._.
e_LS ._.
,_, if_IN an_DT agent_NN Ak_NN is_VBZ at_IN method_NN mi_NN at_IN time_NN t_NN ,_, then_RB it_PRP will_MD wait_VB as_RB long_RB as_IN value_NN function_NN vi_LS -LRB-_-LRB- t_NN -RRB-_-RRB- will_MD be_VB greater_JJR in_IN the_DT future_NN ._.
Formally_RB :_: k_NN -LRB-_-LRB- mi_FW ,_, t_NN -RRB-_-RRB- =_JJ j_NN W_NN if_IN t_NN >_JJR t_NN such_JJ that_IN vi_LS -LRB-_-LRB- t_NN -RRB-_-RRB- <_JJR vi_LS -LRB-_-LRB- t_NN -RRB-_-RRB- E_NN otherwise_RB ._.
We_PRP now_RB develop_VBP an_DT analytical_JJ technique_NN for_IN performing_VBG the_DT value_NN function_NN and_CC probability_NN function_NN propagation_NN phases_NNS ._.
3_CD Similarly_RB for_IN the_DT probability_NN propagation_NN phase_NN 832_CD The_DT Sixth_NNP Intl_NNP ._.
Joint_NNP Conf_NNP ._.
on_IN Autonomous_NNP Agents_NNPS and_CC Multi-Agent_NNP Systems_NNP -LRB-_-LRB- AAMAS_NNP ##_CD -RRB-_-RRB- 5_CD ._.
#_# Value_NNP Function_NN Propagation_NN Phase_NN Suppose_VB ,_, that_IN we_PRP are_VBP performing_VBG a_DT value_NN function_NN propagation_NN phase_NN during_IN which_WDT the_DT value_NN functions_NNS are_VBP propagated_VBN from_IN the_DT sink_NN methods_NNS to_TO the_DT source_NN methods_NNS ._.
At_IN any_DT time_NN during_IN this_DT phase_NN we_PRP encounter_VBP a_DT situation_NN shown_VBN in_IN Figure_NNP #_# ,_, where_WRB opportunity_NN cost_NN functions_NNS -LSB-_-LRB- Vjn_NN -RSB-_-RRB- N_NN n_NN =_JJ #_# of_IN methods_NNS -LSB-_-LRB- mjn_NN -RSB-_-RRB- N_NN n_NN =_JJ #_# are_VBP known_VBN ,_, and_CC the_DT opportunity_NN cost_NN Vi0_NN of_IN method_NN mi0_NN is_VBZ to_TO be_VB derived_VBN ._.
Let_VB pi0_NN be_VB the_DT probability_NN distribution_NN function_NN of_IN method_NN mi0_NN execution_NN duration_NN ,_, and_CC ri0_NN be_VB the_DT immediate_JJ reward_NN for_IN starting_VBG and_CC completing_VBG the_DT execution_NN of_IN method_NN mi0_NN inside_IN a_DT time_NN interval_JJ -LSB-_-LRB- ,_, -RSB-_-RRB- such_JJ that_IN mi0_NN ,_, C_NN -LSB-_-LRB- -RSB-_-RRB- ._.
The_DT function_NN Vi0_NN is_VBZ then_RB derived_VBN from_IN ri0_NN and_CC opportunity_NN costs_NNS Vjn_NNP ,_, i0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- n_NN =_JJ #_# ,_, ..._: ,_, N_NN from_IN future_JJ methods_NNS ._.
Formally_RB :_: Vi0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ 8_CD >_JJR >_JJR <_JJR >_JJR >_JJR :_: R_NN t_NN 0_CD pi0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- -LRB-_-LRB- ri0_NN +_CC PN_NN n_NN =_JJ #_# Vjn_NNP ,_, i0_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- -RRB-_-RRB- dt_NN if_IN mi0_NN ,_, C_NN -LSB-_-LRB- -RSB-_-RRB- such_JJ that_IN t_NN -LSB-_-LRB- ,_, -RSB-_-RRB- 0_CD otherwise_RB -LRB-_-LRB- #_# -RRB-_-RRB- Note_NN ,_, that_IN for_IN t_NN -LSB-_-LRB- ,_, -RSB-_-RRB- ,_, if_IN h_NN -LRB-_-LRB- t_NN -RRB-_-RRB- :_: =_JJ ri0_NN +_CC PN_NN n_NN =_JJ #_# Vjn_NNP ,_, i0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- then_RB Vi0_NN is_VBZ a_DT convolution_NN of_IN p_NN and_CC h_NN :_: vi0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ -LRB-_-LRB- pi0_NN h_NN -RRB-_-RRB- -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
Assume_VB for_IN now_RB ,_, that_IN Vjn_NNP ,_, i0_NN represents_VBZ a_DT full_JJ opportunity_NN cost_NN ,_, postponing_VBG the_DT discussion_NN on_IN different_JJ techniques_NNS for_IN splitting_NN the_DT opportunity_NN cost_NN Vj0_NN into_IN -LSB-_-LRB- Vj0_NN ,_, ik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# until_IN section_NN #_# ._.
We_PRP now_RB show_VBP how_WRB to_TO derive_VB Vj0_NN ,_, i0_NN -LRB-_-LRB- derivation_NN of_IN Vjn_NNP ,_, i0_NN for_IN n_NN =_JJ #_# follows_VBZ the_DT same_JJ scheme_NN -RRB-_-RRB- ._.
Figure_NNP #_# :_: Fragment_NN of_IN an_DT MDP_NN of_IN agent_NN Ak_NN ._.
Probability_NN functions_VBZ propagate_VB forward_RB -LRB-_-LRB- left_VBN to_TO right_NN -RRB-_-RRB- whereas_IN value_NN functions_NNS propagate_VBP backward_RB -LRB-_-LRB- right_NN to_TO left_NN -RRB-_-RRB- ._.
Let_VB V_NNP j0_NN ,_, i0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- be_VB the_DT opportunity_NN cost_NN of_IN starting_VBG the_DT execution_NN of_IN method_NN mj0_NN at_IN time_NN t_NN given_VBN that_IN method_NN mi0_NN has_VBZ been_VBN completed_VBN ._.
It_PRP is_VBZ derived_VBN by_IN multiplying_VBG Vi0_NN by_IN the_DT probability_NN functions_NNS of_IN all_DT methods_NNS other_JJ than_IN mi0_NN that_WDT enable_VBP mj0_NN ._.
Formally_RB :_: V_NN j0_NN ,_, i0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- KY_NN k_NN =_JJ #_# Pik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
Where_WRB similarly_RB to_TO -LSB-_-LRB- #_# -RSB-_-RRB- and_CC -LSB-_-LRB- #_# -RSB-_-RRB- we_PRP ignored_VBD the_DT dependency_NN of_IN -LSB-_-LRB- Plk_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# ._.
Observe_VB that_DT V_NN j0_NN ,_, i0_NN does_VBZ not_RB have_VB to_TO be_VB monotonically_RB decreasing_VBG ,_, i_FW ._.
e_LS ._.
,_, delaying_VBG the_DT execution_NN of_IN the_DT method_NN mi0_NN can_MD sometimes_RB be_VB profitable_JJ ._.
Therefore_RB the_DT opportunity_NN cost_NN Vj0_NN ,_, i0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- of_IN enabling_VBG method_NN mi0_NN at_IN time_NN t_NN must_MD be_VB greater_JJR than_IN or_CC equal_JJ to_TO V_NN j0_NN ,_, i0_NN ._.
Furthermore_RB ,_, Vj0_NN ,_, i0_NN should_MD be_VB non-increasing_JJ ._.
Formally_RB :_: Vj0_NN ,_, i0_NN =_JJ min_NN fF_NN f_FW -LRB-_-LRB- #_# -RRB-_-RRB- Where_WRB F_NN =_JJ -LCB-_-LRB- f_FW |_FW f_FW V_NN j0_NN ,_, i0_NN and_CC f_FW -LRB-_-LRB- t_NN -RRB-_-RRB- f_FW -LRB-_-LRB- t_NN -RRB-_-RRB- t_NN <_JJR t_NN -RCB-_-RRB- ._.
Knowing_VBG the_DT opportunity_NN cost_NN Vi0_NN ,_, we_PRP can_MD then_RB easily_RB derive_VB the_DT value_NN function_NN vi0_NN ._.
Let_VB Ak_NNP be_VB an_DT agent_NN assigned_VBN to_TO the_DT method_NN mi0_NN ._.
If_IN Ak_NNP is_VBZ about_IN to_TO start_VB the_DT execution_NN of_IN mi0_CD it_PRP means_VBZ ,_, that_IN Ak_NNP must_MD have_VB completed_VBN its_PRP$ part_NN of_IN the_DT mission_NN plan_NN up_IN to_TO the_DT method_NN mi0_NN ._.
Since_IN Ak_NN does_VBZ not_RB know_VB if_IN other_JJ agents_NNS have_VBP completed_VBN methods_NNS -LSB-_-LRB- mlk_NN -RSB-_-RRB- k_NN =_JJ K_NN k_NN =_JJ #_# ,_, in_IN order_NN to_TO derive_VB vi0_NN ,_, it_PRP has_VBZ to_TO multiply_VB Vi0_NN by_IN the_DT probability_NN functions_NNS of_IN all_DT methods_NNS of_IN other_JJ agents_NNS that_WDT enable_VBP mi0_NN ._.
Formally_RB :_: vi0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ Vi0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- KY_NN k_NN =_JJ #_# Plk_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Where_WRB the_DT dependency_NN of_IN -LSB-_-LRB- Plk_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# is_VBZ also_RB ignored_VBN ._.
We_PRP have_VBP consequently_RB shown_VBN a_DT general_JJ scheme_NN how_WRB to_TO propagate_VB the_DT value_NN functions_NNS :_: Knowing_VBG -LSB-_-LRB- vjn_NN -RSB-_-RRB- N_NN n_NN =_JJ #_# and_CC -LSB-_-LRB- Vjn_NN -RSB-_-RRB- N_NN n_NN =_JJ #_# of_IN methods_NNS -LSB-_-LRB- mjn_NN -RSB-_-RRB- N_NN n_NN =_JJ #_# we_PRP can_MD derive_VB vi0_NN and_CC Vi0_NN of_IN method_NN mi0_NN ._.
In_IN general_JJ ,_, the_DT value_NN function_NN propagation_NN scheme_NN starts_VBZ with_IN sink_NN nodes_NNS ._.
It_PRP then_RB visits_VBZ at_IN each_DT time_NN a_DT method_NN m_NN ,_, such_JJ that_IN all_PDT the_DT methods_NNS that_WDT m_NN enables_VBZ have_VBP already_RB been_VBN marked_VBN as_IN visited_VBN ._.
The_DT value_NN function_NN propagation_NN phase_NN terminates_VBZ when_WRB all_PDT the_DT source_NN methods_NNS have_VBP been_VBN marked_VBN as_IN visited_VBN ._.
5_CD ._.
#_# Reading_VBG the_DT Policy_NN In_IN order_NN to_TO determine_VB the_DT policy_NN of_IN agent_NN Ak_NN for_IN the_DT method_NN mj0_NN we_PRP must_MD identify_VB the_DT set_NN Zj0_NN of_IN intervals_NNS -LSB-_-LRB- z_SYM ,_, z_SYM -RSB-_-RRB- -LSB-_-LRB- #_# ,_, ..._: ,_, -RSB-_-RRB- ,_, such_JJ that_IN :_: t_NN -LSB-_-LRB- z_SYM ,_, z_SYM -RSB-_-RRB- k_NN -LRB-_-LRB- mj0_NN ,_, t_NN -RRB-_-RRB- =_JJ W_NN ._.
One_PRP can_MD easily_RB identify_VB the_DT intervals_NNS of_IN Zj0_NN by_IN looking_VBG at_IN the_DT time_NN intervals_NNS in_IN which_WDT the_DT value_NN function_NN vj0_NN does_VBZ not_RB decrease_VB monotonically_RB ._.
5_CD ._.
#_# Probability_NNP Function_NN Propagation_NN Phase_NN Assume_VB now_RB ,_, that_IN value_NN functions_NNS and_CC opportunity_NN cost_NN values_NNS have_VBP all_DT been_VBN propagated_VBN from_IN sink_NN methods_NNS to_TO source_NN nodes_NNS and_CC the_DT sets_NNS Zj_NN for_IN all_DT methods_NNS mj_VBP M_NN have_VBP been_VBN identified_VBN ._.
Since_IN value_NN function_NN propagation_NN phase_NN was_VBD using_VBG probabilities_NNS Pi_NN -LRB-_-LRB- t_NN -RRB-_-RRB- for_IN methods_NNS mi_FW M_NN and_CC times_NNS t_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- found_VBN at_IN previous_JJ algorithm_NN iteration_NN ,_, we_PRP now_RB have_VBP to_TO find_VB new_JJ values_NNS Pi_NN -LRB-_-LRB- t_NN -RRB-_-RRB- ,_, in_IN order_NN to_TO prepare_VB the_DT algorithm_NN for_IN its_PRP$ next_JJ iteration_NN ._.
We_PRP now_RB show_VBP how_WRB in_IN the_DT general_JJ case_NN -LRB-_-LRB- Figure_NN #_# -RRB-_-RRB- propagate_VB the_DT probability_NN functions_VBZ forward_RB through_IN one_CD method_NN ,_, i_FW ._.
e_LS ._.
,_, we_PRP assume_VBP that_IN the_DT probability_NN functions_VBZ -LSB-_-LRB- Pik_NNP -RSB-_-RRB- K_NNP k_NN =_JJ #_# of_IN methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# are_VBP known_VBN ,_, and_CC the_DT probability_NN function_NN Pj0_NN of_IN method_NN mj0_NN must_MD be_VB derived_VBN ._.
Let_VB pj0_NN be_VB the_DT probability_NN distribution_NN function_NN of_IN method_NN mj0_NN execution_NN duration_NN ,_, and_CC Zj0_NN be_VB the_DT set_NN of_IN intervals_NNS of_IN inactivity_NN for_IN method_NN mj0_NN ,_, found_VBN during_IN the_DT last_JJ value_NN function_NN propagation_NN phase_NN ._.
If_IN we_PRP ignore_VBP the_DT dependency_NN of_IN -LSB-_-LRB- Pik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# then_RB the_DT probability_NN Pj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- that_IN the_DT execution_NN of_IN method_NN mj0_NN starts_VBZ before_IN time_NN t_NN is_VBZ given_VBN by_IN :_: Pj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ -LRB-_-LRB- QK_JJ k_NN =_JJ #_# Pik_NNP -LRB-_-LRB- -RRB-_-RRB- if_IN -LRB-_-LRB- ,_, -RRB-_-RRB- Zj0_NN s_NNS ._.
t_NN ._.
t_NN -LRB-_-LRB- ,_, -RRB-_-RRB- QK_NN k_NN =_JJ #_# Pik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- otherwise_RB ._.
Given_VBN Pj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- ,_, the_DT probability_NN Pj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- that_WDT method_NN mj0_NN will_MD be_VB completed_VBN by_IN time_NN t_NN is_VBZ derived_VBN by_IN :_: Pj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ Z_NN t_NN 0_CD Z_NN t_NN 0_CD -LRB-_-LRB- Pj0_NN t_NN -RRB-_-RRB- -LRB-_-LRB- t_NN -RRB-_-RRB- pj0_NN -LRB-_-LRB- t_NN t_NN -RRB-_-RRB- dt_NN dt_NN -LRB-_-LRB- #_# -RRB-_-RRB- Which_WDT can_MD be_VB written_VBN compactly_RB as_IN Pj0_NN t_NN =_JJ pj0_NN P_NN j0_NN t_NN ._.
We_PRP have_VBP consequently_RB shown_VBN how_WRB to_TO propagate_VB the_DT probability_NN functions_VBZ -LSB-_-LRB- Pik_NNP -RSB-_-RRB- K_NNP k_NN =_JJ #_# of_IN methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# to_TO obtain_VB the_DT probability_NN function_NN Pj0_NN of_IN method_NN mj0_NN ._.
The_DT general_JJ ,_, the_DT probability_NN function_NN propagation_NN phase_NN starts_VBZ with_IN source_NN methods_NNS msi_NNS for_IN which_WDT we_PRP know_VBP that_IN Psi_NN =_JJ #_# since_IN they_PRP are_VBP enabled_VBN by_IN default_NN ._.
We_PRP then_RB visit_VB at_IN each_DT time_NN a_DT method_NN m_NN such_JJ that_IN all_PDT the_DT methods_NNS that_WDT enable_VBP The_DT Sixth_NNP Intl_NNP ._.
Joint_NNP Conf_NNP ._.
on_IN Autonomous_NNP Agents_NNPS and_CC Multi-Agent_NNP Systems_NNP -LRB-_-LRB- AAMAS_NNP ##_CD -RRB-_-RRB- ###_CD m_NN have_VBP already_RB been_VBN marked_VBN as_IN visited_VBN ._.
The_DT probability_NN function_NN propagation_NN phase_NN terminates_VBZ when_WRB all_PDT the_DT sink_NN methods_NNS have_VBP been_VBN marked_VBN as_IN visited_VBN ._.
5_CD ._.
#_# The_DT Algorithm_NNP Similarly_RB to_TO the_DT OC-DEC-MDP_NN algorithm_NN ,_, VFP_NN starts_VBZ the_DT policy_NN improvement_NN iterations_NNS with_IN the_DT earliest_JJS starting_VBG time_NN policy_NN #_# ._.
Then_RB at_IN each_DT iteration_NN it_PRP :_: -LRB-_-LRB- i_LS -RRB-_-RRB- Propagates_VBZ the_DT value_NN functions_VBZ -LSB-_-LRB- vi_LS -RSB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# using_VBG the_DT old_JJ probability_NN functions_NNS -LSB-_-LRB- Pi_NN -RSB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# from_IN previous_JJ algorithm_NN iteration_NN and_CC establishes_VBZ the_DT new_JJ sets_NNS -LSB-_-LRB- Zi_NN -RSB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# of_IN method_NN inactivity_NN intervals_NNS ,_, and_CC -LRB-_-LRB- ii_LS -RRB-_-RRB- propagates_VBZ the_DT new_JJ probability_NN functions_NNS -LSB-_-LRB- Pi_NN -RSB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# using_VBG the_DT newly_RB established_VBN sets_NNS -LSB-_-LRB- Zi_NN -RSB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# ._.
These_DT new_JJ functions_NNS -LSB-_-LRB- Pi_NN -RSB-_-RRB- |_CD M_NN |_CD i_FW =_JJ #_# are_VBP then_RB used_VBN in_IN the_DT next_JJ iteration_NN of_IN the_DT algorithm_NN ._.
Similarly_RB to_TO OC-DEC-MDP_NN ,_, VFP_NN terminates_VBZ if_IN a_DT new_JJ policy_NN does_VBZ not_RB improve_VB the_DT policy_NN from_IN the_DT previous_JJ algorithm_NN iteration_NN ._.
5_CD ._.
#_# Implementation_NN of_IN Function_NN Operations_NNP So_RB far_RB ,_, we_PRP have_VBP derived_VBN the_DT functional_JJ operations_NNS for_IN value_NN function_NN and_CC probability_NN function_NN propagation_NN without_IN choosing_VBG any_DT function_NN representation_NN ._.
In_IN general_JJ ,_, our_PRP$ functional_JJ operations_NNS can_MD handle_VB continuous_JJ time_NN ,_, and_CC one_CD has_VBZ freedom_NN to_TO choose_VB a_DT desired_VBN function_NN approximation_NN technique_NN ,_, such_JJ as_IN piecewise_JJ linear_JJ -LSB-_-LRB- #_# -RSB-_-RRB- or_CC piecewise_JJ constant_JJ -LSB-_-LRB- #_# -RSB-_-RRB- approximation_NN ._.
However_RB ,_, since_IN one_CD of_IN our_PRP$ goals_NNS is_VBZ to_TO compare_VB VFP_NN with_IN the_DT existing_VBG OC-DEC_NN -_: MDP_NN algorithm_NN ,_, that_WDT works_VBZ only_RB for_IN discrete_JJ time_NN ,_, we_PRP also_RB discretize_VBP time_NN ,_, and_CC choose_VB to_TO approximate_JJ value_NN functions_NNS and_CC probability_NN functions_NNS with_IN piecewise_JJ linear_NN -LRB-_-LRB- PWL_NN -RRB-_-RRB- functions_NNS ._.
When_WRB the_DT VFP_NN algorithm_NN propagates_VBZ the_DT value_NN functions_NNS and_CC probability_NN functions_NNS ,_, it_PRP constantly_RB carries_VBZ out_RP operations_NNS represented_VBN by_IN equations_NNS -LRB-_-LRB- #_# -RRB-_-RRB- and_CC -LRB-_-LRB- #_# -RRB-_-RRB- and_CC we_PRP have_VBP already_RB shown_VBN that_IN these_DT operations_NNS are_VBP convolutions_NNS of_IN some_DT functions_NNS p_NN -LRB-_-LRB- t_NN -RRB-_-RRB- and_CC h_NN -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
If_IN time_NN is_VBZ discretized_VBN ,_, functions_VBZ p_NN -LRB-_-LRB- t_NN -RRB-_-RRB- and_CC h_NN -LRB-_-LRB- t_NN -RRB-_-RRB- are_VBP discrete_JJ ;_: however_RB ,_, h_NN -LRB-_-LRB- t_NN -RRB-_-RRB- can_MD be_VB nicely_RB approximated_VBN with_IN a_DT PWL_NN function_NN bh_NN -LRB-_-LRB- t_NN -RRB-_-RRB- ,_, which_WDT is_VBZ exactly_RB what_WP VFP_NN does_VBZ ._.
As_IN a_DT result_NN ,_, instead_RB of_IN performing_VBG O_NN -LRB-_-LRB- #_# -RRB-_-RRB- multiplications_NNS to_TO compute_VB f_FW -LRB-_-LRB- t_NN -RRB-_-RRB- ,_, VFP_NN only_RB needs_VBZ to_TO perform_VB O_NN -LRB-_-LRB- k_NN -RRB-_-RRB- multiplications_NNS to_TO compute_VB f_FW -LRB-_-LRB- t_NN -RRB-_-RRB- ,_, where_WRB k_NN is_VBZ the_DT number_NN of_IN linear_JJ segments_NNS of_IN bh_NN -LRB-_-LRB- t_NN -RRB-_-RRB- -LRB-_-LRB- note_NN ,_, that_WDT since_IN h_NN -LRB-_-LRB- t_NN -RRB-_-RRB- is_VBZ monotonic_JJ ,_, bh_NN -LRB-_-LRB- t_NN -RRB-_-RRB- is_VBZ usually_RB close_JJ to_TO h_NN -LRB-_-LRB- t_NN -RRB-_-RRB- with_IN k_NN -RRB-_-RRB- ._.
Since_IN Pi_NN values_NNS are_VBP in_IN range_NN -LSB-_-LRB- #_# ,_, #_# -RSB-_-RRB- and_CC Vi_NNP values_NNS are_VBP in_IN range_NN -LSB-_-LRB- #_# ,_, P_NN miM_NNP ri_NN -RSB-_-RRB- ,_, we_PRP suggest_VBP to_TO approximate_JJ Vi_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- with_IN bVi_NN -LRB-_-LRB- t_NN -RRB-_-RRB- within_IN error_NN V_NN ,_, and_CC Pi_NN -LRB-_-LRB- t_NN -RRB-_-RRB- with_IN bPi_NN -LRB-_-LRB- t_NN -RRB-_-RRB- within_IN error_NN P_NN ._.
We_PRP now_RB prove_VBP that_IN the_DT overall_JJ approximation_NN error_NN accumulated_VBN during_IN the_DT value_NN function_NN propagation_NN phase_NN can_MD be_VB expressed_VBN in_IN terms_NNS of_IN P_NN and_CC V_NN :_: THEOREM_NNP #_# ._.
Let_VB C_NNP be_VB a_DT set_NN of_IN precedence_NN constraints_NNS of_IN a_DT DEC-MDP_NN with_IN Temporal_JJ Constraints_NNS ,_, and_CC P_NN and_CC V_NN be_VB the_DT probability_NN function_NN and_CC value_NN function_NN approximation_NN errors_NNS respectively_RB ._.
The_DT overall_JJ error_NN =_JJ maxV_NN supt_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- |_CD V_NN -LRB-_-LRB- t_NN -RRB-_-RRB- bV_NN -LRB-_-LRB- t_NN -RRB-_-RRB- |_NN of_IN value_NN function_NN propagation_NN phase_NN is_VBZ then_RB bounded_VBN by_IN :_: |_CD C_NN |_CD V_NN +_CC -LRB-_-LRB- -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- |_NN C_NN |_CD #_# -RRB-_-RRB- P_NN miM_NNP ri_NNP ._.
PROOF_NN ._.
In_IN order_NN to_TO establish_VB the_DT bound_VBN for_IN ,_, we_PRP first_RB prove_VBP by_IN induction_NN on_IN the_DT size_NN of_IN C_NN ,_, that_IN the_DT overall_JJ error_NN of_IN probability_NN function_NN propagation_NN phase_NN ,_, -LRB-_-LRB- P_NN -RRB-_-RRB- =_JJ maxP_NN supt_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- |_CD P_NN -LRB-_-LRB- t_NN -RRB-_-RRB- bP_NN -LRB-_-LRB- t_NN -RRB-_-RRB- |_NN is_VBZ bounded_VBN by_IN -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- |_NN C_NN |_CD #_# ._.
Induction_NN base_NN :_: If_IN n_NN =_JJ #_# only_RB two_CD methods_NNS are_VBP present_JJ ,_, and_CC we_PRP will_MD perform_VB the_DT operation_NN identified_VBN by_IN Equation_NN -LRB-_-LRB- #_# -RRB-_-RRB- only_RB once_RB ,_, introducing_VBG the_DT error_NN -LRB-_-LRB- P_NN -RRB-_-RRB- =_JJ P_NN =_JJ -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- |_NN C_NN |_CD #_# ._.
Induction_NN step_NN :_: Suppose_VB ,_, that_WDT -LRB-_-LRB- P_NN -RRB-_-RRB- for_IN |_CD C_NN |_NN =_JJ n_NN is_VBZ bounded_VBN by_IN -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- n_NN #_# ,_, and_CC we_PRP want_VBP to_TO prove_VB that_IN this_DT statement_NN holds_VBZ for_IN |_CD C_NN |_NN =_JJ n_NN ._.
Let_VB G_NN =_JJ M_NN ,_, C_NN be_VB a_DT graph_NN with_IN at_IN most_JJS n_NN +_CC #_# edges_NNS ,_, and_CC G_NN =_JJ M_NN ,_, C_NN be_VB a_DT subgraph_NN of_IN G_NN ,_, such_JJ that_IN C_NN =_JJ C_NN -LCB-_-LRB- mi_NN ,_, mj_NN -RCB-_-RRB- ,_, where_WRB mj_NN M_NN is_VBZ a_DT sink_NN node_NN in_IN G_NN ._.
From_IN the_DT induction_NN assumption_NN we_PRP have_VBP ,_, that_IN C_NN introduces_VBZ the_DT probability_NN propagation_NN phase_NN error_NN bounded_VBN by_IN -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- n_NN #_# ._.
We_PRP now_RB add_VBP back_RP the_DT link_NN -LCB-_-LRB- mi_NN ,_, mj_NN -RCB-_-RRB- to_TO C_NN ,_, which_WDT affects_VBZ the_DT error_NN of_IN only_RB one_CD probability_NN function_NN ,_, namely_RB Pj_NNP ,_, by_IN a_DT factor_NN of_IN -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- ._.
Since_IN probability_NN propagation_NN phase_NN error_NN in_IN C_NN was_VBD bounded_VBN by_IN -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- n_NN #_# ,_, in_IN C_NN =_JJ C_NN -LCB-_-LRB- mi_NN ,_, mj_NN -RCB-_-RRB- it_PRP can_MD be_VB at_IN most_JJS -LRB-_-LRB- -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- n_NN #_# -RRB-_-RRB- -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- <_JJR -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- n_NN +_CC #_# #_# ._.
Thus_RB ,_, if_IN opportunity_NN cost_NN functions_NNS are_VBP not_RB overestimated_VBN ,_, they_PRP are_VBP bounded_VBN by_IN P_NN miM_NN ri_NN and_CC the_DT error_NN of_IN a_DT single_JJ value_NN function_NN propagation_NN operation_NN will_MD be_VB at_IN most_JJS Z_NN 0_CD p_NN -LRB-_-LRB- t_NN -RRB-_-RRB- -LRB-_-LRB- V_NN +_CC -LRB-_-LRB- -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- |_CD C_NN |_NN 1_CD -RRB-_-RRB- X_NN miM_NN ri_NN -RRB-_-RRB- dt_NN <_JJR V_NN +_CC -LRB-_-LRB- -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- |_CD C_NN |_NN 1_CD -RRB-_-RRB- X_NN miM_NNP ri_NNP ._.
Since_IN the_DT number_NN of_IN value_NN function_NN propagation_NN operations_NNS is_VBZ |_CD C_NN |_NN ,_, the_DT total_JJ error_NN of_IN the_DT value_NN function_NN propagation_NN phase_NN is_VBZ bounded_VBN by_IN :_: |_CD C_NN |_CD V_NN +_CC -LRB-_-LRB- -LRB-_-LRB- #_# +_CC P_NN -RRB-_-RRB- |_NN C_NN |_CD #_# -RRB-_-RRB- P_NN miM_NNP ri_NNP ._.
6_CD ._.
SPLITTING_VBG THE_DT OPPORTUNITY_NN COST_NN FUNCTIONS_NNS In_IN section_NN #_# we_PRP left_VBD out_RP the_DT discussion_NN about_IN how_WRB the_DT opportunity_NN cost_NN function_NN Vj0_NN of_IN method_NN mj0_NN is_VBZ split_VBN into_IN opportunity_NN cost_NN functions_NNS -LSB-_-LRB- Vj0_NN ,_, ik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# sent_VBD back_RB to_TO methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# ,_, that_WDT directly_RB enable_VBP method_NN mj0_NN ._.
So_RB far_RB ,_, we_PRP have_VBP taken_VBN the_DT same_JJ approach_NN as_IN in_IN -LSB-_-LRB- #_# -RSB-_-RRB- and_CC -LSB-_-LRB- #_# -RSB-_-RRB- in_IN that_IN the_DT opportunity_NN cost_NN function_NN Vj0_NN ,_, ik_NN that_IN the_DT method_NN mik_NN sends_VBZ back_RB to_TO the_DT method_NN mj0_NN is_VBZ a_DT minimal_JJ ,_, non-increasing_JJ function_NN that_WDT dominates_VBZ function_NN V_NN j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ -LRB-_-LRB- Vj0_JJ Q_NNP k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pik_NNP -RRB-_-RRB- -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
We_PRP refer_VBP to_TO this_DT approach_NN ,_, as_IN heuristic_NN H_NN #_# ,_, #_# ._.
Before_IN we_PRP prove_VBP that_IN this_DT heuristic_NN overestimates_VBZ the_DT opportunity_NN cost_NN ,_, we_PRP discuss_VBP three_CD problems_NNS that_WDT might_MD occur_VB when_WRB splitting_NN the_DT opportunity_NN cost_NN functions_NNS :_: -LRB-_-LRB- i_LS -RRB-_-RRB- overestimation_NN ,_, -LRB-_-LRB- ii_LS -RRB-_-RRB- underestimation_NN and_CC -LRB-_-LRB- iii_LS -RRB-_-RRB- starvation_NN ._.
Consider_VB the_DT situation_NN in_IN Figure_NNP Figure_NNP #_# :_: Splitting_VBG the_DT value_NN function_NN of_IN method_NN mj0_NN among_IN methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# ._.
-LRB-_-LRB- #_# -RRB-_-RRB- when_WRB value_NN function_NN propagation_NN for_IN methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# is_VBZ performed_VBN ._.
For_IN each_DT k_NN =_JJ #_# ,_, ..._: ,_, K_NNP ,_, Equation_NN -LRB-_-LRB- #_# -RRB-_-RRB- derives_VBZ the_DT opportunity_NN cost_NN function_NN Vik_NNP from_IN immediate_JJ reward_NN rk_NN and_CC opportunity_NN cost_NN function_NN Vj0_NN ,_, ik_NN ._.
If_IN m0_NN is_VBZ the_DT only_JJ methods_NNS that_WDT precedes_VBZ method_NN mk_NN ,_, then_RB V_NN ik_NN ,_, #_# =_SYM Vik_NNP is_VBZ propagated_VBN to_TO method_NN m0_NN ,_, and_CC consequently_RB the_DT opportunity_NN cost_NN for_IN completing_VBG the_DT method_NN m0_NN at_IN time_NN t_NN is_VBZ equal_JJ to_TO PK_NN k_NN =_JJ #_# Vik_NNP ,_, #_# -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
If_IN this_DT cost_NN is_VBZ overestimated_VBN ,_, then_RB an_DT agent_NN A0_NN at_IN method_NN m0_NN will_MD have_VB too_RB much_JJ incentive_NN to_TO finish_VB the_DT execution_NN of_IN m0_NN at_IN time_NN t_NN ._.
Consequently_RB ,_, although_IN the_DT probability_NN P_NN -LRB-_-LRB- t_NN -RRB-_-RRB- that_WDT m0_NN will_MD be_VB enabled_VBN by_IN other_JJ agents_NNS by_IN time_NN t_NN is_VBZ low_JJ ,_, agent_NN A0_NN might_MD still_RB find_VB the_DT expected_VBN utility_NN of_IN starting_VBG the_DT execution_NN of_IN m0_NN at_IN time_NN t_NN higher_JJR than_IN the_DT expected_VBN utility_NN of_IN doing_VBG it_PRP later_RB ._.
As_IN a_DT result_NN ,_, it_PRP will_MD choose_VB at_IN time_NN t_NN to_TO start_VB executing_VBG method_NN m0_NN instead_RB of_IN waiting_VBG ,_, which_WDT can_MD have_VB disastrous_JJ consequences_NNS ._.
Similarly_RB ,_, if_IN PK_NN k_NN =_JJ #_# Vik_NNP ,_, #_# -LRB-_-LRB- t_NN -RRB-_-RRB- is_VBZ underestimated_VBN ,_, agent_NN A0_NN might_MD loose_VB interest_NN in_IN enabling_VBG the_DT future_JJ methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# and_CC just_RB focus_VB on_IN 834_CD The_DT Sixth_NNP Intl_NNP ._.
Joint_NNP Conf_NNP ._.
on_IN Autonomous_NNP Agents_NNPS and_CC Multi-Agent_NNP Systems_NNP -LRB-_-LRB- AAMAS_NNP ##_CD -RRB-_-RRB- maximizing_VBG the_DT chance_NN of_IN obtaining_VBG its_PRP$ immediate_JJ reward_NN r0_NN ._.
Since_IN this_DT chance_NN is_VBZ increased_VBN when_WRB agent_NN A0_NN waits4_NN ,_, it_PRP will_MD consider_VB at_IN time_NN t_NN to_TO be_VB more_RBR profitable_JJ to_TO wait_VB ,_, instead_RB of_IN starting_VBG the_DT execution_NN of_IN m0_NN ,_, which_WDT can_MD have_VB similarly_RB disastrous_JJ consequences_NNS ._.
Finally_RB ,_, if_IN Vj0_NN is_VBZ split_VBN in_IN a_DT way_NN ,_, that_IN for_IN some_DT k_NN ,_, Vj0_NN ,_, ik_NN =_JJ #_# ,_, it_PRP is_VBZ the_DT method_NN mik_NN that_WDT underestimates_VBZ the_DT opportunity_NN cost_NN of_IN enabling_VBG method_NN mj0_NN ,_, and_CC the_DT similar_JJ reasoning_NN applies_VBZ ._.
We_PRP call_VBP such_JJ problem_NN a_DT starvation_NN of_IN method_NN mk_NN ._.
That_DT short_JJ discussion_NN shows_VBZ the_DT importance_NN of_IN splitting_NN the_DT opportunity_NN cost_NN function_NN Vj0_NN in_IN such_JJ a_DT way_NN ,_, that_WDT overestimation_NN ,_, underestimation_NN ,_, and_CC starvation_NN problem_NN is_VBZ avoided_VBN ._.
We_PRP now_RB prove_VBP that_IN :_: THEOREM_NNP #_# ._.
Heuristic_JJ H_NN #_# ,_, #_# can_MD overestimate_VB the_DT opportunity_NN cost_NN ._.
PROOF_NN ._.
We_PRP prove_VBP the_DT theorem_NN by_IN showing_VBG a_DT case_NN where_WRB the_DT overestimation_NN occurs_VBZ ._.
For_IN the_DT mission_NN plan_NN from_IN Figure_NN -LRB-_-LRB- #_# -RRB-_-RRB- ,_, let_VB H_NN #_# ,_, #_# split_VBD Vj0_NN into_IN -LSB-_-LRB- V_NN j0_NN ,_, ik_NN =_JJ Vj0_NN Q_NNP k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# sent_VBN to_TO methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# respectively_RB ._.
Also_RB ,_, assume_VB that_DT methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# provide_VBP no_DT local_JJ reward_NN and_CC have_VBP the_DT same_JJ time_NN windows_NNS ,_, i_FW ._.
e_LS ._.
,_, rik_NN =_JJ #_# ;_: ESTik_NN =_JJ #_# ,_, LETik_NN =_JJ for_IN k_NN =_JJ #_# ,_, ..._: ,_, K_NNP ._.
To_TO prove_VB the_DT overestimation_NN of_IN opportunity_NN cost_NN ,_, we_PRP must_MD identify_VB t0_NN -LSB-_-LRB- #_# ,_, ..._: ,_, -RSB-_-RRB- such_JJ that_IN the_DT opportunity_NN cost_NN PK_NN k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- for_IN methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# at_IN time_NN t_NN -LSB-_-LRB- #_# ,_, ._. ._.
,_, -RSB-_-RRB- is_VBZ greater_JJR than_IN the_DT opportunity_NN cost_NN Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
From_IN Equation_NN -LRB-_-LRB- #_# -RRB-_-RRB- we_PRP have_VBP :_: Vik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN ,_, ik_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN Summing_NN over_IN all_DT methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# we_PRP obtain_VB :_: KX_NNP k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ KX_NN k_NN =_JJ #_# Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN ,_, ik_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN -LRB-_-LRB- #_# -RRB-_-RRB- KX_NN k_NN =_JJ #_# Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- V_NN j0_NN ,_, ik_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN =_JJ KX_NN k_NN =_JJ #_# Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- Y_NN k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pik_NNP -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN Let_VB c_NN -LRB-_-LRB- #_# ,_, #_# -RSB-_-RRB- be_VB a_DT constant_JJ and_CC t0_NN -LSB-_-LRB- #_# ,_, -RSB-_-RRB- be_VB such_JJ that_IN t_NN >_JJR t0_NN and_CC k_NN =_JJ #_# ,_, ._. ._.
,_, K_NN we_PRP have_VBP Q_NNP k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- >_JJR c_NN ._.
Then_RB :_: KX_NN k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t0_NN -RRB-_-RRB- >_JJR KX_NN k_NN =_JJ #_# Z_NN t0_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN -LRB-_-LRB- t0_NN +_CC t_NN -RRB-_-RRB- c_NN dt_NN Because_IN Pjk_NN is_VBZ non-decreasing_JJ ._.
Now_RB ,_, suppose_VBP there_EX exists_VBZ t1_NN -LRB-_-LRB- t0_NN ,_, -RSB-_-RRB- ,_, such_JJ that_IN PK_NN k_NN =_JJ #_# R_NN t1t0_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- dt_NN >_JJR Vj0_NN -LRB-_-LRB- t0_NN -RRB-_-RRB- cVj0_NN -LRB-_-LRB- t1_NN -RRB-_-RRB- ._.
Since_IN decreasing_VBG the_DT upper_JJ limit_NN of_IN the_DT integral_JJ over_IN positive_JJ function_NN also_RB decreases_VBZ the_DT integral_JJ ,_, we_PRP have_VBP :_: KX_NN k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t0_NN -RRB-_-RRB- >_JJR c_NN KX_NN k_NN =_JJ #_# Z_NN t1_NN t0_NN pik_NN -LRB-_-LRB- t_NN t0_NN -RRB-_-RRB- Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- dt_NN And_CC since_IN Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- is_VBZ non-increasing_JJ we_PRP have_VBP :_: KX_NN k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t0_NN -RRB-_-RRB- >_JJR c_NN Vj0_NN -LRB-_-LRB- t1_NN -RRB-_-RRB- KX_NN k_NN =_JJ #_# Z_NN t1_NN t0_NN pik_NN -LRB-_-LRB- t_NN t0_NN -RRB-_-RRB- dt_NN -LRB-_-LRB- #_# -RRB-_-RRB- =_JJ c_NN Vj0_NN -LRB-_-LRB- t1_NN -RRB-_-RRB- KX_NN k_NN =_JJ #_# Z_NN t1t0_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- dt_NN >_JJR c_NN Vj0_NN -LRB-_-LRB- t1_NN -RRB-_-RRB- Vj_NN -LRB-_-LRB- t0_NN -RRB-_-RRB- c_NN Vj_NN -LRB-_-LRB- t1_NN -RRB-_-RRB- =_JJ Vj_NN -LRB-_-LRB- t0_NN -RRB-_-RRB- 4_CD Assuming_VBG LET0_NN t_NN Consequently_RB ,_, the_DT opportunity_NN cost_NN PK_NN k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t0_NN -RRB-_-RRB- of_IN starting_VBG the_DT execution_NN of_IN methods_NNS -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# at_IN time_NN t_NN -LSB-_-LRB- #_# ,_, ._. ._.
,_, -RSB-_-RRB- is_VBZ greater_JJR than_IN the_DT opportunity_NN cost_NN Vj0_NN -LRB-_-LRB- t0_NN -RRB-_-RRB- which_WDT proves_VBZ the_DT theorem_NN ._.
Figure_NNP 4_CD shows_NNS that_IN the_DT overestimation_NN of_IN opportunity_NN cost_NN is_VBZ easily_RB observable_JJ in_IN practice_NN ._.
To_TO remedy_VB the_DT problem_NN of_IN opportunity_NN cost_NN overestimation_NN ,_, we_PRP propose_VBP three_CD alternative_JJ heuristics_NNS that_WDT split_VBD the_DT opportunity_NN cost_NN functions_NNS :_: Heuristic_JJ H_NN #_# ,_, #_# :_: Only_RB one_CD method_NN ,_, mik_NN gets_VBZ the_DT full_JJ expected_VBN reward_NN for_IN enabling_VBG method_NN mj0_NN ,_, i_FW ._.
e_LS ._.
,_, V_NN j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ #_# for_IN k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- \_RB -LCB-_-LRB- k_NN -RCB-_-RRB- and_CC V_NN j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ -LRB-_-LRB- Vj0_JJ Q_NNP k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pik_NNP -RRB-_-RRB- -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
Heuristic_JJ H_NN #_# /_: #_# ,_, #_# /_: #_# :_: Each_DT method_NN -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# gets_VBZ the_DT full_JJ opportunity_NN cost_NN for_IN enabling_VBG method_NN mj0_NN divided_VBN by_IN the_DT number_NN K_NN of_IN methods_NNS enabling_VBG the_DT method_NN mj0_NN ,_, i_FW ._.
e_LS ._.
,_, V_NN j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ 1_CD K_NN -LRB-_-LRB- Vj0_NN Q_NNP k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pik_NNP -RRB-_-RRB- -LRB-_-LRB- t_NN -RRB-_-RRB- for_IN k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- ._.
Heuristic_JJ bH_NN #_# ,_, #_# :_: This_DT is_VBZ a_DT normalized_VBN version_NN of_IN the_DT H_NN #_# ,_, #_# heuristic_NN in_IN that_DT each_DT method_NN -LSB-_-LRB- mik_NN -RSB-_-RRB- K_NN k_NN =_JJ #_# initially_RB gets_VBZ the_DT full_JJ opportunity_NN cost_NN for_IN enabling_VBG the_DT method_NN mj0_NN ._.
To_TO avoid_VB opportunity_NN cost_NN overestimation_NN ,_, we_PRP normalize_VBP the_DT split_JJ functions_NNS when_WRB their_PRP$ sum_NN exceeds_VBZ the_DT opportunity_NN cost_NN function_NN to_TO be_VB split_VBN ._.
Formally_RB :_: V_NN j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ 8_CD >_JJR <_JJR >_JJR :_: V_NN H_NN #_# ,_, #_# j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- if_IN PK_NN k_NN =_JJ #_# V_NN H_NN #_# ,_, #_# j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- <_JJR Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- V_NN H_NN #_# ,_, #_# j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- PK_NN k_NN =_JJ #_# V_NN H_NN #_# ,_, #_# j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- otherwise_RB Where_WRB V_NN H_NN #_# ,_, #_# j0_NN ,_, ik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ -LRB-_-LRB- Vj0_JJ Q_NNP k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pjk_NN -RRB-_-RRB- -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
For_IN the_DT new_JJ heuristics_NNS ,_, we_PRP now_RB prove_VBP ,_, that_DT :_: THEOREM_NNP #_# ._.
Heuristics_NNS H_NN #_# ,_, #_# ,_, H_NN #_# /_: #_# ,_, #_# /_: #_# and_CC bH_NN #_# ,_, #_# do_VBP not_RB overestimate_VB the_DT opportunity_NN cost_NN ._.
PROOF_NN ._.
When_WRB heuristic_NN H_NN #_# ,_, #_# is_VBZ used_VBN to_TO split_VB the_DT opportunity_NN cost_NN function_NN Vj0_NN ,_, only_RB one_CD method_NN -LRB-_-LRB- e_LS ._.
g_NN ._.
mik_NN -RRB-_-RRB- gets_VBZ the_DT opportunity_NN cost_NN for_IN enabling_VBG method_NN mj0_NN ._.
Thus_RB :_: KX_NN k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN ,_, ik_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN -LRB-_-LRB- #_# -RRB-_-RRB- And_CC since_IN Vj0_NN is_VBZ non-increasing_JJ Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- Y_NN k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pjk_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- The_DT last_JJ inequality_NN is_VBZ also_RB a_DT consequence_NN of_IN the_DT fact_NN that_IN Vj0_NN is_VBZ non-increasing_JJ ._.
For_IN heuristic_NN H_NN #_# /_: #_# ,_, #_# /_: #_# we_PRP similarly_RB have_VBP :_: KX_NN k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- KX_NN k_NN =_JJ #_# Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- 1_CD K_NN Vj0_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- Y_NN k_NN -LCB-_-LRB- #_# ,_, ..._: ,_, K_NNP -RCB-_-RRB- k_NN =_JJ k_NN Pjk_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN 1_CD K_NN KX_NN k_NN =_JJ #_# Z_NN t_NN 0_CD pik_NN -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN -LRB-_-LRB- t_NN +_CC t_NN -RRB-_-RRB- dt_NN 1_CD K_NNP K_NNP Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
For_IN heuristic_NN bH_NN #_# ,_, #_# ,_, the_DT opportunity_NN cost_NN function_NN Vj0_NN is_VBZ by_IN definition_NN split_NN in_IN such_JJ manner_NN ,_, that_IN PK_NN k_NN =_JJ #_# Vik_NNP -LRB-_-LRB- t_NN -RRB-_-RRB- Vj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- ._.
Consequently_RB ,_, we_PRP have_VBP proved_VBN ,_, that_IN our_PRP$ new_JJ heuristics_NNS H_NN #_# ,_, #_# ,_, H_NN #_# /_: #_# ,_, #_# /_: #_# and_CC bH_NN #_# ,_, #_# avoid_VB the_DT overestimation_NN of_IN the_DT opportunity_NN cost_NN ._.
The_DT Sixth_NNP Intl_NNP ._.
Joint_NNP Conf_NNP ._.
on_IN Autonomous_NNP Agents_NNPS and_CC Multi-Agent_NNP Systems_NNP -LRB-_-LRB- AAMAS_NNP ##_CD -RRB-_-RRB- ###_CD The_DT reason_NN why_WRB we_PRP have_VBP introduced_VBN all_DT three_CD new_JJ heuristics_NNS is_VBZ the_DT following_NN :_: Since_IN H_NN #_# ,_, #_# overestimates_VBZ the_DT opportunity_NN cost_NN ,_, one_CD has_VBZ to_TO choose_VB which_WDT method_NN mik_NN will_MD receive_VB the_DT reward_NN from_IN enabling_VBG the_DT method_NN mj0_NN ,_, which_WDT is_VBZ exactly_RB what_WP the_DT heuristic_NN H_NN #_# ,_, #_# does_VBZ ._.
However_RB ,_, heuristic_NN H_NN #_# ,_, #_# leaves_VBZ K_NNP #_# methods_NNS that_WDT precede_VBP the_DT method_NN mj0_NN without_IN any_DT reward_NN which_WDT leads_VBZ to_TO starvation_NN ._.
Starvation_NN can_MD be_VB avoided_VBN if_IN opportunity_NN cost_NN functions_NNS are_VBP split_VBN using_VBG heuristic_NN H_NN #_# /_: #_# ,_, #_# /_: #_# ,_, that_WDT provides_VBZ reward_NN to_TO all_DT enabling_VBG methods_NNS ._.
However_RB ,_, the_DT sum_NN of_IN split_JJ opportunity_NN cost_NN functions_NNS for_IN the_DT H_NN #_# /_: #_# ,_, #_# /_: #_# heuristic_NN can_MD be_VB smaller_JJR than_IN the_DT non-zero_JJ split_NN opportunity_NN cost_NN function_NN for_IN the_DT H_NN #_# ,_, #_# heuristic_NN ,_, which_WDT is_VBZ clearly_RB undesirable_JJ ._.
Such_JJ situation_NN -LRB-_-LRB- Figure_NN #_# ,_, heuristic_NN H_NN #_# ,_, #_# -RRB-_-RRB- occurs_VBZ because_IN the_DT mean_NN f_FW +_CC g_NN 2_CD of_IN two_CD functions_NNS f_LS ,_, g_NN is_VBZ not_RB smaller_JJR than_IN f_FW nor_CC g_NN only_RB if_IN f_FW =_JJ g_NN ._.
This_DT is_VBZ why_WRB we_PRP have_VBP proposed_VBN the_DT bH_NN #_# ,_, #_# heuristic_NN ,_, which_WDT by_IN definition_NN avoids_VBZ the_DT overestimation_NN ,_, underestimation_NN and_CC starvation_NN problems_NNS ._.
7_CD ._.
EXPERIMENTAL_JJ EVALUATION_NN Since_IN the_DT VFP_NN algorithm_NN that_IN we_PRP introduced_VBD provides_VBZ two_CD orthogonal_JJ improvements_NNS over_IN the_DT OC-DEC-MDP_NN algorithm_NN ,_, the_DT experimental_JJ evaluation_NN we_PRP performed_VBD consisted_VBN of_IN two_CD parts_NNS :_: In_IN part_NN #_# ,_, we_PRP tested_VBD empirically_RB the_DT quality_NN of_IN solutions_NNS that_IN an_DT locally_RB optimal_JJ solver_NN -LRB-_-LRB- either_CC OC-DEC-MDP_NN or_CC VFP_NN -RRB-_-RRB- finds_VBZ ,_, given_VBN it_PRP uses_VBZ different_JJ opportunity_NN cost_NN function_NN splitting_NN heuristic_NN ,_, and_CC in_IN part_NN #_# ,_, we_PRP compared_VBD the_DT runtimes_NNS of_IN the_DT VFP_NN and_CC OC-DEC_NN -_: MDP_NN algorithms_NNS for_IN a_DT variety_NN of_IN mission_NN plan_NN configurations_NNS ._.
Part_NNP #_# :_: We_PRP first_RB ran_VBD the_DT VFP_NN algorithm_NN on_IN a_DT generic_JJ mission_NN plan_NN configuration_NN from_IN Figure_NNP #_# where_WRB only_RB methods_NNS mj0_RB ,_, mi1_NN ,_, mi2_NN and_CC m0_NN were_VBD present_JJ ._.
Time_NNP windows_NNS of_IN all_DT methods_NNS were_VBD set_VBN to_TO 400_CD ,_, duration_NN pj0_NN of_IN method_NN mj0_NN was_VBD uniform_JJ ,_, i_FW ._.
e_LS ._.
,_, pj0_NN -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ #_# 400_CD and_CC durations_NNS pi1_NN ,_, pi2_NN of_IN methods_NNS mi1_NN ,_, mi2_NN were_VBD normal_JJ distributions_NNS ,_, i_FW ._.
e_LS ._.
,_, pi1_NN =_JJ N_NN -LRB-_-LRB- =_JJ ###_CD ,_, =_JJ ##_NN -RRB-_-RRB- ,_, and_CC pi2_NN =_JJ N_NN -LRB-_-LRB- =_JJ 200_CD ,_, =_JJ ###_CD -RRB-_-RRB- ._.
We_PRP assumed_VBD that_IN only_RB method_NN mj0_NN provided_VBD reward_NN ,_, i_FW ._.
e_LS ._.
rj0_NN =_JJ ##_NN was_VBD the_DT reward_NN for_IN finishing_VBG the_DT execution_NN of_IN method_NN mj0_NN before_IN time_NN t_NN =_JJ ###_CD ._.
We_PRP show_VBP our_PRP$ results_NNS in_IN Figure_NN -LRB-_-LRB- #_# -RRB-_-RRB- where_WRB the_DT x-axis_NN of_IN each_DT of_IN the_DT graphs_NNS represents_VBZ time_NN whereas_IN the_DT y-axis_NN represents_VBZ the_DT opportunity_NN cost_NN ._.
The_DT first_JJ graph_NN confirms_VBZ ,_, that_IN when_WRB the_DT opportunity_NN cost_NN function_NN Vj0_NN was_VBD split_VBN into_IN opportunity_NN cost_NN functions_NNS Vi1_NN and_CC Vi2_NN using_VBG the_DT H_NN #_# ,_, #_# heuristic_NN ,_, the_DT function_NN Vi1_NN +_CC Vi2_NN was_VBD not_RB always_RB below_IN the_DT Vj0_NN function_NN ._.
In_IN particular_JJ ,_, Vi1_NN -LRB-_-LRB- ###_CD -RRB-_-RRB- +_CC Vi2_NN -LRB-_-LRB- ###_CD -RRB-_-RRB- exceeded_VBD Vj0_NN -LRB-_-LRB- ###_CD -RRB-_-RRB- by_IN ##_CD %_NN ._.
When_WRB heuristics_NNS H_NN #_# ,_, #_# ,_, H_NN #_# /_: #_# ,_, #_# /_: #_# and_CC bH_NN #_# ,_, #_# were_VBD used_VBN -LRB-_-LRB- graphs_NNS #_# ,_, #_# and_CC #_# -RRB-_-RRB- ,_, the_DT function_NN Vi1_NN +_CC Vi2_NN was_VBD always_RB below_IN Vj0_NN ._.
We_PRP then_RB shifted_VBD our_PRP$ attention_NN to_TO the_DT civilian_JJ rescue_NN domain_NN introduced_VBN in_IN Figure_NNP #_# for_IN which_WDT we_PRP sampled_VBD all_DT action_NN execution_NN durations_NNS from_IN the_DT normal_JJ distribution_NN N_NN =_JJ -LRB-_-LRB- =_JJ #_# ,_, =_JJ #_# -RRB-_-RRB- -RRB-_-RRB- ._.
To_TO obtain_VB the_DT baseline_NN for_IN the_DT heuristic_NN performance_NN ,_, we_PRP implemented_VBD a_DT globally_RB optimal_JJ solver_NN ,_, that_WDT found_VBD a_DT true_JJ expected_JJ total_JJ reward_NN for_IN this_DT domain_NN -LRB-_-LRB- Figure_NN -LRB-_-LRB- 6a_NN -RRB-_-RRB- -RRB-_-RRB- ._.
We_PRP then_RB compared_VBD this_DT reward_NN with_IN a_DT expected_VBN total_JJ reward_NN found_VBN by_IN a_DT locally_RB optimal_JJ solver_NN guided_VBN by_IN each_DT of_IN the_DT discussed_VBN heuristics_NNS ._.
Figure_NN -LRB-_-LRB- 6a_NN -RRB-_-RRB- ,_, which_WDT plots_NNS on_IN the_DT y-axis_NN the_DT expected_VBN total_JJ reward_NN of_IN a_DT policy_NN complements_VBZ our_PRP$ previous_JJ results_NNS :_: H_NN #_# ,_, #_# heuristic_NN overestimated_VBD the_DT expected_VBN total_JJ reward_NN by_IN ###_CD %_NN whereas_IN the_DT other_JJ heuristics_NNS were_VBD able_JJ to_TO guide_VB the_DT locally_RB optimal_JJ solver_NN close_NN to_TO a_DT true_JJ expected_JJ total_JJ reward_NN ._.
Part_NNP #_# :_: We_PRP then_RB chose_VBD H_NN #_# ,_, #_# to_TO split_VB the_DT opportunity_NN cost_NN functions_NNS and_CC conducted_VBN a_DT series_NN of_IN experiments_NNS aimed_VBN at_IN testing_VBG the_DT scalability_NN of_IN VFP_NN for_IN various_JJ mission_NN plan_NN configurations_NNS ,_, using_VBG the_DT performance_NN of_IN the_DT OC-DEC-MDP_NN algorithm_NN as_IN a_DT benchmark_NN ._.
We_PRP began_VBD the_DT VFP_NN scalability_NN tests_NNS with_IN a_DT configuration_NN from_IN Figure_NN -LRB-_-LRB- 5a_NN -RRB-_-RRB- associated_VBN with_IN the_DT civilian_JJ rescue_NN domain_NN ,_, for_IN which_WDT method_NN execution_NN durations_NNS were_VBD extended_VBN to_TO normal_JJ distributions_NNS N_NN -LRB-_-LRB- =_JJ Figure_NN #_# :_: Mission_NNP plan_NN configurations_NNS :_: -LRB-_-LRB- a_LS -RRB-_-RRB- civilian_JJ rescue_NN domain_NN ,_, -LRB-_-LRB- b_LS -RRB-_-RRB- chain_NN of_IN n_NN methods_NNS ,_, -LRB-_-LRB- c_NN -RRB-_-RRB- tree_NN of_IN n_NN methods_NNS with_IN branching_VBG factor_NN =_JJ #_# and_CC -LRB-_-LRB- d_LS -RRB-_-RRB- square_JJ mesh_NN of_IN n_NN methods_NNS ._.
Figure_NNP #_# :_: VFP_NN performance_NN in_IN the_DT civilian_JJ rescue_NN domain_NN ._.
30_CD ,_, =_JJ #_# -RRB-_-RRB- ,_, and_CC the_DT deadline_NN was_VBD extended_VBN to_TO =_JJ ###_CD ._.
We_PRP decided_VBD to_TO test_VB the_DT runtime_NN of_IN the_DT VFP_NN algorithm_NN running_VBG with_IN three_CD different_JJ levels_NNS of_IN accuracy_NN ,_, i_FW ._.
e_LS ._.
,_, different_JJ approximation_NN parameters_NNS P_NN and_CC V_NN were_VBD chosen_VBN ,_, such_JJ that_IN the_DT cumulative_JJ error_NN of_IN the_DT solution_NN found_VBN by_IN VFP_NN stayed_VBD within_IN #_# %_NN ,_, #_# %_NN and_CC ##_CD %_NN of_IN the_DT solution_NN found_VBN by_IN the_DT OC_NNP -_: DEC-MDP_NN algorithm_NN ._.
We_PRP then_RB run_VBP both_CC algorithms_NNS for_IN a_DT total_NN of_IN ###_CD policy_NN improvement_NN iterations_NNS ._.
Figure_NN -LRB-_-LRB- 6b_NN -RRB-_-RRB- shows_VBZ the_DT performance_NN of_IN the_DT VFP_NN algorithm_NN in_IN the_DT civilian_JJ rescue_NN domain_NN -LRB-_-LRB- y-axis_NN shows_VBZ the_DT runtime_NN in_IN milliseconds_NNS -RRB-_-RRB- ._.
As_IN we_PRP see_VBP ,_, for_IN this_DT small_JJ domain_NN ,_, VFP_NNP runs_VBZ ##_CD %_NN faster_JJR than_IN OCDEC-MDP_NN when_WRB computing_VBG the_DT policy_NN with_IN an_DT error_NN of_IN less_JJR than_IN 1_CD %_NN ._.
For_IN comparison_NN ,_, the_DT globally_RB optimal_JJ solved_VBD did_VBD not_RB terminate_VB within_IN the_DT first_JJ three_CD hours_NNS of_IN its_PRP$ runtime_NN which_WDT shows_VBZ the_DT strength_NN of_IN the_DT opportunistic_JJ solvers_NNS ,_, like_IN OC-DEC-MDP_NN ._.
We_PRP next_RB decided_VBD to_TO test_VB how_WRB VFP_NNP performs_VBZ in_IN a_DT more_RBR difficult_JJ domain_NN ,_, i_FW ._.
e_LS ._.
,_, with_IN methods_NNS forming_VBG a_DT long_JJ chain_NN -LRB-_-LRB- Figure_NN -LRB-_-LRB- 5b_NN -RRB-_-RRB- -RRB-_-RRB- ._.
We_PRP tested_VBD chains_NNS of_IN ##_NN ,_, ##_NN and_CC ##_NN methods_NNS ,_, increasing_VBG at_IN the_DT same_JJ time_NN method_NN time_NN windows_NNS to_TO ###_CD ,_, ###_CD and_CC ####_CD to_TO ensure_VB that_IN later_JJ methods_NNS can_MD be_VB reached_VBN ._.
We_PRP show_VBP the_DT results_NNS in_IN Figure_NN -LRB-_-LRB- 7a_NN -RRB-_-RRB- ,_, where_WRB we_PRP vary_VBP on_IN the_DT x-axis_NN the_DT number_NN of_IN methods_NNS and_CC plot_NN on_IN the_DT y-axis_NN the_DT algorithm_NN runtime_NN -LRB-_-LRB- notice_NN the_DT logarithmic_JJ scale_NN -RRB-_-RRB- ._.
As_IN we_PRP observe_VBP ,_, scaling_VBG up_RP the_DT domain_NN reveals_VBZ the_DT high_JJ performance_NN of_IN VFP_NNP :_: Within_IN #_# %_NN error_NN ,_, it_PRP runs_VBZ up_IN to_TO #_# times_NNS faster_JJR than_IN OC-DECMDP_NN ._.
We_PRP then_RB tested_VBD how_WRB VFP_NNP scales_NNS up_RB ,_, given_VBN that_IN the_DT methods_NNS are_VBP arranged_VBN into_IN a_DT tree_NN -LRB-_-LRB- Figure_NN -LRB-_-LRB- 5c_NN -RRB-_-RRB- -RRB-_-RRB- ._.
In_IN particular_JJ ,_, we_PRP considered_VBD trees_NNS with_IN branching_VBG factor_NN of_IN #_# ,_, and_CC depth_NN of_IN #_# ,_, #_# and_CC #_# ,_, increasing_VBG at_IN the_DT same_JJ time_NN the_DT time_NN horizon_NN from_IN ###_CD to_TO ###_CD ,_, and_CC then_RB to_TO ###_CD ._.
We_PRP show_VBP the_DT results_NNS in_IN Figure_NN -LRB-_-LRB- 7b_NN -RRB-_-RRB- ._.
Although_IN the_DT speedups_NNS are_VBP smaller_JJR than_IN in_IN case_NN of_IN a_DT chain_NN ,_, the_DT VFP_NNP algorithm_NN still_RB runs_VBZ up_IN to_TO #_# times_NNS faster_JJR than_IN OC-DEC-MDP_NN when_WRB computing_VBG the_DT policy_NN with_IN an_DT error_NN of_IN less_JJR than_IN #_# %_NN ._.
We_PRP finally_RB tested_VBD how_WRB VFP_NNP handles_VBZ the_DT domains_NNS with_IN methods_NNS arranged_VBN into_IN a_DT n_NN n_NN mesh_NN ,_, i_FW ._.
e_LS ._.
,_, C_NN =_JJ -LCB-_-LRB- mi_FW ,_, j_NN ,_, mk_NN ,_, j_NN +_CC #_# -RCB-_-RRB- for_IN i_FW =_JJ 1_CD ,_, ..._: ,_, n_NN ;_: k_NN =_JJ #_# ,_, ..._: ,_, n_NN ;_: j_NN =_JJ #_# ,_, ..._: ,_, n_NN #_# ._.
In_IN particular_JJ ,_, we_PRP consider_VBP 836_CD The_DT Sixth_NNP Intl_NNP ._.
Joint_NNP Conf_NNP ._.
on_IN Autonomous_NNP Agents_NNPS and_CC Multi-Agent_NNP Systems_NNP -LRB-_-LRB- AAMAS_NNP ##_CD -RRB-_-RRB- Figure_NNP #_# :_: Visualization_NN of_IN heuristics_NNS for_IN opportunity_NN costs_NNS splitting_NN ._.
Figure_NNP #_# :_: Scalability_NN experiments_NNS for_IN OC-DEC-MDP_NN and_CC VFP_NN for_IN different_JJ network_NN configurations_NNS ._.
meshes_NNS of_IN ##_NN ,_, ##_NN ,_, and_CC ##_NN methods_NNS ._.
For_IN such_JJ configurations_NNS we_PRP have_VBP to_TO greatly_RB increase_VB the_DT time_NN horizon_NN since_IN the_DT probabilities_NNS of_IN enabling_VBG the_DT final_JJ methods_NNS by_IN a_DT particular_JJ time_NN decrease_VB exponentially_RB ._.
We_PRP therefore_RB vary_VBP the_DT time_NN horizons_NNS from_IN ####_CD to_TO 4000_CD ,_, and_CC then_RB to_TO ####_CD ._.
We_PRP show_VBP the_DT results_NNS in_IN Figure_NN -LRB-_-LRB- 7c_NN -RRB-_-RRB- where_WRB ,_, especially_RB for_IN larger_JJR meshes_NNS ,_, the_DT VFP_NNP algorithm_NN runs_VBZ up_RP to_TO one_CD order_NN of_IN magnitude_NN faster_RBR than_IN OC-DEC-MDP_NN while_IN finding_VBG a_DT policy_NN that_WDT is_VBZ within_IN less_JJR than_IN #_# %_NN from_IN the_DT policy_NN found_VBN by_IN OC_NN -_: DECMDP_NN ._.
8_CD ._.
CONCLUSIONS_NNS Decentralized_JJ Markov_NNP Decision_NNP Process_VB -LRB-_-LRB- DEC-MDP_NN -RRB-_-RRB- has_VBZ been_VBN very_RB popular_JJ for_IN modeling_NN of_IN agent-coordination_JJ problems_NNS ,_, it_PRP is_VBZ very_RB difficult_JJ to_TO solve_VB ,_, especially_RB for_IN the_DT real-world_JJ domains_NNS ._.
In_IN this_DT paper_NN ,_, we_PRP improved_VBD a_DT state-of-the-art_JJ heuristic_NN solution_NN method_NN for_IN DEC-MDPs_NNS ,_, called_VBN OC-DEC-MDP_NN ,_, that_WDT has_VBZ recently_RB been_VBN shown_VBN to_TO scale_VB up_RP to_TO large_JJ DEC-MDPs_NNS ._.
Our_PRP$ heuristic_NN solution_NN method_NN ,_, called_VBN Value_NNP Function_NN Propagation_NN -LRB-_-LRB- VFP_NN -RRB-_-RRB- ,_, provided_VBD two_CD orthogonal_JJ improvements_NNS of_IN OC-DEC-MDP_NN :_: -LRB-_-LRB- i_LS -RRB-_-RRB- It_PRP speeded_VBD up_RP OC-DECMDP_NN by_IN an_DT order_NN of_IN magnitude_NN by_IN maintaining_VBG and_CC manipulating_VBG a_DT value_NN function_NN for_IN each_DT method_NN rather_RB than_IN a_DT separate_JJ value_NN for_IN each_DT pair_NN of_IN method_NN and_CC time_NN interval_NN ,_, and_CC -LRB-_-LRB- ii_LS -RRB-_-RRB- it_PRP achieved_VBD better_JJR solution_NN qualities_NNS than_IN OC-DEC-MDP_NN because_IN it_PRP corrected_VBD the_DT overestimation_NN of_IN the_DT opportunity_NN cost_NN of_IN OC-DEC-MDP_NN ._.
In_IN terms_NNS of_IN related_JJ work_NN ,_, we_PRP have_VBP extensively_RB discussed_VBN the_DT OCDEC-MDP_NN algorithm_NN -LSB-_-LRB- #_# -RSB-_-RRB- ._.
Furthermore_RB ,_, as_IN discussed_VBN in_IN Section_NN #_# ,_, there_EX are_VBP globally_RB optimal_JJ algorithms_NNS for_IN solving_VBG DEC-MDPs_NNS with_IN temporal_JJ constraints_NNS -LSB-_-LRB- #_# -RSB-_-RRB- -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
Unfortunately_RB ,_, they_PRP fail_VBP to_TO scale_VB up_RP to_TO large-scale_JJ domains_NNS at_IN present_JJ time_NN ._.
Beyond_IN OC-DEC-MDP_NN ,_, there_EX are_VBP other_JJ locally_RB optimal_JJ algorithms_NNS for_IN DEC-MDPs_NNS and_CC DECPOMDPs_NNS -LSB-_-LRB- #_# -RSB-_-RRB- -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, yet_RB ,_, they_PRP have_VBP traditionally_RB not_RB dealt_VBN with_IN uncertain_JJ execution_NN times_NNS and_CC temporal_JJ constraints_NNS ._.
Finally_RB ,_, value_NN function_NN techniques_NNS have_VBP been_VBN studied_VBN in_IN context_NN of_IN single_JJ agent_NN MDPs_NN -LSB-_-LRB- #_# -RSB-_-RRB- -LSB-_-LRB- #_# -RSB-_-RRB- ._.
However_RB ,_, similarly_RB to_TO -LSB-_-LRB- #_# -RSB-_-RRB- ,_, they_PRP fail_VBP to_TO address_VB the_DT lack_NN of_IN global_JJ state_NN knowledge_NN ,_, which_WDT is_VBZ a_DT fundamental_JJ issue_NN in_IN decentralized_VBN planning_NN ._.
Acknowledgments_NNS This_DT material_NN is_VBZ based_VBN upon_IN work_NN supported_VBN by_IN the_DT DARPA_NNP /_: IPTO_NNP COORDINATORS_NNPS program_NN and_CC the_DT Air_NNP Force_NNP Research_NNP Laboratory_NNP under_IN Contract_NNP No_NNP ._.
FA875005C0030_NN ._.
The_DT authors_NNS also_RB want_VBP to_TO thank_VB Sven_NNP Koenig_NNP and_CC anonymous_JJ reviewers_NNS for_IN their_PRP$ valuable_JJ comments_NNS ._.
9_CD ._.
REFERENCES_NNS -LSB-_-LRB- #_# -RSB-_-RRB- R_NN ._.
Becker_NNP ,_, V_NNP ._.
Lesser_RBR ,_, and_CC S_NN ._.
Zilberstein_NN ._.
Decentralized_JJ MDPs_NNS with_IN Event-Driven_JJ Interactions_NNS ._.
In_IN AAMAS_NNP ,_, pages_NNS 302-309_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- R_NN ._.
Becker_NNP ,_, S_NN ._.
Zilberstein_NNP ,_, V_NNP ._.
Lesser_RBR ,_, and_CC C_NN ._.
V_NN ._.
Goldman_NNP ._.
Transition-Independent_JJ Decentralized_NNP Markov_NNP Decision_NNP Processes_NNP ._.
In_IN AAMAS_NNP ,_, pages_NNS 41-48_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- D_NN ._.
S_NN ._.
Bernstein_NNP ,_, S_NN ._.
Zilberstein_NNP ,_, and_CC N_NN ._.
Immerman_NNP ._.
The_DT complexity_NN of_IN decentralized_VBN control_NN of_IN Markov_NNP decision_NN processes_NNS ._.
In_IN UAI_NNP ,_, pages_NNS 32-37_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- A_DT ._.
Beynier_NNP and_CC A_NNP ._.
Mouaddib_NNP ._.
A_DT polynomial_JJ algorithm_NN for_IN decentralized_VBN Markov_NNP decision_NN processes_VBZ with_IN temporal_JJ constraints_NNS ._.
In_IN AAMAS_NNP ,_, pages_NNS 963-969_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- A_DT ._.
Beynier_NNP and_CC A_NNP ._.
Mouaddib_NNP ._.
An_DT iterative_JJ algorithm_NN for_IN solving_VBG constrained_VBN decentralized_VBN Markov_NNP decision_NN processes_NNS ._.
In_IN AAAI_NNP ,_, pages_NNS 1089-1094_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- C_NN ._.
Boutilier_NNP ._.
Sequential_JJ optimality_NN and_CC coordination_NN in_IN multiagent_JJ systems_NNS ._.
In_IN IJCAI_NNP ,_, pages_NNS 478-485_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- J_NN ._.
Boyan_NNP and_CC M_NN ._.
Littman_NNP ._.
Exact_JJ solutions_NNS to_TO time-dependent_JJ MDPs_NNS ._.
In_IN NIPS_NNP ,_, pages_NNS 1026-1032_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- C_NN ._.
Goldman_NNP and_CC S_NN ._.
Zilberstein_NN ._.
Optimizing_VBG information_NN exchange_NN in_IN cooperative_JJ multi-agent_JJ systems_NNS ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- L_NN ._.
Li_NNP and_CC M_NN ._.
Littman_NNP ._.
Lazy_JJ approximation_NN for_IN solving_VBG continuous_JJ finite-horizon_JJ MDPs_NNS ._.
In_IN AAAI_NNP ,_, pages_NNS 1175-1180_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Y_NN ._.
Liu_NNP and_CC S_NN ._.
Koenig_NNP ._.
Risk-sensitive_JJ planning_NN with_IN one-switch_JJ utility_NN functions_NNS :_: Value_NNP iteration_NN ._.
In_IN AAAI_NNP ,_, pages_NNS 993-999_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- D_NN ._.
Musliner_NNP ,_, E_NNP ._.
Durfee_NNP ,_, J_NNP ._.
Wu_NNP ,_, D_NNP ._.
Dolgov_NNP ,_, R_NN ._.
Goldman_NNP ,_, and_CC M_NN ._.
Boddy_NNP ._.
Coordinated_VBN plan_NN management_NN using_VBG multiagent_JJ MDPs_NNS ._.
In_IN AAAI_NNP Spring_NNP Symposium_NNP ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- R_NN ._.
Nair_NNP ,_, M_NN ._.
Tambe_NNP ,_, M_NN ._.
Yokoo_NNP ,_, D_NNP ._.
Pynadath_NNP ,_, and_CC S_NN ._.
Marsella_NNP ._.
Taming_VBG decentralized_VBN POMDPs_NNS :_: Towards_IN efficient_JJ policy_NN computation_NN for_IN multiagent_JJ settings_NNS ._.
In_IN IJCAI_NNP ,_, pages_NNS 705-711_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- R_NN ._.
Nair_NNP ,_, P_NN ._.
Varakantham_NNP ,_, M_NN ._.
Tambe_NNP ,_, and_CC M_NN ._.
Yokoo_NNP ._.
Networked_VBN distributed_VBN POMDPs_NNS :_: A_DT synergy_NN of_IN distributed_VBN constraint_NN optimization_NN and_CC POMDPs_NNS ._.
In_IN IJCAI_NNP ,_, pages_NNS 1758-1760_CD ,_, ####_CD ._.
The_DT Sixth_NNP Intl_NNP ._.
Joint_NNP Conf_NNP ._.
on_IN Autonomous_NNP Agents_NNPS and_CC Multi-Agent_NNP Systems_NNP -LRB-_-LRB- AAMAS_NNP ##_CD -RRB-_-RRB- ###_CD
