Empirical_JJ Mechanism_NN Design_NN :_: Methods_NNS ,_, with_IN Application_NN to_TO a_DT Supply-Chain_NNP Scenario_NN Yevgeniy_NNP Vorobeychik_NNP ,_, Christopher_NNP Kiekintveld_NNP ,_, and_CC Michael_NNP P_NN ._.
Wellman_NNP University_NNP of_IN Michigan_NNP Computer_NNP Science_NNP &_CC Engineering_NNP Ann_NNP Arbor_NNP ,_, MI_NNP 48109-2121_CD USA_NNP -LCB-_-LRB- yvorobey_NN ,_, ckiekint_NN ,_, wellman_JJ -RCB-_-RRB- @_IN umich_NN ._.
edu_NN ABSTRACT_NN Our_PRP$ proposed_VBN methods_NNS employ_VBP learning_VBG and_CC search_NN techniques_NNS to_TO estimate_VB outcome_NN features_NNS of_IN interest_NN as_IN a_DT function_NN of_IN mechanism_NN parameter_NN settings_NNS ._.
We_PRP illustrate_VBP our_PRP$ approach_NN with_IN a_DT design_NN task_NN from_IN a_DT supply-chain_JJ trading_NN competition_NN ._.
Designers_NNS adopted_VBD several_JJ rule_NN changes_NNS in_IN order_NN to_TO deter_VB particular_JJ procurement_NN behavior_NN ,_, but_CC the_DT measures_NNS proved_VBD insufficient_JJ ._.
Our_PRP$ empirical_JJ mechanism_NN analysis_NN models_NNS the_DT relation_NN between_IN a_DT key_JJ design_NN parameter_NN and_CC outcomes_NNS ,_, confirming_VBG the_DT observed_VBN behavior_NN and_CC indicating_VBG that_IN no_DT reasonable_JJ parameter_NN settings_NNS would_MD have_VB been_VBN likely_JJ to_TO achieve_VB the_DT desired_VBN effect_NN ._.
More_RBR generally_RB ,_, we_PRP show_VBP that_IN under_IN certain_JJ conditions_NNS ,_, the_DT estimator_NN of_IN optimal_JJ mechanism_NN parameter_NN setting_NN based_VBN on_IN empirical_JJ data_NNS is_VBZ consistent_JJ ._.
Categories_NNS and_CC Subject_NNP Descriptors_NNS I_PRP ._.
#_# -LSB-_-LRB- Computing_NNP Methodologies_NNPS -RSB-_-RRB- :_: Simulation_NN and_CC Modeling_NN ;_: J_NN ._.
#_# -LSB-_-LRB- Computer_NNP Applications_NNS -RSB-_-RRB- :_: Social_NNP and_CC Behavioral_NNP Sciences-Economics_NNP General_NNP Terms_NNS Algorithms_NNS ,_, Economics_NNP ,_, Design_NN 1_CD ._.
MOTIVATION_NN We_PRP illustrate_VBP our_PRP$ problem_NN with_IN an_DT anecdote_NN from_IN a_DT supply_NN chain_NN research_NN exercise_NN :_: the_DT ####_NN and_CC ####_CD Trading_NN Agent_NNP Competition_NN -LRB-_-LRB- TAC_NN -RRB-_-RRB- Supply_NN Chain_NNP Management_NNP -LRB-_-LRB- SCM_NNP -RRB-_-RRB- game_NN ._.
TAC_NN /_: SCM_NNP -LSB-_-LRB- #_# -RSB-_-RRB- defines_VBZ a_DT scenario_NN where_WRB agents_NNS compete_VBP to_TO maximize_VB their_PRP$ profits_NNS as_IN manufacturers_NNS in_IN a_DT supply_NN chain_NN ._.
The_DT agents_NNS procure_VBP components_NNS from_IN the_DT various_JJ suppliers_NNS and_CC assemble_VB finished_VBN goods_NNS for_IN sale_NN to_TO customers_NNS ,_, repeatedly_RB over_IN a_DT simulated_JJ year_NN ._.
As_IN it_PRP happened_VBD ,_, the_DT specified_VBN negotiation_NN behavior_NN of_IN suppliers_NNS provided_VBD a_DT great_JJ incentive_NN for_IN agents_NNS to_TO procure_VB large_JJ quantities_NNS of_IN components_NNS on_IN day_NN #_# :_: the_DT very_RB beginning_NN of_IN the_DT simulation_NN ._.
During_IN the_DT early_JJ rounds_NNS of_IN the_DT ####_CD SCM_NNP competition_NN ,_, several_JJ agent_NN developers_NNS discovered_VBN this_DT ,_, and_CC the_DT apparent_JJ success_NN led_VBD to_TO most_JJS agents_NNS performing_VBG the_DT majority_NN of_IN their_PRP$ purchasing_NN on_IN day_NN #_# ._.
Although_IN jockeying_VBG for_IN day-0_JJ procurement_NN turned_VBD out_RP to_TO be_VB an_DT interesting_JJ strategic_JJ issue_NN in_IN itself_PRP -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, the_DT phenomenon_NN detracted_VBD from_IN other_JJ interesting_JJ problems_NNS ,_, such_JJ as_IN adapting_VBG production_NN levels_NNS to_TO varying_VBG demand_NN -LRB-_-LRB- since_IN component_NN costs_NNS were_VBD already_RB sunk_VBN -RRB-_-RRB- ,_, and_CC dynamic_JJ management_NN of_IN production_NN ,_, sales_NNS ,_, and_CC inventory_NN ._.
Several_JJ participants_NNS noted_VBD that_IN the_DT predominance_NN of_IN day-0_JJ procurement_NN overshadowed_VBD other_JJ key_JJ research_NN issues_NNS ,_, such_JJ as_IN factory_NN scheduling_NN -LSB-_-LRB- #_# -RSB-_-RRB- and_CC optimizing_VBG bids_NNS for_IN customer_NN orders_NNS -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
After_IN the_DT ####_CD tournament_NN ,_, there_EX was_VBD a_DT general_JJ consensus_NN in_IN the_DT TAC_NN community_NN that_IN the_DT rules_NNS should_MD be_VB changed_VBN to_TO deter_VB large_JJ day-0_JJ procurement_NN ._.
The_DT task_NN facing_VBG game_NN organizers_NNS can_MD be_VB viewed_VBN as_IN a_DT problem_NN in_IN mechanism_NN design_NN ._.
The_DT designers_NNS have_VBP certain_JJ game_NN features_NNS under_IN their_PRP$ control_NN ,_, and_CC a_DT set_NN of_IN objectives_NNS regarding_VBG game_NN outcomes_NNS ._.
Unlike_IN most_JJS academic_JJ treatments_NNS of_IN mechanism_NN design_NN ,_, the_DT objective_NN is_VBZ a_DT behavioral_JJ feature_NN -LRB-_-LRB- moderate_JJ day-0_JJ procurement_NN -RRB-_-RRB- rather_RB than_IN an_DT allocation_NN feature_NN like_IN economic_JJ efficiency_NN ,_, and_CC the_DT allowed_VBN mechanisms_NNS are_VBP restricted_JJ to_TO those_DT judged_VBN to_TO require_VB only_RB an_DT incremental_JJ modification_NN of_IN the_DT current_JJ game_NN ._.
Replacing_VBG the_DT supplychain_NN negotiation_NN procedures_NNS with_IN a_DT one-shot_JJ direct_JJ mechanism_NN ,_, for_IN example_NN ,_, was_VBD not_RB an_DT option_NN ._.
We_PRP believe_VBP that_IN such_JJ operational_JJ restrictions_NNS and_CC idiosyncratic_JJ objectives_NNS are_VBP actually_RB quite_RB typical_JJ of_IN practical_JJ mechanism_NN design_NN settings_NNS ,_, where_WRB they_PRP are_VBP perhaps_RB more_RBR commonly_RB characterized_VBN as_IN incentive_NN engineering_NN problems_NNS ._.
In_IN response_NN to_TO the_DT problem_NN ,_, the_DT TAC_NN /_: SCM_NNP designers_NNS adopted_VBD several_JJ rule_NN changes_NNS intended_VBN to_TO penalize_VB large_JJ day-0_JJ orders_NNS ._.
These_DT included_VBD modifications_NNS to_TO supplier_NN pricing_NN policies_NNS and_CC introduction_NN of_IN storage_NN costs_NNS assessed_VBN on_IN inventories_NNS of_IN components_NNS and_CC finished_VBD goods_NNS ._.
Despite_IN the_DT changes_NNS ,_, day-0_JJ procurement_NN was_VBD very_RB high_JJ in_IN the_DT early_JJ rounds_NNS of_IN the_DT ####_CD competition_NN ._.
In_IN a_DT drastic_JJ measure_NN ,_, the_DT GameMaster_NNP imposed_VBD a_DT fivefold_JJ increase_NN of_IN storage_NN costs_NNS midway_NN through_IN the_DT tournament_NN ._.
Even_RB this_DT did_VBD not_RB stem_VB the_DT tide_NN ,_, and_CC day-0_NN procurement_NN in_IN the_DT final_JJ rounds_NNS actually_RB increased_VBN -LRB-_-LRB- by_IN some_DT measures_NNS -RRB-_-RRB- from_IN ####_CD -LSB-_-LRB- #_# -RSB-_-RRB- ._.
The_DT apparent_JJ difficulty_NN in_IN identifying_VBG rule_NN modifications_NNS that_WDT effect_VBP moderation_NN in_IN day-0_JJ procurement_NN is_VBZ quite_RB striking_JJ ._.
Although_IN the_DT designs_NNS were_VBD widely_RB discussed_VBN ,_, predictions_NNS for_IN the_DT effects_NNS of_IN various_JJ proposals_NNS were_VBD supported_VBN primarily_RB by_IN intuitive_JJ arguments_NNS or_CC at_IN best_JJS by_IN back-of-the-envelope_JJ calculations_NNS ._.
Much_JJ of_IN the_DT difficulty_NN ,_, of_IN course_NN ,_, is_VBZ anticipating_VBG the_DT agents_NNS ''_'' -LRB-_-LRB- and_CC their_PRP$ developers_NNS ''_'' -RRB-_-RRB- responses_NNS without_IN essentially_RB running_VBG a_DT gaming_NN exercise_NN for_IN this_DT purpose_NN ._.
The_DT episode_NN caused_VBD us_PRP to_TO consider_VB whether_IN new_JJ ap306_NN proaches_NNS or_CC tools_NNS could_MD enable_VB more_RBR systematic_JJ analysis_NN of_IN design_NN options_NNS ._.
Standard_NNP game-theoretic_JJ and_CC mechanism_NN design_NN methods_NNS are_VBP clearly_RB relevant_JJ ,_, although_IN the_DT lack_NN of_IN an_DT analytic_JJ description_NN of_IN the_DT game_NN seems_VBZ to_TO be_VB an_DT impediment_NN ._.
Under_IN the_DT assumption_NN that_IN the_DT simulator_NN itself_PRP is_VBZ the_DT only_JJ reliable_JJ source_NN of_IN outcome_NN computation_NN ,_, we_PRP refer_VBP to_TO our_PRP$ task_NN as_IN empirical_JJ mechanism_NN design_NN ._.
In_IN the_DT sequel_NN ,_, we_PRP develop_VBP some_DT general_JJ methods_NNS for_IN empirical_JJ mechanism_NN design_NN and_CC apply_VB them_PRP to_TO the_DT TAC_NN /_: SCM_NNP redesign_NN problem_NN ._.
Our_PRP$ analysis_NN focuses_VBZ on_IN the_DT setting_NN of_IN storage_NN costs_NNS -LRB-_-LRB- taking_VBG other_JJ game_NN modifications_NNS as_IN fixed_VBN -RRB-_-RRB- ,_, since_IN this_DT is_VBZ the_DT most_RBS direct_JJ deterrent_NN to_TO early_JJ procurement_NN adopted_VBN ._.
Our_PRP$ results_NNS confirm_VBP the_DT basic_JJ intuition_NN that_WDT incentives_NNS for_IN day-0_JJ purchasing_NN decrease_NN as_IN storage_NN costs_NNS rise_VBP ._.
We_PRP also_RB confirm_VBP that_IN the_DT high_JJ day-0_NN procurement_NN observed_VBN in_IN the_DT ####_CD tournament_NN is_VBZ a_DT rational_JJ response_NN to_TO the_DT setting_NN of_IN storage_NN costs_NNS used_VBN ._.
Finally_RB ,_, we_PRP conclude_VBP from_IN our_PRP$ data_NNS that_IN it_PRP is_VBZ very_RB unlikely_JJ that_IN any_DT reasonable_JJ setting_NN of_IN storage_NN costs_NNS would_MD result_VB in_IN acceptable_JJ levels_NNS of_IN day-0_JJ procurement_NN ,_, so_IN a_DT different_JJ design_NN approach_NN would_MD have_VB been_VBN required_VBN to_TO eliminate_VB this_DT problem_NN ._.
Overall_RB ,_, we_PRP contribute_VBP a_DT formal_JJ framework_NN and_CC a_DT set_NN of_IN methods_NNS for_IN tackling_VBG indirect_JJ mechanism_NN design_NN problems_NNS in_IN settings_NNS where_WRB only_RB a_DT black-box_JJ description_NN of_IN players_NNS ''_'' utilities_NNS is_VBZ available_JJ ._.
Our_PRP$ methods_NNS incorporate_VB estimation_NN of_IN sets_NNS of_IN Nash_NNP equilibria_NNP and_CC sample_NN Nash_NNP equilibria_NNP ,_, used_VBN in_IN conjuction_NN to_TO support_VB general_JJ claims_NNS about_IN the_DT structure_NN of_IN the_DT mechanism_NN designer_NN ''_'' s_NNS utility_NN ,_, as_RB well_RB as_IN a_DT restricted_JJ probabilistic_JJ analysis_NN to_TO assess_VB the_DT likelihood_NN of_IN conclusions_NNS ._.
We_PRP believe_VBP that_IN most_JJS realistic_JJ problems_NNS are_VBP too_RB complex_JJ to_TO be_VB amenable_JJ to_TO exact_JJ analysis_NN ._.
Consequently_RB ,_, we_PRP advocate_VBP the_DT approach_NN of_IN gathering_VBG evidence_NN to_TO provide_VB indirect_JJ support_NN of_IN specific_JJ hypotheses_NNS ._.
2_LS ._.
PRELIMINARIES_NNP A_NNP normal_JJ form_NN game2_NN is_VBZ denoted_VBN by_IN -LSB-_-LRB- I_PRP ,_, -LCB-_-LRB- Ri_NNP -RCB-_-RRB- ,_, -LCB-_-LRB- ui_NN -LRB-_-LRB- r_NN -RRB-_-RRB- -RCB-_-RRB- -RSB-_-RRB- ,_, where_WRB I_PRP refers_VBZ to_TO the_DT set_NN of_IN players_NNS and_CC m_NN =_JJ |_CD I_PRP |_VBP is_VBZ the_DT number_NN of_IN players_NNS ._.
Ri_NNP is_VBZ the_DT set_NN of_IN strategies_NNS available_JJ to_TO player_NN i_FW I_PRP ,_, with_IN R_NN =_JJ R1_NN ..._: Rm_NN representing_VBG the_DT set_NN of_IN joint_JJ strategies_NNS of_IN all_DT players_NNS ._.
We_PRP designate_VBP the_DT set_NN of_IN pure_JJ strategies_NNS available_JJ to_TO player_NN i_FW by_IN Ai_NNP ,_, and_CC denote_VB the_DT joint_JJ set_NN of_IN pure_JJ strategies_NNS of_IN all_DT players_NNS by_IN A_NN =_JJ A1_NN ..._: Am_VBP ._.
It_PRP is_VBZ often_RB convenient_JJ to_TO refer_VB to_TO a_DT strategy_NN of_IN player_NN i_FW separately_RB from_IN that_DT of_IN the_DT remaining_VBG players_NNS ._.
To_TO accommodate_VB this_DT ,_, we_PRP use_VBP ai_VBP to_TO denote_VB the_DT joint_JJ strategy_NN of_IN all_DT players_NNS other_JJ than_IN player_NN i_FW ._.
Let_VB Si_NNP be_VB the_DT set_NN of_IN all_DT probability_NN distributions_NNS -LRB-_-LRB- mixtures_NNS -RRB-_-RRB- over_IN Ai_NN and_CC ,_, similarly_RB ,_, S_NN be_VB the_DT set_NN of_IN all_DT distributions_NNS over_IN A_DT ._.
An_DT s_NNS S_NN is_VBZ called_VBN a_DT mixed_JJ strategy_NN profile_NN ._.
When_WRB the_DT game_NN is_VBZ finite_JJ -LRB-_-LRB- i_FW ._.
e_LS ._.
,_, A_DT and_CC I_PRP are_VBP both_DT finite_JJ -RRB-_-RRB- ,_, the_DT probability_NN that_IN a_DT A_NN is_VBZ played_VBN under_IN s_NNS is_VBZ written_VBN s_NNS -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ s_NNS -LRB-_-LRB- ai_VBP ,_, ai_VBP -RRB-_-RRB- ._.
When_WRB the_DT distribution_NN s_NNS is_VBZ not_RB correlated_VBN ,_, we_PRP can_MD simply_RB say_VB si_NN -LRB-_-LRB- ai_VBP -RRB-_-RRB- when_WRB referring_VBG to_TO the_DT probability_NN player_NN i_FW plays_VBZ ai_VBP under_IN s_NNS ._.
Next_RB ,_, we_PRP define_VBP the_DT payoff_NN -LRB-_-LRB- utility_NN -RRB-_-RRB- function_NN of_IN each_DT player_NN i_FW by_IN ui_NN :_: A1_NN Am_VBP R_NN ,_, where_WRB ui_NN -LRB-_-LRB- ai_VBP ,_, ai_VBP -RRB-_-RRB- indicates_VBZ the_DT payoff_NN to_TO player_NN i_FW to_TO playing_VBG pure_JJ strategy_NN ai_VBP when_WRB the_DT remaining_VBG players_NNS play_VBP ai_VBP ._.
We_PRP can_MD extend_VB this_DT definition_NN to_TO mixed_JJ strategies_NNS by_IN assuming_VBG that_IN ui_NN are_VBP von_NNP Neumann-Morgenstern_NNP -LRB-_-LRB- vNM_NNP -RRB-_-RRB- utilities_NNS as_IN follows_VBZ :_: ui_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- =_JJ Es_NN -LSB-_-LRB- ui_NN -RSB-_-RRB- ,_, where_WRB Es_NNS is_VBZ the_DT expectation_NN taken_VBN with_IN respect_NN to_TO the_DT probability_NN distribution_NN of_IN play_NN induced_VBN by_IN the_DT players_NNS ''_'' mixed_JJ strategy_NN s_NNS ._.
2_CD By_IN employing_VBG the_DT normal_JJ form_NN ,_, we_PRP model_VBP agents_NNS as_IN playing_VBG a_DT single_JJ action_NN ,_, with_IN decisions_NNS taken_VBN simultaneously_RB ._.
This_DT is_VBZ appropriate_JJ for_IN our_PRP$ current_JJ study_NN ,_, which_WDT treats_VBZ strategies_NNS -LRB-_-LRB- agent_NN programs_NNS -RRB-_-RRB- as_IN atomic_JJ actions_NNS ._.
We_PRP could_MD capture_VB finer-grained_JJ decisions_NNS about_IN action_NN over_IN time_NN in_IN the_DT extensive_JJ form_NN ._.
Although_IN any_DT extensive_JJ game_NN can_MD be_VB recast_VBN in_IN normal_JJ form_NN ,_, doing_VBG so_RB may_MD sacrifice_VB compactness_NN and_CC blur_NN relevant_JJ distinctions_NNS -LRB-_-LRB- e_LS ._.
g_NN ._.
,_, subgame_JJ perfection_NN -RRB-_-RRB- ._.
Occasionally_RB ,_, we_PRP write_VBP ui_NN -LRB-_-LRB- x_NN ,_, y_NN -RRB-_-RRB- to_TO mean_VB that_IN x_CC Ai_NN or_CC Si_NNP and_CC y_NNP Ai_NNP or_CC Si_NNP depending_VBG on_IN context_NN ._.
We_PRP also_RB express_VBP the_DT set_NN of_IN utility_NN functions_NNS of_IN all_DT players_NNS as_IN u_NN -LRB-_-LRB- -RRB-_-RRB- =_JJ -LCB-_-LRB- u1_NN -LRB-_-LRB- -RRB-_-RRB- ,_, ..._: ,_, um_NN -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- ._.
We_PRP define_VBP a_DT function_NN ,_, :_: R_NN R_NN ,_, interpreted_VBD as_IN the_DT maximum_NN benefit_NN any_DT player_NN can_MD obtain_VB by_IN deviating_VBG from_IN its_PRP$ strategy_NN in_IN the_DT specified_VBN profile_NN ._.
-LRB-_-LRB- r_NN -RRB-_-RRB- =_JJ max_NN iI_NNP max_NN aiAi_NN -LSB-_-LRB- ui_NN -LRB-_-LRB- ai_VBP ,_, ri_VBP -RRB-_-RRB- ui_NN -LRB-_-LRB- r_NN -RRB-_-RRB- -RSB-_-RRB- ,_, -LRB-_-LRB- #_# -RRB-_-RRB- where_WRB r_NN belongs_VBZ to_TO some_DT strategy_NN set_NN ,_, R_NN ,_, of_IN either_CC pure_JJ or_CC mixed_JJ strategies_NNS ._.
Faced_VBN with_IN a_DT game_NN ,_, an_DT agent_NN would_MD ideally_RB play_VB its_PRP$ best_JJS strategy_NN given_VBN those_DT played_VBN by_IN the_DT other_JJ agents_NNS ._.
A_DT configuration_NN where_WRB all_DT agents_NNS play_VBP strategies_NNS that_WDT are_VBP best_RBS responses_NNS to_TO the_DT others_NNS constitutes_VBZ a_DT Nash_NNP equilibrium_NN ._.
DEFINITION_NN #_# ._.
A_DT strategy_NN profile_NN r_NN =_JJ -LRB-_-LRB- r1_NN ,_, ..._: ,_, rm_NN -RRB-_-RRB- constitutes_VBZ a_DT Nash_NNP equilibrium_NN of_IN game_NN -LSB-_-LRB- I_PRP ,_, -LCB-_-LRB- Ri_NNP -RCB-_-RRB- ,_, -LCB-_-LRB- ui_NN -LRB-_-LRB- r_NN -RRB-_-RRB- -RCB-_-RRB- -RSB-_-RRB- if_IN for_IN every_DT i_FW I_PRP ,_, ri_FW Ri_FW ,_, ui_NN -LRB-_-LRB- ri_NN ,_, ri_NN -RRB-_-RRB- ui_NN -LRB-_-LRB- ri_NN ,_, ri_NN -RRB-_-RRB- ._.
When_WRB r_NN A_NN ,_, the_DT above_JJ defines_VBZ a_DT pure_JJ strategy_NN Nash_NNP equilibrium_NN ;_: otherwise_RB the_DT definition_NN describes_VBZ a_DT mixed_JJ strategy_NN Nash_NNP equilibrium_NN ._.
We_PRP often_RB appeal_VBP to_TO the_DT concept_NN of_IN an_DT approximate_JJ ,_, or_CC -_: Nash_NNP equilibrium_NN ,_, where_WRB is_VBZ the_DT maximum_NN benefit_NN to_TO any_DT agent_NN for_IN deviating_VBG from_IN the_DT prescribed_VBN strategy_NN ._.
Thus_RB ,_, -LRB-_-LRB- r_NN -RRB-_-RRB- as_IN defined_VBN above_IN -LRB-_-LRB- #_# -RRB-_-RRB- is_VBZ such_JJ that_IN profile_NN r_NN is_VBZ an_DT -_: Nash_NNP equilibrium_NN iff_NN -LRB-_-LRB- r_NN -RRB-_-RRB- ._.
In_IN this_DT study_NN we_PRP devote_VBP particular_JJ attention_NN to_TO games_NNS that_WDT exhibit_VBP symmetry_NN with_IN respect_NN to_TO payoffs_NNS ,_, rendering_VBG agents_NNS strategically_RB identical_JJ ._.
DEFINITION_NN #_# ._.
A_DT game_NN -LSB-_-LRB- I_PRP ,_, -LCB-_-LRB- Ri_NNP -RCB-_-RRB- ,_, -LCB-_-LRB- ui_NN -LRB-_-LRB- r_NN -RRB-_-RRB- -RCB-_-RRB- -RSB-_-RRB- is_VBZ symmetric_JJ if_IN for_IN all_DT i_FW ,_, j_NN I_PRP ,_, -LRB-_-LRB- a_DT -RRB-_-RRB- Ri_NN =_JJ Rj_NN and_CC -LRB-_-LRB- b_LS -RRB-_-RRB- ui_NN -LRB-_-LRB- ri_NN ,_, ri_NN -RRB-_-RRB- =_JJ uj_NN -LRB-_-LRB- rj_NN ,_, rj_NN -RRB-_-RRB- whenever_WRB ri_NN =_JJ rj_NN and_CC ri_NN =_JJ rj_NN 3_CD ._.
THE_DT MODEL_NN We_PRP model_VBP the_DT strategic_JJ interactions_NNS between_IN the_DT designer_NN of_IN the_DT mechanism_NN and_CC its_PRP$ participants_NNS as_IN a_DT two-stage_JJ game_NN ._.
The_DT designer_NN moves_VBZ first_RB by_IN selecting_VBG a_DT value_NN ,_, ,_, from_IN a_DT set_NN of_IN allowable_JJ mechanism_NN settings_NNS ,_, ._.
All_PDT the_DT participant_NN agents_NNS observe_VBP the_DT mechanism_NN parameter_NN and_CC move_VB simultaneously_RB thereafter_RB ._.
For_IN example_NN ,_, the_DT designer_NN could_MD be_VB deciding_VBG between_IN a_DT first-price_NN and_CC second-price_JJ sealed-bid_JJ auction_NN mechanisms_NNS ,_, with_IN the_DT presumption_NN that_WDT after_IN the_DT choice_NN has_VBZ been_VBN made_VBN ,_, the_DT bidders_NNS will_MD participate_VB with_IN full_JJ awareness_NN of_IN the_DT auction_NN rules_NNS ._.
Since_IN the_DT participants_NNS play_VBP with_IN full_JJ knowledge_NN of_IN the_DT mechanism_NN parameter_NN ,_, we_PRP define_VBP a_DT game_NN between_IN them_PRP in_IN the_DT second_JJ stage_NN as_IN =_JJ -LSB-_-LRB- I_PRP ,_, -LCB-_-LRB- Ri_NNP -RCB-_-RRB- ,_, -LCB-_-LRB- ui_NN -LRB-_-LRB- r_NN ,_, -RRB-_-RRB- -RCB-_-RRB- -RSB-_-RRB- ._.
We_PRP refer_VBP to_TO as_IN a_DT game_NN induced_VBN by_IN ._.
Let_VB N_NNP -LRB-_-LRB- -RRB-_-RRB- be_VB the_DT set_NN of_IN strategy_NN profiles_NNS considered_VBN solutions_NNS of_IN the_DT game_NN ._.
#_# Suppose_VB that_IN the_DT goal_NN of_IN the_DT designer_NN is_VBZ to_TO optimize_VB the_DT value_NN of_IN some_DT welfare_NN function_NN ,_, W_NN -LRB-_-LRB- r_NN ,_, -RRB-_-RRB- ,_, dependent_JJ on_IN the_DT mechanism_NN parameter_NN and_CC resulting_VBG play_NN ,_, r_NN ._.
We_PRP define_VBP a_DT pessimistic_JJ measure_NN ,_, W_NN -LRB-_-LRB- R_NN ,_, -RRB-_-RRB- =_JJ inf_NN -LCB-_-LRB- W_NN -LRB-_-LRB- r_NN ,_, -RRB-_-RRB- :_: r_NN R_NN -RCB-_-RRB- ,_, representing_VBG the_DT worst-case_JJ welfare_NN of_IN the_DT game_NN induced_VBN by_IN ,_, assuming_VBG that_IN agents_NNS play_VBP some_DT joint_JJ strategy_NN in_IN R_NN ._.
Typically_RB we_PRP care_VBP about_IN W_NN -LRB-_-LRB- N_NN -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- ,_, the_DT worst-case_JJ outcome_NN of_IN playing_VBG some_DT solution_NN ._.
#_# On_IN some_DT problems_NNS we_PRP can_MD gain_VB considerable_JJ advantage_NN by_IN using_VBG an_DT aggregation_NN function_NN to_TO map_VB the_DT welfare_NN outcome_NN of_IN a_DT game_NN 3_CD We_PRP generally_RB adopt_VB Nash_NNP equilibrium_NN as_IN the_DT solution_NN concept_NN ,_, and_CC thus_RB take_VB N_NN -LRB-_-LRB- -RRB-_-RRB- to_TO be_VB the_DT set_NN of_IN equilibria_NNS ._.
However_RB ,_, much_RB of_IN the_DT methodology_NN developed_VBN here_RB could_MD be_VB employed_VBN with_IN alternative_JJ criteria_NNS for_IN deriving_VBG agent_NN behavior_NN from_IN a_DT game_NN definition_NN ._.
4_CD Again_RB ,_, alternatives_NNS are_VBP available_JJ ._.
For_IN example_NN ,_, if_IN one_CD has_VBZ a_DT probability_NN distribution_NN over_IN the_DT solution_NN set_VBN N_NN -LRB-_-LRB- -RRB-_-RRB- ,_, it_PRP would_MD be_VB natural_JJ to_TO take_VB the_DT expectation_NN of_IN W_NN -LRB-_-LRB- r_NN ,_, -RRB-_-RRB- instead_RB ._.
307_CD specified_VBN in_IN terms_NNS of_IN agent_NN strategies_NNS to_TO an_DT equivalent_JJ welfare_NN outcome_NN specified_VBN in_IN terms_NNS of_IN a_DT lower-dimensional_JJ summary_NN ._.
DEFINITION_NN #_# ._.
A_DT function_NN :_: R1_NN Rm_NN Rq_NN is_VBZ an_DT aggregation_NN function_NN if_IN m_NN q_NN and_CC W_NN -LRB-_-LRB- r_NN ,_, -RRB-_-RRB- =_JJ V_NN -LRB-_-LRB- -LRB-_-LRB- r_NN -RRB-_-RRB- ,_, -RRB-_-RRB- for_IN some_DT function_NN V_NN ._.
We_PRP overload_NN the_DT function_NN symbol_NN to_TO apply_VB to_TO sets_NNS of_IN strategy_NN profiles_NNS :_: -LRB-_-LRB- R_NN -RRB-_-RRB- =_JJ -LCB-_-LRB- -LRB-_-LRB- r_NN -RRB-_-RRB- :_: r_NN R_NN -RCB-_-RRB- ._.
For_IN convenience_NN of_IN exposition_NN ,_, we_PRP write_VBP -LRB-_-LRB- -RRB-_-RRB- to_TO mean_VB -LRB-_-LRB- N_NN -LRB-_-LRB- -RRB-_-RRB- -RRB-_-RRB- ._.
Using_VBG an_DT aggregation_NN function_NN yields_VBZ a_DT more_RBR compact_JJ representation_NN of_IN strategy_NN profiles_NNS ._.
For_IN example_NN ,_, suppose-as_NN in_IN our_PRP$ application_NN below-that_NN an_DT agent_NN ''_'' s_NNS strategy_NN is_VBZ defined_VBN by_IN a_DT numeric_JJ parameter_NN ._.
If_IN all_DT we_PRP care_VBP about_RB is_VBZ the_DT total_JJ value_NN played_VBD ,_, we_PRP may_MD take_VB -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ Pm_NN i_FW =_JJ #_# ai_VBP ._.
If_IN we_PRP have_VBP chosen_VBN our_PRP$ aggregator_NN carefully_RB ,_, we_PRP may_MD also_RB capture_VB structure_NN not_RB obvious_JJ otherwise_RB ._.
For_IN example_NN ,_, -LRB-_-LRB- -RRB-_-RRB- could_MD be_VB decreasing_VBG in_IN ,_, whereas_IN N_NN -LRB-_-LRB- -RRB-_-RRB- might_MD have_VB a_DT more_RBR complex_JJ structure_NN ._.
Given_VBN a_DT description_NN of_IN the_DT solution_NN correspondence_NN N_NN -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- equivalently_RB ,_, -LRB-_-LRB- -RRB-_-RRB- -RRB-_-RRB- ,_, the_DT designer_NN faces_VBZ a_DT standard_JJ optimization_NN problem_NN ._.
Alternatively_RB ,_, given_VBN a_DT simulator_NN that_WDT could_MD produce_VB an_DT unbiased_JJ sample_NN from_IN the_DT distribution_NN of_IN W_NN -LRB-_-LRB- N_NN -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- for_IN any_DT ,_, the_DT designer_NN would_MD be_VB faced_VBN with_IN another_DT much_JJ appreciated_VBN problem_NN in_IN the_DT literature_NN :_: simulation_NN optimization_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
However_RB ,_, even_RB for_IN a_DT game_NN with_IN known_JJ payoffs_NNS it_PRP may_MD be_VB computationally_RB intractable_JJ to_TO solve_VB for_IN Nash_NNP equilibria_NNP ,_, particularly_RB if_IN the_DT game_NN has_VBZ large_JJ or_CC infinite_JJ strategy_NN sets_NNS ._.
Additionally_RB ,_, we_PRP wish_VBP to_TO study_VB games_NNS where_WRB the_DT payoffs_NNS are_VBP not_RB explicitly_RB given_VBN ,_, but_CC must_MD be_VB determined_VBN from_IN simulation_NN or_CC other_JJ experience_NN with_IN the_DT game_NN ._.
#_# Accordingly_RB ,_, we_PRP assume_VBP that_IN we_PRP are_VBP given_VBN a_DT -LRB-_-LRB- possibly_RB noisy_JJ -RRB-_-RRB- data_NNS set_NN of_IN payoff_NN realizations_NNS :_: Do_VBP =_JJ -LCB-_-LRB- -LRB-_-LRB- #_# ,_, a1_NN ,_, U1_NN -RRB-_-RRB- ,_, ..._: ,_, -LRB-_-LRB- k_NN ,_, ak_NN ,_, Uk_NN -RRB-_-RRB- -RCB-_-RRB- ,_, where_WRB for_IN every_DT data_NN point_NN i_FW is_VBZ the_DT observed_VBN mechanism_NN parameter_NN setting_NN ,_, ai_VBP is_VBZ the_DT observed_VBN pure_JJ strategy_NN profile_NN of_IN the_DT participants_NNS ,_, and_CC Ui_NN is_VBZ the_DT corresponding_JJ realization_NN of_IN agent_NN payoffs_NNS ._.
We_PRP may_MD also_RB have_VB additional_JJ data_NNS generated_VBN by_IN a_DT -LRB-_-LRB- possibly_RB noisy_JJ -RRB-_-RRB- simulator_NN :_: Ds_NNS =_JJ -LCB-_-LRB- -LRB-_-LRB- k_NN +_CC #_# ,_, ak_NN +_CC #_# ,_, Uk_NN +_CC #_# -RRB-_-RRB- ,_, ..._: ,_, -LRB-_-LRB- k_NN +_CC l_NN ,_, ak_NN +_CC l_NN ,_, Uk_NN +_CC l_NN -RRB-_-RRB- -RCB-_-RRB- ._.
Let_VB D_NN =_JJ -LCB-_-LRB- Do_VBP ,_, Ds_NNS -RCB-_-RRB- be_VB the_DT combined_JJ data_NN set_NN ._.
-LRB-_-LRB- Either_CC Do_VBP or_CC Ds_NNS may_MD be_VB null_JJ for_IN a_DT particular_JJ problem_NN ._. -RRB-_-RRB-
In_IN the_DT remainder_NN of_IN this_DT paper_NN ,_, we_PRP apply_VBP our_PRP$ modeling_NN approach_NN ,_, together_RB with_IN several_JJ empirical_JJ game-theoretic_JJ methods_NNS ,_, in_IN order_NN to_TO answer_VB questions_NNS regarding_VBG the_DT design_NN of_IN the_DT TAC_NN /_: SCM_NNP scenario_NN ._.
4_LS ._.
EMPIRICAL_JJ DESIGN_NN ANALYSIS_NN Since_IN our_PRP$ data_NN comes_VBZ in_IN the_DT form_NN of_IN payoff_NN experience_NN and_CC not_RB as_IN the_DT value_NN of_IN an_DT objective_JJ function_NN for_IN given_VBN settings_NNS of_IN the_DT control_NN variable_JJ ,_, we_PRP can_MD no_RB longer_RB rely_VB on_IN the_DT methods_NNS for_IN optimizing_VBG functions_NNS using_VBG simulations_NNS ._.
Indeed_RB ,_, a_DT fundamental_JJ aspect_NN of_IN our_PRP$ design_NN problem_NN involves_VBZ estimating_VBG the_DT Nash_NNP equilibrium_NN correspondence_NN ._.
Furthermore_RB ,_, we_PRP can_MD not_RB rely_VB directly_RB on_IN the_DT convergence_NN results_VBZ that_IN abound_VBP in_IN the_DT simulation_NN optimization_NN literature_NN ,_, and_CC must_MD establish_VB probabilistic_JJ analysis_NN methods_NNS tailored_VBN for_IN our_PRP$ problem_NN setting_VBG ._.
4_LS ._.
#_# TAC_NN /_: SCM_NNP Design_NNP Problem_NNP We_PRP describe_VBP our_PRP$ empirical_JJ design_NN analysis_NN methods_NNS by_IN presenting_VBG a_DT detailed_JJ application_NN to_TO the_DT TAC_NN /_: SCM_NNP scenario_NN introduced_VBN above_IN ._.
Recall_VB that_DT during_IN the_DT ####_CD tournament_NN ,_, the_DT designers_NNS of_IN the_DT supplychain_NN game_NN chose_VBD to_TO dramatically_RB increase_VB storage_NN costs_NNS as_IN a_DT measure_NN aimed_VBN at_IN curbing_VBG day-0_JJ procurement_NN ,_, to_TO little_JJ avail_NN ._.
Here_RB we_PRP systematically_RB explore_VBP the_DT relationship_NN between_IN storage_NN costs_NNS and_CC 5_CD This_DT is_VBZ often_RB the_DT case_NN for_IN real_JJ games_NNS of_IN interest_NN ,_, where_WRB natural_JJ language_NN or_CC algorithmic_JJ descriptions_NNS may_MD substitute_VB for_IN a_DT formal_JJ specification_NN of_IN strategy_NN and_CC payoff_NN functions_NNS ._.
the_DT aggregate_NN quantity_NN of_IN components_NNS procured_VBN on_IN day_NN #_# in_IN equilibrium_NN ._.
In_IN doing_VBG so_RB ,_, we_PRP consider_VBP several_JJ questions_NNS raised_VBN during_IN and_CC after_IN the_DT tournament_NN ._.
First_RB ,_, does_VBZ increasing_VBG storage_NN costs_NNS actually_RB reduce_VB day-0_JJ procurement_NN ?_.
Second_RB ,_, was_VBD the_DT excessive_JJ day-0_NN procurement_NN that_WDT was_VBD observed_VBN during_IN the_DT ####_CD tournament_NN rational_JJ ?_.
And_CC third_JJ ,_, could_MD increasing_VBG storage_NN costs_NNS sufficiently_RB have_VBP reduced_VBN day-0_JJ procurement_NN to_TO an_DT acceptable_JJ level_NN ,_, and_CC if_IN so_RB ,_, what_WP should_MD the_DT setting_NN of_IN storage_NN costs_NNS have_VBP been_VBN ?_.
It_PRP is_VBZ this_DT third_JJ question_NN that_WDT defines_VBZ the_DT mechanism_NN design_NN aspect_NN of_IN our_PRP$ analysis_NN ._.
#_# To_TO apply_VB our_PRP$ methods_NNS ,_, we_PRP must_MD specify_VB the_DT agent_NN strategy_NN sets_NNS ,_, the_DT designer_NN ''_'' s_NNS welfare_NN function_NN ,_, the_DT mechanism_NN parameter_NN space_NN ,_, and_CC the_DT source_NN of_IN data_NNS ._.
We_PRP restrict_VBP the_DT agent_NN strategies_NNS to_TO be_VB a_DT multiplier_NN on_IN the_DT quantity_NN of_IN the_DT day-0_NN requests_NNS by_IN one_CD of_IN the_DT finalists_NNS ,_, Deep_NNP Maize_NNP ,_, in_IN the_DT ####_CD TAC_NN /_: SCM_NNP tournament_NN ._.
We_PRP further_RB restrict_VBP it_PRP to_TO the_DT set_NN -LSB-_-LRB- #_# ,_, #_# ._.
#_# -RSB-_-RRB- ,_, since_IN any_DT strategy_NN below_IN #_# is_VBZ illegal_JJ and_CC strategies_NNS above_IN #_# ._.
#_# are_VBP extremely_RB aggressive_JJ -LRB-_-LRB- thus_RB unlikely_JJ to_TO provide_VB refuting_VBG deviations_NNS beyond_IN those_DT available_JJ from_IN included_VBN strategies_NNS ,_, and_CC certainly_RB not_RB part_NN of_IN any_DT desirable_JJ equilibrium_NN -RRB-_-RRB- ._.
All_DT other_JJ behavior_NN is_VBZ based_VBN on_IN the_DT behavior_NN of_IN Deep_NNP Maize_NNP and_CC is_VBZ identical_JJ for_IN all_DT agents_NNS ._.
This_DT choice_NN can_MD provide_VB only_RB an_DT estimate_NN of_IN the_DT actual_JJ tournament_NN behavior_NN of_IN a_DT typical_JJ agent_NN ._.
However_RB ,_, we_PRP believe_VBP that_IN the_DT general_JJ form_NN of_IN the_DT results_NNS should_MD be_VB robust_JJ to_TO changes_NNS in_IN the_DT full_JJ agent_NN behavior_NN ._.
We_PRP model_VBP the_DT designer_NN ''_'' s_NNS welfare_NN function_NN as_IN a_DT threshold_NN on_IN the_DT sum_NN of_IN day-0_JJ purchases_NNS ._.
Let_VB -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ P6_NN i_FW =_JJ #_# ai_VBP be_VB the_DT aggregation_NN function_NN representing_VBG the_DT sum_NN of_IN day-0_JJ procurement_NN of_IN the_DT six_CD agents_NNS participating_VBG in_IN a_DT particular_JJ supply-chain_JJ game_NN -LRB-_-LRB- for_IN mixed_JJ strategy_NN profiles_NNS s_NNS ,_, we_PRP take_VBP expectation_NN of_IN with_IN respect_NN to_TO the_DT mixture_NN -RRB-_-RRB- ._.
The_DT designer_NN ''_'' s_NNS welfare_NN function_NN W_NN -LRB-_-LRB- N_NN -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- is_VBZ then_RB given_VBN by_IN I_PRP -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RCB-_-RRB- ,_, where_WRB is_VBZ the_DT maximum_NN acceptable_JJ level_NN of_IN day-0_JJ procurement_NN and_CC I_PRP is_VBZ the_DT indicator_NN function_NN ._.
The_DT designer_NN selects_VBZ a_DT value_NN of_IN storage_NN costs_NNS ,_, expressed_VBN as_IN an_DT annual_JJ percentage_NN of_IN the_DT baseline_NN value_NN of_IN components_NNS in_IN the_DT inventory_NN -LRB-_-LRB- charged_VBN daily_RB -RRB-_-RRB- ,_, from_IN the_DT set_NN =_JJ R_NN +_CC ._.
Since_IN the_DT designer_NN ''_'' s_NNS decision_NN depends_VBZ only_RB on_IN -LRB-_-LRB- -RRB-_-RRB- ,_, we_PRP present_VBP all_DT of_IN our_PRP$ results_NNS in_IN terms_NNS of_IN the_DT value_NN of_IN the_DT aggregation_NN function_NN ._.
4_LS ._.
#_# Estimating_VBG Nash_NNP Equilibria_NNP The_DT objective_NN of_IN TAC_NN /_: SCM_NNP agents_NNS is_VBZ to_TO maximize_VB profits_NNS realized_VBN over_IN a_DT game_NN instance_NN ._.
Thus_RB ,_, if_IN we_PRP fix_VBP a_DT strategy_NN for_IN each_DT agent_NN at_IN the_DT beginning_NN of_IN the_DT simulation_NN and_CC record_VB the_DT corresponding_JJ profits_NNS at_IN the_DT end_NN ,_, we_PRP will_MD have_VB obtained_VBN a_DT data_NN point_NN in_IN the_DT form_NN -LRB-_-LRB- a_DT ,_, U_NNP -LRB-_-LRB- a_DT -RRB-_-RRB- -RRB-_-RRB- ._.
If_IN we_PRP also_RB have_VBP fixed_VBN the_DT parameter_NN of_IN the_DT simulator_NN ,_, the_DT resulting_VBG data_NNS point_NN becomes_VBZ part_NN of_IN our_PRP$ data_NNS set_VBP D_NN ._.
This_DT data_NN set_NN ,_, then_RB ,_, contains_VBZ data_NNS only_RB in_IN the_DT form_NN of_IN pure_JJ strategies_NNS of_IN players_NNS and_CC their_PRP$ corresponding_JJ payoffs_NNS ,_, and_CC ,_, consequently_RB ,_, in_IN order_NN to_TO formulate_VB the_DT designer_NN ''_'' s_NNS problem_NN as_IN optimization_NN ,_, we_PRP must_MD first_RB determine_VB or_CC approximate_JJ the_DT set_NN of_IN Nash_NNP equilibria_NNS of_IN each_DT game_NN ._.
Thus_RB ,_, we_PRP need_VBP methods_NNS for_IN approximating_VBG Nash_NNP equilibria_NNS for_IN infinite_JJ games_NNS ._.
Below_IN ,_, we_PRP describe_VBP the_DT two_CD methods_NNS we_PRP used_VBD in_IN our_PRP$ study_NN ._.
The_DT first_JJ has_VBZ been_VBN explored_VBN empirically_RB before_RB ,_, whereas_IN the_DT second_JJ is_VBZ introduced_VBN here_RB as_IN the_DT method_NN specifically_RB designed_VBN to_TO approximate_JJ a_DT set_NN of_IN Nash_NNP equilibria_NNP ._.
4_LS ._.
#_# ._.
#_# Payoff_NNP Function_NN Approximation_NN The_DT first_JJ method_NN for_IN estimating_VBG Nash_NNP equilibria_NNS based_VBN on_IN data_NNS uses_VBZ supervised_JJ learning_VBG to_TO approximate_JJ payoff_NN functions_NNS of_IN mech6_NN We_PRP do_VBP not_RB address_VB whether_IN and_CC how_WRB other_JJ measures_NNS -LRB-_-LRB- e_LS ._.
g_NN ._.
,_, constraining_VBG procurement_NN directly_RB -RRB-_-RRB- could_MD have_VB achieved_VBN design_NN objectives_NNS ._.
Our_PRP$ approach_NN takes_VBZ as_IN given_VBN some_DT set_NN of_IN design_NN options_NNS ,_, in_IN this_DT case_NN defined_VBN by_IN the_DT storage_NN cost_NN parameter_NN ._.
In_IN principle_NN our_PRP$ methods_NNS could_MD be_VB applied_VBN to_TO a_DT different_JJ or_CC larger_JJR design_NN space_NN ,_, though_IN with_IN corresponding_JJ complexity_NN growth_NN ._.
308_CD anism_NN participants_NNS from_IN a_DT data_NN set_NN of_IN game_NN experience_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
Once_RB approximate_JJ payoff_NN functions_NNS are_VBP available_JJ for_IN all_DT players_NNS ,_, the_DT Nash_NNP equilibria_NNS may_MD be_VB either_CC found_VBN analytically_RB or_CC approximated_VBN using_VBG numerical_JJ techniques_NNS ,_, depending_VBG on_IN the_DT learning_NN model_NN ._.
In_IN what_WDT follows_VBZ ,_, we_PRP estimate_VBP only_RB a_DT sample_NN Nash_NNP equilibrium_NN using_VBG this_DT technique_NN ,_, although_IN this_DT restriction_NN can_MD be_VB removed_VBN at_IN the_DT expense_NN of_IN additional_JJ computation_NN time_NN ._.
One_CD advantage_NN of_IN this_DT method_NN is_VBZ that_IN it_PRP can_MD be_VB applied_VBN to_TO any_DT data_NNS set_NN and_CC does_VBZ not_RB require_VB the_DT use_NN of_IN a_DT simulator_NN ._.
Thus_RB ,_, we_PRP can_MD apply_VB it_PRP when_WRB Ds_NNS =_JJ ._.
If_IN a_DT simulator_NN is_VBZ available_JJ ,_, we_PRP can_MD generate_VB additional_JJ data_NNS to_TO build_VB confidence_NN in_IN our_PRP$ initial_JJ estimates_NNS ._.
#_# We_PRP tried_VBD the_DT following_VBG methods_NNS for_IN approximating_VBG payoff_NN functions_NNS :_: quadratic_JJ regression_NN -LRB-_-LRB- QR_NN -RRB-_-RRB- ,_, locally_RB weighted_JJ average_NN -LRB-_-LRB- LWA_NN -RRB-_-RRB- ,_, and_CC locally_RB weighted_JJ linear_JJ regression_NN -LRB-_-LRB- LWLR_NN -RRB-_-RRB- ._.
We_PRP also_RB used_VBD control_JJ variates_NNS to_TO reduce_VB the_DT variance_NN of_IN payoff_NN estimates_NNS ,_, as_IN in_IN our_PRP$ previous_JJ empirical_JJ game-theoretic_JJ analysis_NN of_IN TAC_NN /_: SCM-03_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
The_DT quadratic_JJ regression_NN model_NN makes_VBZ it_PRP possible_JJ to_TO compute_VB equilibria_NNS of_IN the_DT learned_VBN game_NN analytically_RB ._.
For_IN the_DT other_JJ methods_NNS we_PRP applied_VBD replicator_NN dynamics_NNS -LSB-_-LRB- #_# -RSB-_-RRB- to_TO a_DT discrete_JJ approximation_NN of_IN the_DT learned_VBN game_NN ._.
The_DT expected_VBN total_JJ day-0_JJ procurement_NN in_IN equilibrium_NN was_VBD taken_VBN as_IN the_DT estimate_NN of_IN an_DT outcome_NN ._.
4_LS ._.
#_# ._.
#_# Search_VB in_IN Strategy_NNP Profile_NNP Space_NNP When_WRB we_PRP have_VBP access_NN to_TO a_DT simulator_NN ,_, we_PRP can_MD also_RB use_VB directed_VBN search_NN through_IN profile_NN space_NN to_TO estimate_VB the_DT set_NN of_IN Nash_NNP equilibria_NNP ,_, which_WDT we_PRP describe_VBP here_RB after_IN presenting_VBG some_DT additional_JJ notation_NN ._.
DEFINITION_NN #_# ._.
A_DT strategic_JJ neighbor_NN of_IN a_DT pure_JJ strategy_NN profile_NN a_DT is_VBZ a_DT profile_NN that_WDT is_VBZ identical_JJ to_TO a_DT in_IN all_DT but_IN one_CD strategy_NN ._.
We_PRP define_VBP Snb_NN -LRB-_-LRB- a_DT ,_, D_NN -RRB-_-RRB- as_IN the_DT set_NN of_IN all_DT strategic_JJ neighbors_NNS of_IN a_DT available_JJ in_IN the_DT data_NN set_NN D_NN ._.
Similarly_RB ,_, we_PRP define_VBP Snb_NN -LRB-_-LRB- a_DT ,_, D_NN -RRB-_-RRB- to_TO be_VB all_DT strategic_JJ neighbors_NNS of_IN a_DT not_RB in_IN D_NN ._.
Finally_RB ,_, for_IN any_DT a_DT Snb_NN -LRB-_-LRB- a_DT ,_, D_NN -RRB-_-RRB- we_PRP define_VBP the_DT deviating_VBG agent_NN as_IN i_FW -LRB-_-LRB- a_DT ,_, a_DT -RRB-_-RRB- ._.
DEFINITION_NN #_# ._.
The_DT -_: bound_VBN ,_, ,_, of_IN a_DT pure_JJ strategy_NN profile_NN a_DT is_VBZ defined_VBN as_IN maxa_NN Snb_NN -LRB-_-LRB- a_DT ,_, D_NN -RRB-_-RRB- max_NN -LCB-_-LRB- ui_NN -LRB-_-LRB- a_DT ,_, a_DT -RRB-_-RRB- -LRB-_-LRB- a_DT -RRB-_-RRB- ui_NN -LRB-_-LRB- a_DT ,_, a_DT -RRB-_-RRB- -LRB-_-LRB- a_DT -RRB-_-RRB- ,_, #_# -RCB-_-RRB- ._.
We_PRP say_VBP that_IN a_DT is_VBZ a_DT candidate_NN -_: equilibrium_NN for_IN ._.
When_WRB Snb_NNP -LRB-_-LRB- a_DT ,_, D_NN -RRB-_-RRB- =_JJ -LRB-_-LRB- i_FW ._.
e_LS ._.
,_, all_DT strategic_JJ neighbors_NNS are_VBP represented_VBN in_IN the_DT data_NNS -RRB-_-RRB- ,_, a_DT is_VBZ confirmed_VBN as_IN an_DT -_: Nash_NNP equilibrium_NN ._.
Our_PRP$ search_NN method_NN operates_VBZ by_IN exploring_VBG deviations_NNS from_IN candidate_NN equilibria_NNS ._.
We_PRP refer_VBP to_TO it_PRP as_IN BestFirstSearch_NNP ,_, as_IN it_PRP selects_VBZ with_IN probability_NN one_CD a_DT strategy_NN profile_NN a_DT Snb_NN -LRB-_-LRB- a_DT ,_, D_NN -RRB-_-RRB- that_WDT has_VBZ the_DT smallest_JJS in_IN D_NN ._.
Finally_RB we_PRP define_VBP an_DT estimator_NN for_IN a_DT set_NN of_IN Nash_NNP equilibria_NNP ._.
DEFINITION_NN #_# ._.
For_IN a_DT set_VBN K_NN ,_, define_VB Co_NNP -LRB-_-LRB- K_NNP -RRB-_-RRB- to_TO be_VB the_DT convex_NN hull_NN of_IN K_NN ._.
Let_VB B_NNP be_VB the_DT set_NN of_IN candidates_NNS at_IN level_NN ._.
We_PRP define_VBP -LRB-_-LRB- -RRB-_-RRB- =_JJ Co_NNP -LRB-_-LRB- -LCB-_-LRB- -LRB-_-LRB- a_DT -RRB-_-RRB- :_: a_DT B_NN -RCB-_-RRB- -RRB-_-RRB- for_IN a_DT fixed_VBN to_TO be_VB an_DT estimator_NN of_IN -LRB-_-LRB- -RRB-_-RRB- ._.
In_IN words_NNS ,_, the_DT estimate_NN of_IN a_DT set_NN of_IN equilibrium_NN outcomes_NNS is_VBZ the_DT convex_NN hull_NN of_IN all_DT aggregated_JJ strategy_NN profiles_NNS with_IN -_: bound_VBN below_IN some_DT fixed_VBN ._.
This_DT definition_NN allows_VBZ us_PRP to_TO exploit_VB structure_NN arising_VBG from_IN the_DT aggregation_NN function_NN ._.
If_IN two_CD profiles_NNS are_VBP close_RB in_IN terms_NNS of_IN aggregation_NN values_NNS ,_, they_PRP may_MD be_VB likely_JJ to_TO have_VB similar_JJ -_: bounds_NNS ._.
In_IN particular_JJ ,_, if_IN one_CD is_VBZ an_DT equilibrium_NN ,_, the_DT other_JJ may_MD be_VB as_RB well_RB ._.
We_PRP present_VBP some_DT theoretical_JJ support_NN for_IN this_DT method_NN of_IN estimating_VBG the_DT set_NN of_IN Nash_NNP equilibria_NNP below_IN ._.
Since_IN the_DT game_NN we_PRP are_VBP interested_JJ in_IN is_VBZ infinite_JJ ,_, it_PRP is_VBZ necessary_JJ to_TO terminate_VB BestFirstSearch_NNP before_IN exploring_VBG the_DT entire_JJ space_NN of_IN strat7_NN For_IN example_NN ,_, we_PRP can_MD use_VB active_JJ learning_NN techniques_NNS -LSB-_-LRB- #_# -RSB-_-RRB- to_TO improve_VB the_DT quality_NN of_IN payoff_NN function_NN approximation_NN ._.
In_IN this_DT work_NN ,_, we_PRP instead_RB concentrate_VBP on_IN search_NN in_IN strategy_NN profile_NN space_NN ._.
egy_NN profiles_NNS ._.
We_PRP currently_RB determine_VBP termination_NN time_NN in_IN a_DT somewhat_RB ad-hoc_JJ manner_NN ,_, based_VBN on_IN observations_NNS about_IN the_DT current_JJ set_NN of_IN candidate_NN equilibria_NNS ._.
#_# 4_CD ._.
#_# Data_NNS Generation_NNP Our_PRP$ data_NNS was_VBD collected_VBN by_IN simulating_VBG TAC_NN /_: SCM_NNP games_NNS on_IN a_DT local_JJ version_NN of_IN the_DT ####_CD TAC_NN /_: SCM_NNP server_NN ,_, which_WDT has_VBZ a_DT configuration_NN setting_NN for_IN the_DT storage_NN cost_NN ._.
Agent_NNP strategies_NNS in_IN simulated_JJ games_NNS were_VBD selected_VBN from_IN the_DT set_VBN -LCB-_-LRB- #_# ,_, #_# ._.
#_# ,_, #_# ._.
#_# ,_, ..._: ,_, #_# ._.
#_# -RCB-_-RRB- in_IN order_NN to_TO have_VB positive_JJ probability_NN of_IN generating_VBG strategic_JJ neighbors_NNS ._.
#_# A_DT baseline_NN data_NN set_NN Do_VBP was_VBD generated_VBN by_IN sampling_NN ##_CD randomly_RB generated_VBN strategy_NN profiles_NNS for_IN each_DT -LCB-_-LRB- #_# ,_, ##_CD ,_, ###_CD ,_, ###_CD ,_, ###_CD -RCB-_-RRB- ._.
Between_IN #_# and_CC ##_CD games_NNS were_VBD run_VBN for_IN each_DT profile_NN after_IN discarding_VBG games_NNS that_WDT had_VBD various_JJ flaws_NNS ._.
##_NN We_PRP used_VBD search_NN to_TO generate_VB a_DT simulated_JJ data_NN set_NN Ds_NNS ,_, performing_VBG between_IN ##_CD and_CC ##_CD iterations_NNS of_IN BestFirstSearch_NNP for_IN each_DT of_IN the_DT above_JJ settings_NNS of_IN ._.
Since_IN simulation_NN cost_NN is_VBZ extremely_RB high_JJ -LRB-_-LRB- a_DT game_NN takes_VBZ nearly_RB #_# hour_NN to_TO run_VB -RRB-_-RRB- ,_, we_PRP were_VBD able_JJ to_TO run_VB a_DT total_NN of_IN ####_CD games_NNS over_IN the_DT span_NN of_IN more_JJR than_IN six_CD months_NNS ._.
For_IN comparison_NN ,_, to_TO get_VB the_DT entire_JJ description_NN of_IN an_DT empirical_JJ game_NN defined_VBN by_IN the_DT restricted_JJ finite_JJ joint_JJ strategy_NN space_NN for_IN each_DT value_NN of_IN -LCB-_-LRB- #_# ,_, ##_CD ,_, ###_CD ,_, ###_CD ,_, ###_CD -RCB-_-RRB- would_MD have_VB required_VBN at_IN least_JJS #####_CD games_NNS -LRB-_-LRB- sampling_NN each_DT profile_NN ##_CD times_NNS -RRB-_-RRB- ._.
4_LS ._.
#_# Results_NNS 4_CD ._.
#_# ._.
#_# Analysis_NN of_IN the_DT Baseline_NNP Data_NNP Set_VB We_PRP applied_VBD the_DT three_CD learning_VBG methods_NNS described_VBN above_IN to_TO the_DT baseline_NN data_NN set_NN Do_VBP ._.
Additionally_RB ,_, we_PRP generated_VBD an_DT estimate_NN of_IN the_DT Nash_NNP equilibrium_NN correspondence_NN ,_, -LRB-_-LRB- -RRB-_-RRB- ,_, by_IN applying_VBG Definition_NNP #_# with_IN =_JJ #_# ._.
5E6_NN ._.
The_DT results_NNS are_VBP shown_VBN in_IN Figure_NNP #_# ._.
As_IN we_PRP can_MD see_VB ,_, the_DT correspondence_NN -LRB-_-LRB- -RRB-_-RRB- has_VBZ little_JJ predictive_JJ power_NN based_VBN on_IN Do_NNP ,_, and_CC reveals_VBZ no_DT interesting_JJ structure_NN about_IN the_DT game_NN ._.
In_IN contrast_NN ,_, all_DT three_CD learning_VBG methods_NNS suggest_VBP that_IN total_JJ day-0_JJ procurement_NN is_VBZ a_DT decreasing_VBG function_NN of_IN storage_NN costs_NNS ._.
0_CD 1_CD 2_CD 3_CD 4_CD 5_CD 6_CD 7_CD 8_CD 9_CD 10_CD 0_CD ##_CD ###_CD ###_CD ###_CD Storage_NNP Cost_NN TotalDay-0Procurement_NN LWA_NN LWLR_NN QR_NN BaselineMin_NNP BaselineMax_NNP Figure_NNP #_# :_: Aggregate_NN day-0_NN procurement_NN estimates_VBZ based_VBN on_IN Do_NNP ._.
The_DT correspondence_NN -LRB-_-LRB- -RRB-_-RRB- is_VBZ the_DT interval_NN between_IN BaselineMin_NNP and_CC BaselineMax_NNP ._.
8_CD Generally_RB ,_, search_NN is_VBZ terminated_VBN once_RB the_DT set_NN of_IN candidate_NN equilibria_NNS is_VBZ small_JJ enough_RB to_TO draw_VB useful_JJ conclusions_NNS about_IN the_DT likely_JJ range_NN of_IN equilibrium_NN strategies_NNS in_IN the_DT game_NN ._.
9_CD Of_IN course_NN ,_, we_PRP do_VBP not_RB restrict_VB our_PRP$ Nash_NNP equilibrium_NN estimates_VBZ to_TO stay_VB in_IN this_DT discrete_JJ subset_NN of_IN -LSB-_-LRB- #_# ,_, #_# ._.
#_# -RSB-_-RRB- ._.
10_CD For_IN example_NN ,_, if_IN we_PRP detected_VBD that_IN any_DT agent_NN failed_VBD during_IN the_DT game_NN -LRB-_-LRB- failures_NNS included_VBD crashes_NNS ,_, network_NN connectivity_NN problems_NNS ,_, and_CC other_JJ obvious_JJ anomalies_NNS -RRB-_-RRB- ,_, the_DT game_NN would_MD be_VB thrown_VBN out_RP ._.
309_CD 4_CD ._.
#_# ._.
#_# Analysis_NN of_IN Search_VB Data_NNS To_TO corroborate_VB the_DT initial_JJ evidence_NN from_IN the_DT learning_NN methods_NNS ,_, we_PRP estimated_VBD -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- again_RB ,_, using_VBG =_JJ #_# ._.
5E6_NN -RRB-_-RRB- on_IN the_DT data_NN set_NN D_NN =_JJ -LCB-_-LRB- Do_VBP ,_, Ds_NNS -RCB-_-RRB- ,_, where_WRB Ds_NNS is_VBZ data_NN generated_VBN through_IN the_DT application_NN of_IN BestFirstSearch_NNP ._.
The_DT results_NNS of_IN this_DT estimate_NN are_VBP plotted_VBN against_IN the_DT results_NNS of_IN the_DT learning_NN methods_NNS trained_VBN on_IN Do_VBP 11_CD in_IN Figure_NNP #_# ._.
First_RB ,_, we_PRP note_VBP that_IN the_DT addition_NN of_IN the_DT search_NN data_NNS narrows_VBZ the_DT range_NN of_IN potential_JJ equilibria_NNS substantially_RB ._.
Furthermore_RB ,_, the_DT actual_JJ point_NN predictions_NNS of_IN the_DT learning_NN methods_NNS and_CC those_DT based_VBN on_IN -_: bounds_NNS after_IN search_NN are_VBP reasonably_RB close_RB ._.
Combining_VBG the_DT evidence_NN gathered_VBN from_IN these_DT two_CD very_RB different_JJ approaches_NNS to_TO estimating_VBG the_DT outcome_NN correspondence_NN yields_VBZ a_DT much_RB more_RBR compelling_JJ picture_NN of_IN the_DT relationship_NN between_IN storage_NN costs_NNS and_CC day-0_JJ procurement_NN than_IN either_CC method_NN used_VBN in_IN isolation_NN ._.
0_CD 1_CD 2_CD 3_CD 4_CD 5_CD 6_CD 7_CD 8_CD 9_CD 10_CD 0_CD ##_CD ###_CD ###_CD ###_CD Storage_NNP Cost_NN TotayDay-0Procurement_NN LWA_NN LWLR_NN QR_NN SearchMin_NNP SearchMax_NNP Figure_NNP #_# :_: Aggregate_NN day-0_NN procurement_NN estimates_VBZ based_VBN on_IN search_NN in_IN strategy_NN profile_NN space_NN compared_VBN to_TO function_VB approximation_NN techniques_NNS trained_VBN on_IN Do_NNP ._.
The_DT correspondence_NN -LRB-_-LRB- -RRB-_-RRB- for_IN D_NN =_JJ -LCB-_-LRB- Do_VBP ,_, Ds_NNS -RCB-_-RRB- is_VBZ the_DT interval_NN between_IN SearchMin_NNP and_CC SearchMax_NNP ._.
This_DT evidence_NN supports_VBZ the_DT initial_JJ intuition_NN that_WDT day-0_NN procurement_NN should_MD be_VB decreasing_VBG with_IN storage_NN costs_NNS ._.
It_PRP also_RB confirms_VBZ that_IN high_JJ levels_NNS of_IN day-0_JJ procurement_NN are_VBP a_DT rational_JJ response_NN to_TO the_DT ####_CD tournament_NN setting_NN of_IN average_JJ storage_NN cost_NN ,_, which_WDT corresponds_VBZ to_TO =_JJ ###_CD ._.
The_DT minimum_JJ prediction_NN for_IN aggregate_JJ procurement_NN at_IN this_DT level_NN of_IN storage_NN costs_NNS given_VBN by_IN any_DT experimental_JJ methods_NNS is_VBZ approximately_RB #_# ._.
This_DT is_VBZ quite_RB high_JJ ,_, as_IN it_PRP corresponds_VBZ to_TO an_DT expected_VBN commitment_NN of_IN #_# /_: #_# of_IN the_DT total_JJ supplier_NN capacity_NN for_IN the_DT entire_JJ game_NN ._.
The_DT maximum_NN prediction_NN is_VBZ considerably_RB higher_JJR at_IN #_# ._.
#_# ._.
In_IN the_DT actual_JJ ####_CD competition_NN ,_, aggregate_JJ day-0_NN procurement_NN was_VBD equivalent_JJ to_TO #_# ._.
##_NN on_IN the_DT scale_NN used_VBN here_RB -LSB-_-LRB- #_# -RSB-_-RRB- ._.
Our_PRP$ predictions_NNS underestimate_VBP this_DT outcome_NN to_TO some_DT degree_NN ,_, but_CC show_VBP that_IN any_DT rational_JJ outcome_NN was_VBD likely_JJ to_TO have_VB high_JJ day-0_NN procurement_NN ._.
4_LS ._.
#_# ._.
#_# Extrapolating_VBG the_DT Solution_NN Correspondence_NN We_PRP have_VBP reasonably_RB strong_JJ evidence_NN that_IN the_DT outcome_NN correspondence_NN is_VBZ decreasing_VBG ._.
However_RB ,_, the_DT ultimate_JJ goal_NN is_VBZ to_TO be_VB able_JJ to_TO either_DT set_VBN the_DT storage_NN cost_NN parameter_NN to_TO a_DT value_NN that_WDT would_MD curb_VB day-0_NN procurement_NN in_IN equilibrium_NN or_CC conclude_VBP that_IN this_DT is_VBZ not_RB possible_JJ ._.
To_TO answer_VB this_DT question_NN directly_RB ,_, suppose_VBP that_IN we_PRP set_VBD a_DT conservative_JJ threshold_NN =_JJ #_# on_IN aggregate_NN day-0_NN procurement_NN ._.
##_NNP Linear_NNP 11_CD It_PRP is_VBZ unclear_JJ how_WRB meaningful_JJ the_DT results_NNS of_IN learning_VBG would_MD be_VB if_IN Ds_NNS were_VBD added_VBN to_TO the_DT training_NN data_NN set_NN ._.
Indeed_RB ,_, the_DT additional_JJ data_NNS may_MD actually_RB increase_VB the_DT learning_NN variance_NN ._.
12_CD Recall_VB that_DT designer_NN ''_'' s_NNS objective_NN is_VBZ to_TO incentivize_VB aggergate_NN day-0_NN procurement_NN that_WDT is_VBZ below_IN the_DT threshold_NN ._.
Our_PRP$ threshold_NN here_RB still_RB represents_VBZ a_DT commitment_NN of_IN over_IN ##_CD %_NN of_IN the_DT suppliers_NNS ''_'' capacity_NN for_IN extrapolation_NN of_IN the_DT maximum_NN of_IN the_DT outcome_NN correspondence_NN estimated_VBN from_IN D_NN yields_NNS =_JJ ###_CD ._.
The_DT data_NNS for_IN =_JJ ###_CD were_VBD collected_VBN in_IN the_DT same_JJ way_NN as_IN for_IN other_JJ storage_NN cost_NN settings_NNS ,_, with_IN ##_NN randomly_RB generated_VBD profiles_NNS followed_VBN by_IN ##_CD iterations_NNS of_IN BestFirstSearch_NNP ._.
Figure_NNP #_# shows_VBZ the_DT detailed_JJ -_: bounds_NNS for_IN all_DT profiles_NNS in_IN terms_NNS of_IN their_PRP$ corresponding_JJ values_NNS of_IN ._.
0_CD ._.
00E_NN +_CC ##_CD 5_CD ._.
00E_NN +_CC ##_NN 1_CD ._.
00E_NN +_CC ##_NN 1_CD ._.
50E_NN +_CC ##_NN 2_CD ._.
00E_NN +_CC ##_NN 2_CD ._.
50E_CD +_CC ##_CD 3_CD ._.
00E_NN +_CC ##_CD 3_CD ._.
50E_CD +_CC ##_CD 4_CD ._.
00E_NN +_CC ##_CD 4_CD ._.
50E_CD +_CC ##_CD 5_CD ._.
00E_NN +_CC ##_NN 2_CD ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# #_# ._.
#_# Total_JJ Day-0_NN Procurement_NNP boundFigure_NNP #_# :_: Values_NNS of_IN for_IN profiles_NNS explored_VBN using_VBG search_NN when_WRB =_JJ ###_CD ._.
Strategy_NN profiles_NNS explored_VBN are_VBP presented_VBN in_IN terms_NNS of_IN the_DT corresponding_JJ values_NNS of_IN -LRB-_-LRB- a_DT -RRB-_-RRB- ._.
The_DT gray_JJ region_NN corresponds_VBZ to_TO -LRB-_-LRB- ###_CD -RRB-_-RRB- with_IN =_JJ #_# ._.
5M_NN ._.
The_DT estimated_VBN set_NN of_IN aggregate_JJ day-0_NN outcomes_NNS is_VBZ very_RB close_JJ to_TO that_DT for_IN =_JJ ###_CD ,_, indicating_VBG that_IN there_EX is_VBZ little_JJ additional_JJ benefit_NN to_TO raising_VBG storage_NN costs_NNS above_IN ###_CD ._.
Observe_VB ,_, that_IN even_RB the_DT lower_JJR bound_VBN of_IN our_PRP$ estimated_VBN set_NN of_IN Nash_NNP equilibria_NNP is_VBZ well_RB above_IN the_DT target_NN day-0_NN procurement_NN of_IN #_# ._.
Furthermore_RB ,_, payoffs_NNS to_TO agents_NNS are_VBP almost_RB always_RB negative_JJ at_IN =_JJ ###_CD ._.
Consequently_RB ,_, increasing_VBG the_DT costs_NNS further_RB would_MD be_VB undesirable_JJ even_RB if_IN day-0_JJ procurement_NN could_MD eventually_RB be_VB curbed_VBN ._.
Since_IN we_PRP are_VBP reasonably_RB confident_JJ that_IN -LRB-_-LRB- -RRB-_-RRB- is_VBZ decreasing_VBG in_IN ,_, we_PRP also_RB do_VBP not_RB expect_VB that_DT setting_VBG somewhere_RB between_IN ###_CD and_CC ###_CD will_MD achieve_VB the_DT desired_VBN result_NN ._.
We_PRP conclude_VBP that_IN it_PRP is_VBZ unlikely_JJ that_IN day-0_NN procurement_NN could_MD ever_RB be_VB reduced_VBN to_TO a_DT desirable_JJ level_NN using_VBG any_DT reasonable_JJ setting_NN of_IN the_DT storage_NN cost_NN parameter_NN ._.
That_DT our_PRP$ predictions_NNS tend_VBP to_TO underestimate_VB tournament_NN outcomes_NNS reinforces_VBZ this_DT conclusion_NN ._.
To_TO achieve_VB the_DT desired_VBN reduction_NN in_IN day-0_JJ procurement_NN requires_VBZ redesigning_VBG other_JJ aspects_NNS of_IN the_DT mechanism_NN ._.
4_LS ._.
#_# Probabilistic_NNP Analysis_NNP Our_PRP$ empirical_JJ analysis_NN has_VBZ produced_VBN evidence_NN in_IN support_NN of_IN the_DT conclusion_NN that_IN no_DT reasonable_JJ setting_NN of_IN storage_NN cost_NN was_VBD likely_JJ to_TO sufficiently_RB curb_VB excessive_JJ day-0_NN procurement_NN in_IN TAC_NN /_: SCM_NNP ''_'' ##_NN ._.
All_DT of_IN this_DT evidence_NN has_VBZ been_VBN in_IN the_DT form_NN of_IN simple_JJ interpolation_NN and_CC extrapolation_NN of_IN estimates_NNS of_IN the_DT Nash_NNP equilibrium_NN correspondence_NN ._.
These_DT estimates_NNS are_VBP based_VBN on_IN simulating_VBG game_NN instances_NNS ,_, and_CC are_VBP subject_JJ to_TO sampling_NN noise_NN contributed_VBN by_IN the_DT various_JJ stochastic_JJ elements_NNS of_IN the_DT game_NN ._.
In_IN this_DT section_NN ,_, we_PRP develop_VBP and_CC apply_VBP methods_NNS for_IN evaluating_VBG the_DT sensitivity_NN of_IN our_PRP$ -_: bound_VBN calculations_NNS to_TO such_JJ stochastic_JJ effects_NNS ._.
Suppose_VB that_IN all_DT agents_NNS have_VBP finite_JJ -LRB-_-LRB- and_CC small_JJ -RRB-_-RRB- pure_JJ strategy_NN sets_NNS ,_, A_DT ._.
Thus_RB ,_, it_PRP is_VBZ feasible_JJ to_TO sample_NN the_DT entire_JJ payoff_NN matrix_NN of_IN the_DT game_NN ._.
Additionally_RB ,_, suppose_VBP that_IN noise_NN is_VBZ additive_JJ with_IN zero-mean_JJ the_DT entire_JJ game_NN on_IN average_NN ,_, so_RB in_IN practice_NN we_PRP would_MD probably_RB want_VB the_DT threshold_NN to_TO be_VB even_RB lower_JJR ._.
310_CD and_CC finite_JJ variance_NN ,_, that_WDT is_VBZ ,_, Ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- +_CC i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- ,_, where_WRB Ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- is_VBZ the_DT observed_VBN payoff_NN to_TO i_FW when_WRB a_DT was_VBD played_VBN ,_, ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- is_VBZ the_DT actual_JJ corresponding_JJ payoff_NN ,_, and_CC i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- is_VBZ a_DT mean-zero_NN normal_JJ random_JJ variable_NN ._.
We_PRP designate_VBP the_DT known_JJ variance_NN of_IN i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- by_IN #_# i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- ._.
Thus_RB ,_, we_PRP assume_VBP that_IN i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- is_VBZ normal_JJ with_IN distribution_NN N_NN -LRB-_-LRB- #_# ,_, #_# i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- -RRB-_-RRB- ._.
We_PRP take_VBP ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- to_TO be_VB the_DT sample_NN mean_NN over_IN all_DT Ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- in_IN D_NN ,_, and_CC follow_VB Chang_NNP and_CC Huang_NNP -LSB-_-LRB- #_# -RSB-_-RRB- to_TO assume_VB that_IN we_PRP have_VBP an_DT improper_JJ prior_RB over_IN the_DT actual_JJ payoffs_NNS ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- and_CC sampling_NN was_VBD independent_JJ for_IN all_DT i_FW and_CC a_DT ._.
We_PRP also_RB rely_VBP on_IN their_PRP$ result_NN that_IN ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- |_CD ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- Zi_NN -LRB-_-LRB- a_DT -RRB-_-RRB- /_: -LSB-_-LRB- i_LS -LRB-_-LRB- a_DT -RRB-_-RRB- /_: p_NN ni_NNS -LRB-_-LRB- a_DT -RRB-_-RRB- -RSB-_-RRB- are_VBP independent_JJ with_IN posterior_JJ distributions_NNS N_NN -LRB-_-LRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- ,_, #_# i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- /_: ni_NNS -LRB-_-LRB- a_DT -RRB-_-RRB- -RRB-_-RRB- ,_, where_WRB ni_NNS -LRB-_-LRB- a_DT -RRB-_-RRB- is_VBZ the_DT number_NN of_IN samples_NNS taken_VBN of_IN payoffs_NNS to_TO i_FW for_IN pure_JJ profile_NN a_DT ,_, and_CC Zi_NNP -LRB-_-LRB- a_DT -RRB-_-RRB- N_NN -LRB-_-LRB- #_# ,_, #_# -RRB-_-RRB- ._.
We_PRP now_RB derive_VBP a_DT generic_JJ probabilistic_JJ bound_VBD that_IN a_DT profile_NN a_DT A_NN is_VBZ an_DT -_: Nash_NNP equilibrium_NN ._.
If_IN ui_NN -LRB-_-LRB- -RRB-_-RRB- |_CD ui_NN -LRB-_-LRB- -RRB-_-RRB- are_VBP independent_JJ for_IN all_DT i_FW I_PRP and_CC a_DT A_NN ,_, we_PRP have_VBP the_DT following_VBG result_NN -LRB-_-LRB- from_IN this_DT point_NN on_IN we_PRP omit_VBP conditioning_NN on_IN ui_NN -LRB-_-LRB- -RRB-_-RRB- for_IN brevity_NN -RRB-_-RRB- :_: PROPOSITION_NN #_# ._.
Pr_NNP max_NN iI_NNP max_NNP bAi_NNP ui_NN -LRB-_-LRB- b_NN ,_, ai_VBP -RRB-_-RRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ =_JJ Y_NN iI_NN Z_NN R_NN Y_NN bAi_NN \_CD ai_VBP Pr_NN -LRB-_-LRB- ui_NN -LRB-_-LRB- b_NN ,_, ai_VBP -RRB-_-RRB- u_NN +_CC -RRB-_-RRB- fui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- -LRB-_-LRB- u_NN -RRB-_-RRB- du_NNP ,_, -LRB-_-LRB- #_# -RRB-_-RRB- where_WRB fui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- -LRB-_-LRB- u_NN -RRB-_-RRB- is_VBZ the_DT pdf_NN of_IN N_NN -LRB-_-LRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- ,_, i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- -RRB-_-RRB- ._.
The_DT proofs_NNS of_IN this_DT and_CC all_DT subsequent_JJ results_NNS are_VBP in_IN the_DT Appendix_NN ._.
The_DT posterior_JJ distribution_NN of_IN the_DT optimum_JJ mean_NN of_IN n_NN samples_NNS ,_, derived_VBN by_IN Chang_NNP and_CC Huang_NNP -LSB-_-LRB- #_# -RSB-_-RRB- ,_, is_VBZ Pr_NN -LRB-_-LRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- c_NN -RRB-_-RRB- =_JJ #_# ''_'' p_NN ni_NNS -LRB-_-LRB- a_DT -RRB-_-RRB- -LRB-_-LRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- c_NN -RRB-_-RRB- i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- #_# ,_, -LRB-_-LRB- #_# -RRB-_-RRB- where_WRB a_DT A_NN and_CC -LRB-_-LRB- -RRB-_-RRB- is_VBZ the_DT N_NN -LRB-_-LRB- #_# ,_, #_# -RRB-_-RRB- distribution_NN function_NN ._.
Combining_VBG the_DT results_NNS -LRB-_-LRB- #_# -RRB-_-RRB- and_CC -LRB-_-LRB- #_# -RRB-_-RRB- ,_, we_PRP obtain_VBP a_DT probabilistic_JJ confidence_NN bound_VBD that_IN -LRB-_-LRB- a_DT -RRB-_-RRB- for_IN a_DT given_VBN ._.
Now_RB ,_, we_PRP consider_VBP cases_NNS of_IN incomplete_JJ data_NNS and_CC use_VB the_DT results_NNS we_PRP have_VBP just_RB obtained_VBN to_TO construct_VB an_DT upper_JJ bound_VBN -LRB-_-LRB- restricted_JJ to_TO profiles_NNS represented_VBN in_IN data_NNS -RRB-_-RRB- on_IN the_DT distribution_NN of_IN sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- and_CC inf_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -LRB-_-LRB- assuming_VBG that_IN both_DT are_VBP attainable_JJ -RRB-_-RRB- :_: Pr_NN -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- x_CC -RCB-_-RRB- D_NNP Pr_NNP -LCB-_-LRB- a_DT D_NN :_: -LRB-_-LRB- a_LS -RRB-_-RRB- x_CC a_DT N_NN -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- X_NN aD_NN :_: -LRB-_-LRB- a_LS -RRB-_-RRB- x_CC Pr_NN -LCB-_-LRB- a_DT N_NN -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- =_JJ X_NN aD_NN :_: -LRB-_-LRB- a_LS -RRB-_-RRB- x_CC Pr_NN -LCB-_-LRB- -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ #_# -RCB-_-RRB- ,_, where_WRB x_NN is_VBZ a_DT real_JJ number_NN and_CC D_NN indicates_VBZ that_IN the_DT upper_JJ bound_VBN accounts_NNS only_RB for_IN strategies_NNS that_WDT appear_VBP in_IN the_DT data_NN set_NN D_NN ._.
Since_IN the_DT events_NNS -LCB-_-LRB- a_DT D_NN :_: -LRB-_-LRB- a_LS -RRB-_-RRB- x_CC a_DT N_NN -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- and_CC -LCB-_-LRB- inf_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- x_CC -RCB-_-RRB- are_VBP equivalent_JJ ,_, this_DT also_RB defines_VBZ an_DT upper_JJ bound_VBN on_IN the_DT probability_NN of_IN -LCB-_-LRB- inf_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- x_CC -RCB-_-RRB- ._.
The_DT values_NNS thus_RB derived_VBN comprise_VBP the_DT Tables_NNPS #_# and_CC #_# ._.
-LRB-_-LRB- -RRB-_-RRB- =_JJ #_# =_JJ ##_NN =_JJ ###_CD <_JJR #_# ._.
#_# #_# ._.
######_NN #_# #_# ._.
###_NN <_JJR #_# #_# ._.
###_NN #_# ._.
####_NN #_# ._.
###_NN <_JJR #_# ._.
#_# #_# ._.
###_NN #_# ._.
###_NN #_# <_JJR #_# ._.
#_# #_# #_# #_# Table_NNP #_# :_: Upper_NNP bounds_VBZ on_IN the_DT distribution_NN of_IN inf_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- restricted_JJ to_TO D_NN for_IN -LCB-_-LRB- #_# ,_, ##_NN ,_, ###_CD -RCB-_-RRB- when_WRB N_NN -LRB-_-LRB- -RRB-_-RRB- is_VBZ a_DT set_NN of_IN Nash_NNP equilibria_NNP ._.
-LRB-_-LRB- -RRB-_-RRB- =_JJ ###_NN =_JJ ###_NN =_JJ ###_CD <_JJR #_# ._.
#_# #_# #_# #_# ._.
#####_NN <_JJR #_# #_# ._.
####_NN #_# ._.
###_NN #_# <_JJR #_# ._.
#_# #_# #_# #_# <_JJR #_# ._.
#_# #_# #_# #_# Table_NNP #_# :_: Upper_NNP bounds_VBZ on_IN the_DT distribution_NN of_IN inf_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- restricted_JJ to_TO D_NN for_IN -LCB-_-LRB- ###_NN ,_, ###_CD ,_, ###_CD -RCB-_-RRB- when_WRB N_NN -LRB-_-LRB- -RRB-_-RRB- is_VBZ a_DT set_NN of_IN Nash_NNP equilibria_NNP ._.
Tables_NNS #_# and_CC #_# suggest_VBP that_IN the_DT existence_NN of_IN any_DT equilibrium_NN with_IN -LRB-_-LRB- a_DT -RRB-_-RRB- <_JJR #_# ._.
#_# is_VBZ unlikely_JJ for_IN any_DT that_IN we_PRP have_VBP data_NNS for_IN ,_, although_IN this_DT judgment_NN ,_, as_IN we_PRP mentioned_VBD ,_, is_VBZ only_RB with_IN respect_NN to_TO the_DT profiles_NNS we_PRP have_VBP actually_RB sampled_VBN ._.
We_PRP can_MD then_RB accept_VB this_DT as_IN another_DT piece_NN of_IN evidence_NN that_IN the_DT designer_NN could_MD not_RB find_VB a_DT suitable_JJ setting_NN of_IN to_TO achieve_VB his_PRP$ objectives-indeed_NN ,_, the_DT designer_NN seems_VBZ unlikely_JJ to_TO achieve_VB his_PRP$ objective_NN even_RB if_IN he_PRP could_MD persuade_VB participants_NNS to_TO play_VB a_DT desirable_JJ equilibrium_NN !_.
Table_NNP #_# also_RB provides_VBZ additional_JJ evidence_NN that_IN the_DT agents_NNS in_IN the_DT 2004_CD TAC_NN /_: SCM_NNP tournament_NN were_VBD indeed_RB rational_JJ in_IN procuring_VBG large_JJ numbers_NNS of_IN components_NNS at_IN the_DT beginning_VBG fo_NN the_DT game_NN ._.
If_IN we_PRP look_VBP at_IN the_DT third_JJ column_NN of_IN this_DT table_NN ,_, which_WDT corresponds_VBZ to_TO =_JJ ###_CD ,_, we_PRP can_MD gather_VB that_IN no_DT profile_NN a_DT in_IN our_PRP$ data_NNS with_IN -LRB-_-LRB- a_DT -RRB-_-RRB- <_JJR #_# is_VBZ very_RB likely_JJ to_TO be_VB played_VBN in_IN equilibrium_NN ._.
The_DT bounds_NNS above_IN provide_VBP some_DT general_JJ evidence_NN ,_, but_CC ultimately_RB we_PRP are_VBP interested_JJ in_IN a_DT concrete_JJ probabilistic_JJ assessment_NN of_IN our_PRP$ conclusion_NN with_IN respect_NN to_TO the_DT data_NNS we_PRP have_VBP sampled_VBN ._.
Particularly_RB ,_, we_PRP would_MD like_VB to_TO say_VB something_NN about_IN what_WP happens_VBZ for_IN the_DT settings_NNS of_IN for_IN which_WDT we_PRP have_VBP no_DT data_NNS ._.
To_TO derive_VB an_DT approximate_JJ probabilistic_JJ bound_VBN on_IN the_DT probability_NN that_IN no_DT could_MD have_VB achieved_VBN the_DT designer_NN ''_'' s_NNS objective_JJ ,_, let_VB J_NN j_NN =_JJ 1j_NN ,_, be_VB a_DT partition_NN of_IN ,_, and_CC assume_VB that_IN the_DT function_NN sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- satisfies_VBZ the_DT Lipschitz_NNP condition_NN with_IN Lipschitz_NNP constant_JJ Aj_NN on_IN each_DT subset_NN j_NN ._.
##_NN Since_IN we_PRP have_VBP determined_VBN that_IN raising_VBG the_DT storage_NN cost_NN above_IN ###_CD is_VBZ undesirable_JJ due_JJ to_TO secondary_JJ considerations_NNS ,_, we_PRP restrict_VBP attention_NN to_TO =_JJ -LSB-_-LRB- #_# ,_, ###_CD -RSB-_-RRB- ._.
We_PRP now_RB define_VBP each_DT subset_NN j_NN to_TO be_VB the_DT interval_NN between_IN two_CD points_NNS for_IN which_WDT we_PRP have_VBP produced_VBN data_NNS ._.
Thus_RB ,_, =_JJ -LSB-_-LRB- #_# ,_, ##_NN -RSB-_-RRB- -LSB-_-LRB- -LRB-_-LRB- ##_CD ,_, ###_CD -RSB-_-RRB- -LSB-_-LRB- -LRB-_-LRB- ###_CD ,_, ###_CD -RSB-_-RRB- -LSB-_-LRB- -LRB-_-LRB- ###_CD ,_, ###_CD -RSB-_-RRB- -LSB-_-LRB- -LRB-_-LRB- ###_CD ,_, ###_CD -RSB-_-RRB- ,_, with_IN j_NN running_VBG between_IN #_# and_CC #_# ,_, corresponding_VBG to_TO subintervals_NNS above_IN ._.
We_PRP will_MD further_RB denote_VB each_DT j_NN by_IN -LRB-_-LRB- aj_NN ,_, bj_NN -RSB-_-RRB- ._.
##_NN Then_RB ,_, the_DT following_VBG Proposition_NN gives_VBZ us_PRP an_DT approximate_JJ upper_JJ bound15_NN on_IN the_DT probability_NN that_IN sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- ._.
PROPOSITION_NN #_# ._.
Pr_NN -LCB-_-LRB- __NN sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RCB-_-RRB- D_NN 5X_NN j_NN =_JJ #_# X_NN y_NN ,_, zD_NN :_: y_NN +_CC zcj_NN 0_CD @_IN X_NN a_DT :_: -LRB-_-LRB- a_LS -RRB-_-RRB- =_JJ z_SYM Pr_NNP -LCB-_-LRB- -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ #_# -RCB-_-RRB- 1_CD A_DT 0_CD @_IN X_NN a_DT :_: -LRB-_-LRB- a_LS -RRB-_-RRB- =_JJ y_JJ Pr_NN -LCB-_-LRB- -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ #_# -RCB-_-RRB- 1_CD A_NN ,_, where_WRB cj_NN =_JJ #_# +_CC Aj_NN -LRB-_-LRB- bj_NN aj_NN -RRB-_-RRB- and_CC D_NN indicates_VBZ that_IN the_DT upper_JJ bound_VBN only_RB accounts_VBZ for_IN strategies_NNS that_WDT appear_VBP in_IN the_DT data_NN set_NN D_NN ._.
13_CD A_DT function_NN that_IN satisfies_VBZ the_DT Lipschitz_NNP condition_NN is_VBZ called_VBN Lipschitz_NNP continuous_JJ ._.
14_CD The_DT treatment_NN for_IN the_DT interval_NN -LSB-_-LRB- #_# ,_, ##_NN -RSB-_-RRB- is_VBZ identical_JJ ._.
15_CD It_PRP is_VBZ approximate_JJ in_IN a_DT sense_NN that_IN we_PRP only_RB take_VBP into_IN account_NN strategies_NNS that_WDT are_VBP present_JJ in_IN the_DT data_NNS ._.
311_CD Due_JJ to_TO the_DT fact_NN that_IN our_PRP$ bounds_NNS are_VBP approximate_JJ ,_, we_PRP can_MD not_RB use_VB them_PRP as_IN a_DT conclusive_JJ probabilistic_JJ assessment_NN ._.
Instead_RB ,_, we_PRP take_VBP this_DT as_IN another_DT piece_NN of_IN evidence_NN to_TO complement_VB our_PRP$ findings_NNS ._.
Even_RB if_IN we_PRP can_MD assume_VB that_IN a_DT function_NN that_IN we_PRP approximate_JJ from_IN data_NNS is_VBZ Lipschitz_NNP continuous_JJ ,_, we_PRP rarely_RB actually_RB know_VB the_DT Lipschitz_NNP constant_NN for_IN any_DT subset_NN of_IN ._.
Thus_RB ,_, we_PRP are_VBP faced_VBN with_IN a_DT task_NN of_IN estimating_VBG it_PRP from_IN data_NNS ._.
Here_RB ,_, we_PRP tried_VBD three_CD methods_NNS of_IN doing_VBG this_DT ._.
The_DT first_JJ one_CD simply_RB takes_VBZ the_DT highest_JJS slope_NN that_IN the_DT function_NN attains_VBZ within_IN the_DT available_JJ data_NNS and_CC uses_VBZ this_DT constant_JJ value_NN for_IN every_DT subinterval_NN ._.
This_DT produces_VBZ the_DT most_RBS conservative_JJ bound_VBN ,_, and_CC in_IN many_JJ situations_NNS it_PRP is_VBZ unlikely_JJ to_TO be_VB informative_JJ ._.
An_DT alternative_NN method_NN is_VBZ to_TO take_VB an_DT upper_JJ bound_VBN on_IN slope_NN obtained_VBN within_IN each_DT subinterval_NN using_VBG the_DT available_JJ data_NNS ._.
This_DT produces_VBZ a_DT much_RB less_RBR conservative_JJ upper_JJ bound_VBN on_IN probabilities_NNS ._.
However_RB ,_, since_IN the_DT actual_JJ upper_JJ bound_VBN is_VBZ generally_RB greater_JJR for_IN each_DT subinterval_NN ,_, the_DT resulting_VBG probabilistic_JJ bound_VBN may_MD be_VB deceiving_VBG ._.
A_DT final_JJ method_NN that_IN we_PRP tried_VBD is_VBZ a_DT compromise_NN between_IN the_DT two_CD above_IN ._.
Instead_RB of_IN taking_VBG the_DT conservative_JJ upper_JJ bound_VBN based_VBN on_IN data_NNS over_IN the_DT entire_JJ function_NN domain_NN ,_, we_PRP take_VBP the_DT average_NN of_IN upper_JJ bounds_NNS obtained_VBN at_IN each_DT j_NN ._.
The_DT bound_VBN at_IN an_DT interval_NN is_VBZ then_RB taken_VBN to_TO be_VB the_DT maximum_NN of_IN the_DT upper_JJ bound_VBN for_IN this_DT interval_NN and_CC the_DT average_JJ upper_JJ bound_VBN for_IN all_DT intervals_NNS ._.
The_DT results_NNS of_IN evaluating_VBG the_DT expression_NN for_IN Pr_NNP -LCB-_-LRB- __CD sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RCB-_-RRB- when_WRB =_JJ #_# are_VBP presented_VBN in_IN Table_NNP #_# ._.
In_IN terms_NNS of_IN our_PRP$ claims_NNS in_IN maxj_NN Aj_NNP Aj_NNP max_NN -LCB-_-LRB- Aj_NN ,_, ave_NN -LRB-_-LRB- Aj_NN -RRB-_-RRB- -RCB-_-RRB- 1_CD #_# ._.
#####_NN #_# ._.
#####_NNP Table_NNP #_# :_: Approximate_JJ upper_JJ bound_VBN on_IN probability_NN that_IN some_DT setting_NN of_IN -LSB-_-LRB- #_# ,_, ###_CD -RSB-_-RRB- will_MD satisfy_VB the_DT designer_NN objective_NN with_IN target_NN =_JJ #_# ._.
Different_JJ methods_NNS of_IN approximating_VBG the_DT upper_JJ bound_VBN on_IN slope_NN in_IN each_DT subinterval_JJ j_NN are_VBP used_VBN ._.
this_DT work_NN ,_, the_DT expression_NN gives_VBZ an_DT upper_JJ bound_VBN on_IN the_DT probability_NN that_IN some_DT setting_NN of_IN -LRB-_-LRB- i_LS ._.
e_LS ._.
,_, storage_NN cost_NN -RRB-_-RRB- in_IN the_DT interval_NN -LSB-_-LRB- #_# ,_, ###_CD -RSB-_-RRB- will_MD result_VB in_IN total_JJ day-0_JJ procurement_NN that_WDT is_VBZ no_DT greater_JJR in_IN any_DT equilibrium_NN than_IN the_DT target_NN specified_VBN by_IN and_CC taken_VBN here_RB to_TO be_VB #_# ._.
As_IN we_PRP had_VBD suspected_VBN ,_, the_DT most_RBS conservative_JJ approach_NN to_TO estimating_VBG the_DT upper_JJ bound_VBN on_IN slope_NN ,_, presented_VBN in_IN the_DT first_JJ column_NN of_IN the_DT table_NN ,_, provides_VBZ us_PRP little_JJ information_NN here_RB ._.
However_RB ,_, the_DT other_JJ two_CD estimation_NN approaches_NNS ,_, found_VBN in_IN columns_NNS two_CD and_CC three_CD of_IN Table_NNP #_# ,_, suggest_VBP that_IN we_PRP are_VBP indeed_RB quite_RB confident_JJ that_IN no_DT reasonable_JJ setting_NN of_IN -LSB-_-LRB- #_# ,_, ###_CD -RSB-_-RRB- would_MD have_VB done_VBN the_DT job_NN ._.
Given_VBN the_DT tremendous_JJ difficulty_NN of_IN the_DT problem_NN ,_, this_DT result_NN is_VBZ very_RB strong_JJ ._.
##_NN Still_RB ,_, we_PRP must_MD be_VB very_RB cautious_JJ in_IN drawing_VBG too_RB heroic_JJ a_DT conclusion_NN based_VBN on_IN this_DT evidence_NN ._.
Certainly_RB ,_, we_PRP have_VBP not_RB checked_VBN all_PDT the_DT profiles_NNS but_CC only_RB a_DT small_JJ proportion_NN of_IN them_PRP -LRB-_-LRB- infinitesimal_JJ ,_, if_IN we_PRP consider_VBP the_DT entire_JJ continuous_JJ domain_NN of_IN and_CC strategy_NN sets_NNS -RRB-_-RRB- ._.
Nor_CC can_MD we_PRP expect_VB ever_RB to_TO obtain_VB enough_JJ evidence_NN to_TO make_VB completely_RB objective_JJ conclusions_NNS ._.
Instead_RB ,_, the_DT approach_NN we_PRP advocate_VBP here_RB is_VBZ to_TO collect_VB as_RB much_JJ evidence_NN as_IN is_VBZ feasible_JJ given_VBN resource_NN constraints_NNS ,_, and_CC make_VB the_DT most_RBS compelling_JJ judgment_NN based_VBN on_IN this_DT evidence_NN ,_, if_IN at_IN all_DT possible_JJ ._.
5_CD ._.
CONVERGENCE_NN RESULTS_NNS At_IN this_DT point_NN ,_, we_PRP explore_VBP abstractly_RB whether_IN a_DT design_NN parameter_NN choice_NN based_VBN on_IN payoff_NN data_NNS can_MD be_VB asymptotically_RB reliable_JJ ._.
16_CD Since_IN we_PRP did_VBD not_RB have_VB all_PDT the_DT possible_JJ deviations_NNS for_IN any_DT profile_NN available_JJ in_IN the_DT data_NNS ,_, the_DT true_JJ upper_JJ bounds_NNS may_MD be_VB even_RB lower_JJR ._.
As_IN a_DT matter_NN of_IN convenience_NN ,_, we_PRP will_MD use_VB notation_NN un_NN ,_, i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- to_TO refer_VB to_TO a_DT payoff_NN function_NN of_IN player_NN i_FW based_VBN on_IN an_DT average_NN over_IN n_NN i_FW ._.
i_LS ._.
d_NN ._.
samples_NNS from_IN the_DT distribution_NN of_IN payoffs_NNS ._.
We_PRP also_RB assume_VBP that_IN un_NN ,_, i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- are_VBP independent_JJ for_IN all_PDT a_DT A_NN and_CC i_FW I_PRP ._.
We_PRP will_MD use_VB the_DT notation_NN n_NN to_TO refer_VB to_TO the_DT game_NN -LSB-_-LRB- I_PRP ,_, R_NN ,_, -LCB-_-LRB- ui_NN ,_, n_NN -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RSB-_-RRB- ,_, whereas_IN will_MD denote_VB the_DT underlying_JJ game_NN ,_, -LSB-_-LRB- I_PRP ,_, R_NN ,_, -LCB-_-LRB- ui_NN -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RSB-_-RRB- ._.
Similarly_RB ,_, we_PRP define_VBP n_NN -LRB-_-LRB- r_NN -RRB-_-RRB- to_TO be_VB -LRB-_-LRB- r_NN -RRB-_-RRB- with_IN respect_NN to_TO the_DT game_NN n_NN ._.
In_IN this_DT section_NN ,_, we_PRP show_VBP that_IN n_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- a_DT ._.
s_NNS ._.
uniformly_RB on_IN the_DT mixed_JJ strategy_NN space_NN for_IN any_DT finite_JJ game_NN ,_, and_CC ,_, furthermore_RB ,_, that_IN all_DT mixed_JJ strategy_NN Nash_NNP equilibria_NNP in_IN empirical_JJ games_NNS eventually_RB become_VBP arbitrarily_RB close_JJ to_TO some_DT Nash_NNP equilibrium_NN strategies_NNS in_IN the_DT underlying_JJ game_NN ._.
We_PRP use_VBP these_DT results_NNS to_TO show_VB that_IN under_IN certain_JJ conditions_NNS ,_, the_DT optimal_JJ choice_NN of_IN the_DT design_NN parameter_NN based_VBN on_IN empirical_JJ data_NNS converges_VBZ almost_RB surely_RB to_TO the_DT actual_JJ optimum_NN ._.
THEOREM_NNP #_# ._.
Suppose_VB that_DT |_NN I_PRP |_VBP <_JJR ,_, |_CD A_DT |_NN <_JJR ._.
Then_RB n_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- a_DT ._.
s_NNS ._.
uniformly_RB on_IN S_NN ._.
Recall_VB that_DT N_NN is_VBZ a_DT set_NN of_IN all_DT Nash_NNP equilibria_NN of_IN ._.
If_IN we_PRP define_VBP Nn_NN ,_, =_JJ -LCB-_-LRB- s_NNS S_NN :_: n_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- -RCB-_-RRB- ,_, we_PRP have_VBP the_DT following_VBG corollary_NN to_TO Theorem_NNP #_# :_: COROLLARY_NN #_# ._.
For_IN every_DT >_JJR #_# ,_, there_EX is_VBZ M_NN such_JJ that_IN n_NN M_NN ,_, N_NN Nn_NN ,_, a_DT ._.
s_NNS ._.
PROOF_NN ._.
Since_IN -LRB-_-LRB- s_NNS -RRB-_-RRB- =_JJ #_# for_IN every_DT s_NNS N_NN ,_, we_PRP can_MD find_VB M_NN large_JJ enough_RB such_JJ that_IN Pr_NN -LCB-_-LRB- supnM_NN supsN_NN n_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- <_JJR -RCB-_-RRB- =_JJ #_# ._.
By_IN the_DT Corollary_NNP ,_, for_IN any_DT game_NN with_IN a_DT finite_JJ set_NN of_IN pure_JJ strategies_NNS and_CC for_IN any_DT >_JJR #_# ,_, all_DT Nash_NNP equilibria_NNS lie_VBP in_IN the_DT set_NN of_IN empirical_JJ -_: Nash_NNP equilibria_NNP if_IN enough_JJ samples_NNS have_VBP been_VBN taken_VBN ._.
As_IN we_PRP now_RB show_VBP ,_, this_DT provides_VBZ some_DT justification_NN for_IN our_PRP$ use_NN of_IN a_DT set_NN of_IN profiles_NNS with_IN a_DT non-zero_JJ -_: bound_VBN as_IN an_DT estimate_NN of_IN the_DT set_NN of_IN Nash_NNP equilibria_NNP ._.
First_RB ,_, suppose_VBP we_PRP conclude_VBP that_IN for_IN a_DT particular_JJ setting_NN of_IN ,_, sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- ._.
Then_RB ,_, since_IN for_IN any_DT fixed_JJ >_JJR #_# ,_, N_NN -LRB-_-LRB- -RRB-_-RRB- Nn_NN ,_, -LRB-_-LRB- -RRB-_-RRB- when_WRB n_NN is_VBZ large_JJ enough_RB ,_, sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- =_JJ sup_NN sN_NN -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- sup_NN sNn_NN ,_, -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- =_JJ sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- for_IN any_DT such_JJ n_NN ._.
Thus_RB ,_, since_IN we_PRP defined_VBD the_DT welfare_NN function_NN of_IN the_DT designer_NN to_TO be_VB I_PRP -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RCB-_-RRB- in_IN our_PRP$ domain_NN of_IN interest_NN ,_, the_DT empirical_JJ choice_NN of_IN satisfies_NNS the_DT designer_NN ''_'' s_NNS objective_JJ ,_, thereby_RB maximizing_VBG his_PRP$ welfare_NN function_NN ._.
Alternatively_RB ,_, suppose_VBP we_PRP conclude_VBP that_IN inf_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- >_JJR for_IN every_DT in_IN the_DT domain_NN ._.
Then_RB ,_, <_JJR inf_CD -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- =_JJ inf_NN sNn_NN ,_, -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- inf_NN sN_NN -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- sup_NN sN_NN -LRB-_-LRB- -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- =_JJ sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- ,_, for_IN every_DT ,_, and_CC we_PRP can_MD conclude_VB that_IN no_DT setting_NN of_IN will_MD satisfy_VB the_DT designer_NN ''_'' s_NNS objective_NN ._.
Now_RB ,_, we_PRP will_MD show_VB that_IN when_WRB the_DT number_NN of_IN samples_NNS is_VBZ large_JJ enough_RB ,_, every_DT Nash_NNP equilibrium_NN of_IN n_NN is_VBZ close_JJ to_TO some_DT Nash_NNP equilibrium_NN of_IN the_DT underlying_JJ game_NN ._.
This_DT result_NN will_MD lead_VB us_PRP to_TO consider_VB convergence_NN of_IN optimizers_NNS based_VBN on_IN empirical_JJ data_NNS to_TO actual_JJ optimal_JJ mechanism_NN parameter_NN settings_NNS ._.
We_PRP first_RB note_VBP that_IN the_DT function_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- is_VBZ continuous_JJ in_IN a_DT finite_JJ game_NN ._.
LEMMA_NNP #_# ._.
Let_VB S_NN be_VB a_DT mixed_JJ strategy_NN set_VBN defined_VBN on_IN a_DT finite_JJ game_NN ._.
Then_RB :_: S_NN R_NN is_VBZ continuous_JJ ._.
312_CD For_IN the_DT exposition_NN that_WDT follows_VBZ ,_, we_PRP need_VBP a_DT bit_NN of_IN additional_JJ notation_NN ._.
First_RB ,_, let_VB -LRB-_-LRB- Z_NN ,_, d_NN -RRB-_-RRB- be_VB a_DT metric_JJ space_NN ,_, and_CC X_NN ,_, Y_NN Z_NN and_CC define_VB directed_VBN Hausdorff_NNP distance_NN from_IN X_NN to_TO Y_NN to_TO be_VB h_NN -LRB-_-LRB- X_NN ,_, Y_NN -RRB-_-RRB- =_JJ sup_NN xX_NN inf_NN yY_NN d_NN -LRB-_-LRB- x_NN ,_, y_NN -RRB-_-RRB- ._.
Observe_VB that_IN U_NNP X_NNP h_NN -LRB-_-LRB- U_NN ,_, Y_NN -RRB-_-RRB- h_NN -LRB-_-LRB- X_NN ,_, Y_NN -RRB-_-RRB- ._.
Further_RB ,_, define_VB BS_NN -LRB-_-LRB- x_NN ,_, -RRB-_-RRB- to_TO be_VB an_DT open_JJ ball_NN in_IN S_NN Z_NN with_IN center_NN x_CC S_NN and_CC radius_NN ._.
Now_RB ,_, let_VB Nn_NNP denote_VB all_DT Nash_NNP equilibria_NN of_IN the_DT game_NN n_NN and_CC let_VB N_NN =_JJ -LSB-_-LRB- xN_NN BS_NN -LRB-_-LRB- x_NN ,_, -RRB-_-RRB- ,_, that_WDT is_VBZ ,_, the_DT union_NN of_IN open_JJ balls_NNS of_IN radius_NN with_IN centers_NNS at_IN Nash_NNP equilibria_NNS of_IN ._.
Note_VB that_DT h_NN -LRB-_-LRB- N_NN ,_, N_NN -RRB-_-RRB- =_JJ ._.
We_PRP can_MD then_RB prove_VB the_DT following_VBG general_JJ result_NN ._.
THEOREM_NNP #_# ._.
Suppose_VB |_CD I_PRP |_VBP <_JJR and_CC |_CD A_DT |_NN <_JJR ._.
Then_RB almost_RB surely_RB h_NN -LRB-_-LRB- Nn_NN ,_, N_NN -RRB-_-RRB- converges_VBZ to_TO #_# ._.
We_PRP will_MD now_RB show_VB that_IN in_IN the_DT special_JJ case_NN when_WRB and_CC A_DT are_VBP finite_JJ and_CC each_DT has_VBZ a_DT unique_JJ Nash_NNP equilibrium_NN ,_, the_DT estimates_NNS of_IN optimal_JJ designer_NN parameter_NN converge_VBP to_TO an_DT actual_JJ optimizer_NN almost_RB surely_RB ._.
Let_VB =_JJ arg_NN max_NN W_NN -LRB-_-LRB- Nn_NN -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- ,_, where_WRB n_NN is_VBZ the_DT number_NN of_IN times_NNS each_DT pure_JJ profile_NN was_VBD sampled_VBN in_IN for_IN every_DT ,_, and_CC let_VB =_JJ arg_NN max_NN W_NN -LRB-_-LRB- N_NN -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- ._.
THEOREM_NNP #_# ._.
Suppose_VB |_CD N_NN -LRB-_-LRB- -RRB-_-RRB- |_NN =_JJ #_# for_IN all_DT and_CC suppose_VB that_DT and_CC A_DT are_VBP finite_JJ ._.
Let_VB W_NNP -LRB-_-LRB- s_NNS ,_, -RRB-_-RRB- be_VB continuous_JJ at_IN the_DT unique_JJ s_NNS -LRB-_-LRB- -RRB-_-RRB- N_NN -LRB-_-LRB- -RRB-_-RRB- for_IN each_DT ._.
Then_RB is_VBZ a_DT consistent_JJ estimator_NN of_IN if_IN W_NN -LRB-_-LRB- N_NN -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- is_VBZ defined_VBN as_IN a_DT supremum_NN ,_, infimum_NN ,_, or_CC expectation_NN over_IN the_DT set_NN of_IN Nash_NNP equilibria_NNP ._.
In_IN fact_NN ,_, a_DT ._.
s_NNS ._.
in_IN each_DT of_IN these_DT cases_NNS ._.
The_DT shortcoming_NN of_IN the_DT above_JJ result_NN is_VBZ that_IN ,_, within_IN our_PRP$ framework_NN ,_, the_DT designer_NN has_VBZ no_DT way_NN of_IN knowing_VBG or_CC ensuring_VBG that_DT do_VBP ,_, indeed_RB ,_, have_VBP unique_JJ equilibria_NNS ._.
However_RB ,_, it_PRP does_VBZ lend_VB some_DT theoretical_JJ justification_NN for_IN pursuing_VBG design_NN in_IN this_DT manner_NN ,_, and_CC ,_, perhaps_RB ,_, will_MD serve_VB as_IN a_DT guide_NN for_IN more_JJR general_JJ results_NNS in_IN the_DT future_NN ._.
6_CD ._.
RELATED_JJ WORK_VBP The_DT mechanism_NN design_NN literature_NN in_IN Economics_NNP has_VBZ typically_RB explored_VBN existence_NN of_IN a_DT mechanism_NN that_WDT implements_VBZ a_DT social_JJ choice_NN function_NN in_IN equilibrium_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ._.
Additionally_RB ,_, there_EX is_VBZ an_DT extensive_JJ literature_NN on_IN optimal_JJ auction_NN design_NN -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, of_IN which_WDT the_DT work_NN by_IN Roger_NNP Myerson_NNP -LSB-_-LRB- ##_CD -RSB-_-RRB- is_VBZ ,_, perhaps_RB ,_, the_DT most_RBS relevant_JJ ._.
In_IN much_RB of_IN this_DT work_NN ,_, analytical_JJ results_NNS are_VBP presented_VBN with_IN respect_NN to_TO specific_JJ utility_NN functions_NNS and_CC accounting_NN for_IN constraints_NNS such_JJ as_IN incentive_NN compatibility_NN and_CC individual_JJ rationality_NN ._.
Several_JJ related_JJ approaches_NNS to_TO search_VB for_IN the_DT best_JJS mechanism_NN exist_VBP in_IN the_DT Computer_NNP Science_NNP literature_NN ._.
Conitzer_NNP and_CC Sandholm_NNP -LSB-_-LRB- #_# -RSB-_-RRB- developed_VBD a_DT search_NN algorithm_NN when_WRB all_PDT the_DT relevant_JJ game_NN parameters_NNS are_VBP common_JJ knowledge_NN ._.
When_WRB payoff_NN functions_NNS of_IN players_NNS are_VBP unknown_JJ ,_, a_DT search_NN using_VBG simulations_NNS has_VBZ been_VBN explored_VBN as_IN an_DT alternative_NN ._.
One_CD approach_NN in_IN that_DT direction_NN ,_, taken_VBN in_IN -LSB-_-LRB- #_# -RSB-_-RRB- and_CC -LSB-_-LRB- ##_CD -RSB-_-RRB- ,_, is_VBZ to_TO co-evolve_VB the_DT mechanism_NN parameter_NN and_CC agent_NN strategies_NNS ,_, using_VBG some_DT notion_NN of_IN social_JJ utility_NN and_CC agent_NN payoffs_NNS as_IN fitness_NN criteria_NNS ._.
An_DT alternative_NN to_TO co-evolution_NN explored_VBN in_IN -LSB-_-LRB- ##_NN -RSB-_-RRB- was_VBD to_TO optimize_VB a_DT well-defined_JJ welfare_NN function_NN of_IN the_DT designer_NN using_VBG genetic_JJ programming_NN ._.
In_IN this_DT work_NN the_DT authors_NNS used_VBD a_DT common_JJ learning_NN strategy_NN for_IN all_DT agents_NNS and_CC defined_VBD an_DT outcome_NN of_IN a_DT game_NN induced_VBN by_IN a_DT mechanism_NN parameter_NN as_IN the_DT outcome_NN of_IN joint_JJ agent_NN learning_NN ._.
Most_RBS recently_RB ,_, Phelps_NNP et_FW al_FW ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- compared_VBN two_CD mechanisms_NNS based_VBN on_IN expected_VBN social_JJ utility_NN with_IN expectation_NN taken_VBN over_RP an_DT empirical_JJ distribution_NN of_IN equilibria_NNS in_IN games_NNS defined_VBN by_IN heuristic_NN strategies_NNS ,_, as_IN in_IN -LSB-_-LRB- ##_NN -RSB-_-RRB- ._.
7_CD ._.
CONCLUSION_NN In_IN this_DT work_NN we_PRP spent_VBD considerable_JJ effort_NN developing_VBG general_JJ tactics_NNS for_IN empirical_JJ mechanism_NN design_NN ._.
We_PRP defined_VBD a_DT formal_JJ gametheoretic_JJ model_NN of_IN interaction_NN between_IN the_DT designer_NN and_CC the_DT participants_NNS of_IN the_DT mechanism_NN as_IN a_DT two-stage_JJ game_NN ._.
We_PRP also_RB described_VBD in_IN some_DT generality_NN the_DT methods_NNS for_IN estimating_VBG a_DT sample_NN Nash_NNP equilibrium_NN function_NN when_WRB the_DT data_NNS is_VBZ extremely_RB scarce_JJ ,_, or_CC a_DT Nash_NNP equilibrium_NN correspondence_NN when_WRB more_RBR data_NNS is_VBZ available_JJ ._.
Our_PRP$ techniques_NNS are_VBP designed_VBN specifically_RB to_TO deal_VB with_IN problems_NNS in_IN which_WDT both_CC the_DT mechanism_NN parameter_NN space_NN and_CC the_DT agent_NN strategy_NN sets_NNS are_VBP infinite_JJ and_CC only_RB a_DT relatively_RB small_JJ data_NNS set_NN can_MD be_VB acquired_VBN ._.
A_DT difficult_JJ design_NN issue_NN in_IN the_DT TAC_NN /_: SCM_NNP game_NN which_WDT the_DT TAC_NN community_NN has_VBZ been_VBN eager_JJ to_TO address_VB provides_VBZ us_PRP with_IN a_DT setting_VBG to_TO test_VB our_PRP$ methods_NNS ._.
In_IN applying_VBG empirical_JJ game_NN analysis_NN to_TO the_DT problem_NN at_IN hand_NN ,_, we_PRP are_VBP fully_RB aware_JJ that_IN our_PRP$ results_NNS are_VBP inherently_RB inexact_JJ ._.
Thus_RB ,_, we_PRP concentrate_VBP on_IN collecting_VBG evidence_NN about_IN the_DT structure_NN of_IN the_DT Nash_NNP equilibrium_NN correspondence_NN ._.
In_IN the_DT end_NN ,_, we_PRP can_MD try_VB to_TO provide_VB enough_JJ evidence_NN to_TO either_CC prescribe_VB a_DT parameter_NN setting_NN ,_, or_CC suggest_VBP that_IN no_DT setting_NN is_VBZ possible_JJ that_WDT will_MD satisfy_VB the_DT designer_NN ._.
In_IN the_DT case_NN of_IN TAC_NN /_: SCM_NNP ,_, our_PRP$ evidence_NN suggests_VBZ quite_RB strongly_RB that_IN storage_NN cost_NN could_MD not_RB have_VB been_VBN effectively_RB adjusted_VBN in_IN the_DT ####_CD tournament_NN to_TO curb_VB excessive_JJ day-0_NN procurement_NN without_IN detrimental_JJ effects_NNS on_IN overall_JJ profitability_NN ._.
The_DT success_NN of_IN our_PRP$ analysis_NN in_IN this_DT extremely_RB complex_JJ environment_NN with_IN high_JJ simulation_NN costs_NNS makes_VBZ us_PRP optimistic_JJ that_IN our_PRP$ methods_NNS can_MD provide_VB guidance_NN in_IN making_VBG mechanism_NN design_NN decisions_NNS in_IN other_JJ challenging_JJ domains_NNS ._.
The_DT theoretical_JJ results_NNS confirm_VBP some_DT intuitions_NNS behind_IN the_DT empirical_JJ mechanism_NN design_NN methods_NNS we_PRP have_VBP introduced_VBN ,_, and_CC increases_VBZ our_PRP$ confidence_NN that_IN our_PRP$ framework_NN can_MD be_VB effective_JJ in_IN estimating_VBG the_DT best_JJS mechanism_NN parameter_NN choice_NN in_IN relatively_RB general_JJ settings_NNS ._.
Acknowledgments_NNS We_PRP thank_VBP Terence_NNP Kelly_NNP ,_, Matthew_NNP Rudary_NNP ,_, and_CC Satinder_NNP Singh_NNP for_IN helpful_JJ comments_NNS on_IN earlier_JJR drafts_NNS of_IN this_DT work_NN ._.
This_DT work_NN was_VBD supported_VBN in_IN part_NN by_IN NSF_NNP grant_NN IIS-0205435_NN and_CC the_DT DARPA_NNP REAL_NNP strategic_JJ reasoning_NN program_NN ._.
8_CD ._.
REFERENCES_NNS -LSB-_-LRB- #_# -RSB-_-RRB- R_NN ._.
Arunachalam_NNP and_CC N_NNP ._.
M_NN ._.
Sadeh_NNP ._.
The_DT supply_NN chain_NN trading_NN agent_NN competition_NN ._.
Electronic_JJ Commerce_NNP Research_NNP and_CC Applications_NNS ,_, #_# :_: 63-81_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- M_NN ._.
Benisch_NNP ,_, A_NNP ._.
Greenwald_NNP ,_, V_NNP ._.
Naroditskiy_NNP ,_, and_CC M_NN ._.
Tschantz_NNP ._.
A_DT stochastic_JJ programming_NN approach_NN to_TO scheduling_NN in_IN TAC_NNP SCM_NNP ._.
In_IN Fifth_JJ ACM_NNP Conference_NN on_IN Electronic_JJ Commerce_NNP ,_, pages_NNS 152-159_CD ,_, New_NNP York_NNP ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- Y_NN ._.
-_: P_NN ._.
Chang_NNP and_CC W_NNP ._.
-_: T_NN ._.
Huang_NNP ._.
Generalized_NNP confidence_NN intervals_NNS for_IN the_DT largest_JJS value_NN of_IN some_DT functions_NNS of_IN parameters_NNS under_IN normality_NN ._.
Statistica_NNP Sinica_NNP ,_, ##_CD :_: 1369-1383_CD ,_, 2000_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- D_NN ._.
Cliff_NNP ._.
Evolution_NN of_IN market_NN mechanism_NN through_IN a_DT continuous_JJ space_NN of_IN auction-types_NNS ._.
In_IN Congress_NNP on_IN Evolutionary_NNP Computation_NNP ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- D_NN ._.
A_DT ._.
Cohn_NNP ,_, Z_NN ._.
Ghahramani_NNP ,_, and_CC M_NN ._.
I_PRP ._.
Jordan_NNP ._.
Active_JJ learning_NN with_IN statistical_JJ models_NNS ._.
Journal_NNP of_IN Artificial_NNP Intelligence_NNP Research_NNP ,_, #_# :_: 129-145_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- V_NN ._.
Conitzer_NNP and_CC T_NN ._.
Sandholm_NNP ._.
An_DT algorithm_NN for_IN automatically_RB designing_VBG deterministic_JJ mechanisms_NNS without_IN payments_NNS ._.
In_IN 313_CD Third_NNP International_NNP Joint_NNP Conference_NNP on_IN Autonomous_NNP Agents_NNPS and_CC Multi-Agent_NNP Systems_NNPS ,_, pages_NNS 128-135_CD ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- D_NN ._.
Friedman_NNP ._.
Evolutionary_JJ games_NNS in_IN economics_NNS ._.
Econometrica_NNP ,_, ##_CD -LRB-_-LRB- #_# -RRB-_-RRB- :_: 637-666_CD ,_, May_NNP ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- R_NN ._.
Keener_NNP ._.
Statistical_JJ Theory_NNP :_: A_NNP Medley_NNP of_IN Core_NNP Topics_NNPS ._.
University_NNP of_IN Michigan_NNP Department_NNP of_IN Statistics_NNPS ,_, ####_CD ._.
-LSB-_-LRB- #_# -RSB-_-RRB- C_NN ._.
Kiekintveld_NNP ,_, Y_NN ._.
Vorobeychik_NNP ,_, and_CC M_NN ._.
P_NN ._.
Wellman_NNP ._.
An_DT analysis_NN of_IN the_DT ####_CD supply_NN chain_NN management_NN trading_NN agent_NN competition_NN ._.
In_IN IJCAI-05_NNP Workshop_NNP on_IN Trading_NNP Agent_NNP Design_NNP and_CC Analysis_NN ,_, Edinburgh_NNP ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- A_DT ._.
Mas-Colell_NNP ,_, M_NN ._.
Whinston_NNP ,_, and_CC J_NN ._.
Green_NNP ._.
Microeconomic_JJ Theory_NNP ._.
Oxford_NNP University_NNP Press_NNP ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- R_NN ._.
B_NN ._.
Myerson_NNP ._.
Optimal_JJ auction_NN design_NN ._.
Mathematics_NN of_IN Operations_NNP Research_NNP ,_, #_# -LRB-_-LRB- #_# -RRB-_-RRB- :_: 58-73_CD ,_, February_NNP ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- S_NN ._.
Olafsson_NNP and_CC J_NNP ._.
Kim_NNP ._.
Simulation_NN optimization_NN ._.
In_IN E_NN ._.
Yucesan_NNP ,_, C_NNP ._.
-_: H_NN ._.
Chen_NNP ,_, J_NNP ._.
Snowdon_NNP ,_, and_CC J_NN ._.
Charnes_NNP ,_, editors_NNS ,_, 2002_CD Winter_NNP Simulation_NNP Conference_NNP ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- D_NN ._.
Pardoe_NNP and_CC P_NN ._.
Stone_NNP ._.
TacTex-03_NN :_: A_DT supply_NN chain_NN management_NN agent_NN ._.
SIGecom_NNP Exchanges_NNPS ,_, #_# -LRB-_-LRB- #_# -RRB-_-RRB- :_: 19-28_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- S_NN ._.
Phelps_NNP ,_, S_NN ._.
Parsons_NNP ,_, and_CC P_NN ._.
McBurney_NNP ._.
Automated_VBN agents_NNS versus_CC virtual_JJ humans_NNS :_: an_DT evolutionary_JJ game_NN theoretic_JJ comparison_NN of_IN two_CD double-auction_JJ market_NN designs_NNS ._.
In_IN Workshop_NNP on_IN Agent_NNP Mediated_NNP Electronic_NNP Commerce_NNP VI_NNP ,_, 2004_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- S_NN ._.
Phelps_NNP ,_, S_NN ._.
Parsons_NNP ,_, P_NN ._.
McBurney_NNP ,_, and_CC E_NN ._.
Sklar_NNP ._.
Co-evolution_NN of_IN auction_NN mechanisms_NNS and_CC trading_NN strategies_NNS :_: towards_IN a_DT novel_JJ approach_NN to_TO microeconomic_JJ design_NN ._.
In_IN ECOMAS_NNP ####_CD Workshop_NNP ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- S_NN ._.
Phelps_NNP ,_, S_NN ._.
Parsons_NNP ,_, E_NNP ._.
Sklar_NNP ,_, and_CC P_NN ._.
McBurney_NNP ._.
Using_VBG genetic_JJ programming_NN to_TO optimise_VB pricing_NN rules_NNS for_IN a_DT double-auction_JJ market_NN ._.
In_IN Workshop_NNP on_IN Agents_NNPS for_IN Electronic_NNP Commerce_NNP ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- Y_NN ._.
Vorobeychik_NNP ,_, M_NN ._.
P_NN ._.
Wellman_NNP ,_, and_CC S_NN ._.
Singh_NNP ._.
Learning_NNP payoff_NN functions_NNS in_IN infinite_JJ games_NNS ._.
In_IN Nineteenth_NNP International_NNP Joint_NNP Conference_NNP on_IN Artificial_NNP Intelligence_NNP ,_, pages_NNS 977-982_CD ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- W_NN ._.
E_NN ._.
Walsh_NNP ,_, R_NN ._.
Das_NNP ,_, G_NNP ._.
Tesauro_NNP ,_, and_CC J_NN ._.
O_NN ._.
Kephart_NNP ._.
Analyzing_VBG complex_JJ strategic_JJ interactions_NNS in_IN multi-agent_JJ systems_NNS ._.
In_IN AAAI-02_NN Workshop_NNP on_IN Game_NNP Theoretic_NNP and_CC Decision_NNP Theoretic_NNP Agents_NNPS ,_, ####_CD ._.
-LSB-_-LRB- ##_NN -RSB-_-RRB- M_NN ._.
P_NN ._.
Wellman_NNP ,_, J_NNP ._.
J_NN ._.
Estelle_NNP ,_, S_NN ._.
Singh_NNP ,_, Y_NN ._.
Vorobeychik_NNP ,_, C_NNP ._.
Kiekintveld_NNP ,_, and_CC V_NN ._.
Soni_NNP ._.
Strategic_NNP interactions_NNS in_IN a_DT supply_NN chain_NN game_NN ._.
Computational_JJ Intelligence_NNP ,_, ##_CD -LRB-_-LRB- #_# -RRB-_-RRB- :_: 1-26_CD ,_, February_NNP ####_CD ._.
APPENDIX_NN A_NN ._.
PROOFS_NNS A_DT ._.
#_# Proof_NNP of_IN Proposition_NNP #_# Pr_NNP max_NN iI_NNP max_NNP bAi_NNP \_NNP ai_VBP ui_NN -LRB-_-LRB- b_NN ,_, ai_VBP -RRB-_-RRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ =_JJ Y_NN iI_NNP Eui_NNP -LRB-_-LRB- a_DT -RRB-_-RRB- Pr_NN -LRB-_-LRB- max_NN bAi_NNP \_NNP ai_VBP ui_NN -LRB-_-LRB- b_NN ,_, ai_VBP -RRB-_-RRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- |_CD ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- -RRB-_-RRB- =_JJ =_JJ Y_NN iI_NN Z_NN R_NN Y_NN bAi_NN \_CD ai_VBP Pr_NN -LRB-_-LRB- ui_NN -LRB-_-LRB- b_NN ,_, ai_VBP -RRB-_-RRB- u_NN +_CC -RRB-_-RRB- fui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- -LRB-_-LRB- u_NN -RRB-_-RRB- du_NNP ._.
A_DT ._.
#_# Proof_NNP of_IN Proposition_NNP #_# First_RB ,_, let_VB us_PRP suppose_VB that_IN some_DT function_NN ,_, f_FW -LRB-_-LRB- x_NN -RRB-_-RRB- defined_VBN on_IN -LSB-_-LRB- ai_VBP ,_, bi_VBP -RSB-_-RRB- ,_, satisfy_VB Lipschitz_NNP condition_NN on_IN -LRB-_-LRB- ai_VBP ,_, bi_VBP -RSB-_-RRB- with_IN Lipschitz_NNP constant_JJ Ai_NNP ._.
Then_RB the_DT following_VBG claim_NN holds_VBZ :_: Claim_NNP :_: infx_NN -LRB-_-LRB- ai_VBP ,_, bi_VBP -RSB-_-RRB- f_FW -LRB-_-LRB- x_NN -RRB-_-RRB- #_# ._.
#_# -LRB-_-LRB- f_FW -LRB-_-LRB- ai_VBP -RRB-_-RRB- +_CC f_FW -LRB-_-LRB- bi_NN -RRB-_-RRB- Ai_NN -LRB-_-LRB- bi_NN ai_VBP -RRB-_-RRB- ._.
To_TO prove_VB this_DT claim_NN ,_, note_NN that_IN the_DT intersection_NN of_IN lines_NNS at_IN f_FW -LRB-_-LRB- ai_VBP -RRB-_-RRB- and_CC f_FW -LRB-_-LRB- bi_NN -RRB-_-RRB- with_IN slopes_NNS Ai_NNP and_CC Ai_NNP respectively_RB will_MD determine_VB the_DT lower_JJR bound_VBN on_IN the_DT minimum_NN of_IN f_FW -LRB-_-LRB- x_NN -RRB-_-RRB- on_IN -LSB-_-LRB- ai_VBP ,_, bi_VBP -RSB-_-RRB- -LRB-_-LRB- which_WDT is_VBZ a_DT lower_JJR bound_VBN on_IN infimum_NN of_IN f_FW -LRB-_-LRB- x_NN -RRB-_-RRB- on_IN -LRB-_-LRB- ai_VBP ,_, bj_VBP -RSB-_-RRB- -RRB-_-RRB- ._.
The_DT line_NN at_IN f_FW -LRB-_-LRB- ai_VBP -RRB-_-RRB- is_VBZ determined_VBN by_IN f_FW -LRB-_-LRB- ai_VBP -RRB-_-RRB- =_JJ Aiai_NN +_CC cL_NN and_CC the_DT line_NN at_IN f_FW -LRB-_-LRB- bi_NN -RRB-_-RRB- is_VBZ determined_VBN by_IN f_FW -LRB-_-LRB- bi_NN -RRB-_-RRB- =_JJ Aibi_NN +_CC cR_NN ._.
Thus_RB ,_, the_DT intercepts_NNS are_VBP cL_NN =_JJ f_FW -LRB-_-LRB- ai_VBP -RRB-_-RRB- +_CC Aiai_NNP and_CC cR_NN =_JJ f_FW -LRB-_-LRB- bi_NN -RRB-_-RRB- +_CC Aibi_NNP respectively_RB ._.
Let_VB x_CC be_VB the_DT point_NN at_IN which_WDT these_DT lines_NNS intersect_VBP ._.
Then_RB ,_, x_NN =_JJ f_FW -LRB-_-LRB- x_NN -RRB-_-RRB- cR_NN A_NN =_JJ f_FW -LRB-_-LRB- x_NN -RRB-_-RRB- cL_NN A_NN ._.
By_IN substituting_VBG the_DT expressions_NNS for_IN cR_NN and_CC cL_NN ,_, we_PRP get_VBP the_DT desired_VBN result_NN ._.
Now_RB ,_, subadditivity_NN gives_VBZ us_PRP Pr_VB -LCB-_-LRB- __CD sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RCB-_-RRB- 5X_NN j_NN =_JJ #_# Pr_NNP -LCB-_-LRB- __CD j_NN sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RCB-_-RRB- ,_, and_CC ,_, by_IN the_DT claim_NN ,_, Pr_NN -LCB-_-LRB- __NN j_NN sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- -RCB-_-RRB- =_JJ 1_CD Pr_NN -LCB-_-LRB- inf_NN j_NN sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- >_JJR -RCB-_-RRB- Pr_NNP -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- aj_NN -RRB-_-RRB- -RCB-_-RRB- +_CC sup_NN -LCB-_-LRB- -LRB-_-LRB- bj_NN -RRB-_-RRB- -RCB-_-RRB- #_# +_CC Aj_NN -LRB-_-LRB- bj_NN aj_NN -RRB-_-RRB- -RCB-_-RRB- ._.
Since_IN we_PRP have_VBP a_DT finite_JJ number_NN of_IN points_NNS in_IN the_DT data_NNS set_VBN for_IN each_DT ,_, we_PRP can_MD obtain_VB the_DT following_VBG expression_NN :_: Pr_NN -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- aj_NN -RRB-_-RRB- -RCB-_-RRB- +_CC sup_NN -LCB-_-LRB- -LRB-_-LRB- bj_NN -RRB-_-RRB- -RCB-_-RRB- cj_NN -RCB-_-RRB- =_JJ D_NN X_NN y_NN ,_, zD_NN :_: y_NN +_CC zcj_NN Pr_NN -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- bj_NN -RRB-_-RRB- -RCB-_-RRB- =_JJ y_NN -RCB-_-RRB- Pr_NN -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- aj_NN -RRB-_-RRB- -RCB-_-RRB- =_JJ z_SYM -RCB-_-RRB- ._.
We_PRP can_MD now_RB restrict_VB attention_NN to_TO deriving_VBG an_DT upper_JJ bound_VBN on_IN Pr_NN -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- =_JJ y_NN -RCB-_-RRB- for_IN a_DT fixed_VBN ._.
To_TO do_VB this_DT ,_, observe_VBP that_IN Pr_NN -LCB-_-LRB- sup_NN -LCB-_-LRB- -LRB-_-LRB- -RRB-_-RRB- -RCB-_-RRB- =_JJ y_NN -RCB-_-RRB- D_NN Pr_NN -LCB-_-LRB- __CD aD_NN :_: -LRB-_-LRB- a_LS -RRB-_-RRB- =_JJ y_NN -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ #_# -RCB-_-RRB- X_NN aD_NN :_: -LRB-_-LRB- a_LS -RRB-_-RRB- =_JJ y_JJ Pr_NN -LCB-_-LRB- -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ #_# -RCB-_-RRB- by_IN subadditivity_NN and_CC the_DT fact_NN that_IN a_DT profile_NN a_DT is_VBZ a_DT Nash_NNP equilibrium_NN if_IN and_CC only_RB if_IN -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ #_# ._.
Putting_VBG everything_NN together_RB yields_VBZ the_DT desired_VBN result_NN ._.
A_DT ._.
#_# Proof_NNP of_IN Theorem_NNP #_# First_RB ,_, we_PRP will_MD need_VB the_DT following_VBG fact_NN :_: Claim_NNP :_: Given_VBN a_DT function_NN fi_NN -LRB-_-LRB- x_NN -RRB-_-RRB- and_CC a_DT set_NN X_NN ,_, |_CD maxxX_NN f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- maxxX_NN f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- |_CD maxxX_NNP |_CD f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- |_NN ._.
To_TO prove_VB this_DT claim_NN ,_, observe_VBP that_IN |_CD max_NN xX_NNP f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- max_NN xX_NN f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- |_NN =_JJ maxx_NN f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- maxx_NN f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- if_IN maxx_NN f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- maxx_NN f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- maxx_NN f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- maxx_NN f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- if_IN maxx_NN f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- maxx_NN f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- In_IN the_DT first_JJ case_NN ,_, max_NN xX_NNP f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- max_NN xX_NN f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- max_NN xX_NN -LRB-_-LRB- f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- -RRB-_-RRB- max_NN xX_NNP |_CD f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- |_NN ._.
314_CD Similarly_RB ,_, in_IN the_DT second_JJ case_NN ,_, max_NN xX_NNP f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- max_NN xX_NN f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- max_NN xX_NN -LRB-_-LRB- f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- -RRB-_-RRB- max_NN xX_NNP |_CD f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- |_NN =_JJ max_NN xX_NNP |_CD f1_NN -LRB-_-LRB- x_NN -RRB-_-RRB- f2_NN -LRB-_-LRB- x_NN -RRB-_-RRB- |_NN ._.
Thus_RB ,_, the_DT claim_NN holds_VBZ ._.
By_IN the_DT Strong_JJ Law_NN of_IN Large_JJ Numbers_NNS ,_, un_NN ,_, i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- a_DT ._.
s_NNS ._.
for_IN all_DT i_FW I_PRP ,_, a_DT A_NN ._.
That_DT is_VBZ ,_, Pr_NN -LCB-_-LRB- lim_NN n_NN un_NN ,_, i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- =_JJ ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- -RCB-_-RRB- =_JJ #_# ,_, or_CC ,_, equivalently_RB -LSB-_-LRB- #_# -RSB-_-RRB- ,_, for_IN any_DT >_JJR #_# and_CC >_JJR #_# ,_, there_EX is_VBZ M_NN -LRB-_-LRB- i_FW ,_, a_DT -RRB-_-RRB- >_JJR #_# such_PDT that_IN Pr_NN -LCB-_-LRB- sup_NN nM_NN -LRB-_-LRB- i_FW ,_, a_DT -RRB-_-RRB- |_CD un_NN ,_, i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- |_NN <_JJR 2_CD |_CD A_DT |_NN -RCB-_-RRB- #_# ._.
By_IN taking_VBG M_NN =_JJ maxiI_NN maxaA_NN M_NN -LRB-_-LRB- i_FW ,_, a_DT -RRB-_-RRB- ,_, we_PRP have_VBP Pr_NN -LCB-_-LRB- max_NN iI_NN max_NN aA_NN sup_NN nM_NN |_CD un_NN ,_, i_FW -LRB-_-LRB- a_DT -RRB-_-RRB- ui_NN -LRB-_-LRB- a_DT -RRB-_-RRB- |_NN <_JJR 2_CD |_CD A_DT |_NN -RCB-_-RRB- #_# ._.
Thus_RB ,_, by_IN the_DT claim_NN ,_, for_IN any_DT n_NN M_NN ,_, sup_NN nM_NN |_CD n_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- |_VBP max_NN iI_NNP max_NN aiAi_NN sup_NN nM_NN |_CD un_NN ,_, i_FW -LRB-_-LRB- ai_VBP ,_, si_VBP -RRB-_-RRB- ui_NN -LRB-_-LRB- ai_VBP ,_, si_VBP -RRB-_-RRB- |_NN +_CC +_CC sup_NN nM_NN max_NN iI_NNP |_CD un_NN ,_, i_FW -LRB-_-LRB- s_NNS -RRB-_-RRB- ui_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- |_VBP max_NN iI_NNP max_NN aiAi_NN X_NN bAi_NN sup_NN nM_NN |_CD un_NN ,_, i_FW -LRB-_-LRB- ai_VBP ,_, b_LS -RRB-_-RRB- ui_NN -LRB-_-LRB- ai_VBP ,_, b_LS -RRB-_-RRB- |_CD si_NNS -LRB-_-LRB- b_NN -RRB-_-RRB- +_CC +_CC max_NN iI_NN X_NN bA_NN sup_NN nM_NN |_CD un_NN ,_, i_FW -LRB-_-LRB- b_NN -RRB-_-RRB- ui_NN -LRB-_-LRB- b_NN -RRB-_-RRB- |_CD s_NNS -LRB-_-LRB- b_NN -RRB-_-RRB- max_NN iI_NNP max_NN aiAi_NN X_NN bAi_NN sup_NN nM_NN |_CD un_NN ,_, i_FW -LRB-_-LRB- ai_VBP ,_, b_LS -RRB-_-RRB- ui_NN -LRB-_-LRB- ai_VBP ,_, b_LS -RRB-_-RRB- |_NN +_CC +_CC max_NN iI_NN X_NN bA_NN sup_NN nM_NN |_CD un_NN ,_, i_FW -LRB-_-LRB- b_NN -RRB-_-RRB- ui_NN -LRB-_-LRB- b_NN -RRB-_-RRB- |_NN <_JJR max_CD iI_NNP max_NN aiAi_NN X_NN bAi_NN -LRB-_-LRB- 2_CD |_CD A_DT |_NN -RRB-_-RRB- +_CC max_NN iI_NN X_NN bA_NN -LRB-_-LRB- 2_CD |_CD A_DT |_NN -RRB-_-RRB- with_IN probability_NN at_IN least_JJS #_# ._.
Note_VB that_DT since_IN si_NN -LRB-_-LRB- a_DT -RRB-_-RRB- and_CC s_NNS -LRB-_-LRB- a_DT -RRB-_-RRB- are_VBP bounded_VBN between_IN #_# and_CC #_# ,_, we_PRP were_VBD able_JJ to_TO drop_VB them_PRP from_IN the_DT expressions_NNS above_IN to_TO obtain_VB a_DT bound_VBN that_WDT will_MD be_VB valid_JJ independent_JJ of_IN the_DT particular_JJ choice_NN of_IN s_NNS ._.
Furthermore_RB ,_, since_IN the_DT above_JJ result_NN can_MD be_VB obtained_VBN for_IN an_DT arbitrary_JJ >_JJR #_# and_CC >_JJR #_# ,_, we_PRP have_VBP Pr_NN -LCB-_-LRB- limn_NN n_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- =_JJ -LRB-_-LRB- s_NNS -RRB-_-RRB- -RCB-_-RRB- =_JJ #_# uniformly_RB on_IN S_NN ._.
A_DT ._.
#_# Proof_NNP of_IN Lemma_NNP #_# We_PRP prove_VBP the_DT result_NN using_VBG uniform_JJ continuity_NN of_IN ui_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- and_CC preservation_NN of_IN continuity_NN under_IN maximum_NN ._.
Claim_NN :_: A_DT function_NN f_FW :_: Rk_NN R_NN defined_VBN by_IN f_FW -LRB-_-LRB- t_NN -RRB-_-RRB- =_JJ Pk_NN i_FW =_JJ #_# ziti_NNS ,_, where_WRB zi_NN are_VBP constants_NNS in_IN R_NN ,_, is_VBZ uniformly_RB continuous_JJ in_IN t_NN ._.
The_DT claim_NN follows_VBZ because_IN |_NN f_FW -LRB-_-LRB- t_NN -RRB-_-RRB- f_FW -LRB-_-LRB- t_NN -RRB-_-RRB- |_NN =_JJ |_CD Pk_NN i_FW =_JJ #_# zi_NN -LRB-_-LRB- titi_NN -RRB-_-RRB- |_CD Pk_NN i_FW =_JJ #_# |_SYM zi_FW |_FW |_FW ti_FW ti_FW |_FW ._.
An_DT immediate_JJ result_NN of_IN this_DT for_IN our_PRP$ purposes_NNS is_VBZ that_IN ui_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- is_VBZ uniformly_RB continuous_JJ in_IN s_NNS and_CC ui_NN -LRB-_-LRB- ai_VBP ,_, si_VBP -RRB-_-RRB- is_VBZ uniformly_RB continuous_JJ in_IN si_FW ._.
Claim_NN :_: Let_VB f_FW -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- be_VB uniformly_RB continuous_JJ in_IN b_NN B_NN for_IN every_DT a_DT A_NN ,_, with_IN |_CD A_DT |_NN <_JJR ._.
Then_RB V_NN -LRB-_-LRB- b_NN -RRB-_-RRB- =_JJ maxaA_NN f_FW -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- is_VBZ uniformly_RB continuous_JJ in_IN b_NN ._.
To_TO show_VB this_DT ,_, take_VB >_JJR #_# and_CC let_VB b_NN ,_, b_NN B_NN such_JJ that_IN b_NN b_NN <_JJR -LRB-_-LRB- a_DT -RRB-_-RRB- |_FW f_FW -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- f_FW -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- |_NN <_JJR ._.
Now_RB take_VB =_JJ minaA_NN -LRB-_-LRB- a_DT -RRB-_-RRB- ._.
Then_RB ,_, whenever_WRB b_NN b_NN <_JJR ,_, |_CD V_NN -LRB-_-LRB- b_NN -RRB-_-RRB- V_NN -LRB-_-LRB- b_NN -RRB-_-RRB- |_NN =_JJ |_CD max_NN aA_NN f_FW -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- max_FW aA_FW f_FW -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- |_CD max_FW aA_FW |_FW f_FW -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- f_FW -LRB-_-LRB- a_DT ,_, b_NN -RRB-_-RRB- |_NN <_JJR ._.
Now_RB ,_, recall_VBP that_IN -LRB-_-LRB- s_NNS -RRB-_-RRB- =_JJ maxi_NN -LSB-_-LRB- maxaiAi_NN ui_NN -LRB-_-LRB- ai_VBP ,_, si_VBP -RRB-_-RRB- ui_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- -RSB-_-RRB- ._.
By_IN the_DT claims_NNS above_IN ,_, maxaiAi_NN ui_NN -LRB-_-LRB- ai_VBP ,_, si_VBP -RRB-_-RRB- is_VBZ uniformly_RB continuous_JJ in_IN si_NN and_CC ui_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- is_VBZ uniformly_RB continuous_JJ in_IN s_NNS ._.
Since_IN the_DT difference_NN of_IN two_CD uniformly_RB continuous_JJ functions_NNS is_VBZ uniformly_RB continuous_JJ ,_, and_CC since_IN this_DT continuity_NN is_VBZ preserved_VBN under_IN maximum_NN by_IN our_PRP$ second_JJ claim_NN ,_, we_PRP have_VBP the_DT desired_VBN result_NN ._.
A_DT ._.
#_# Proof_NNP of_IN Theorem_NNP #_# Choose_VB >_JJR #_# ._.
First_RB ,_, we_PRP need_VBP to_TO ascertain_VB that_IN the_DT following_VBG claim_NN holds_VBZ :_: Claim_NNP :_: =_JJ minsS_NN \_CD N_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- exists_VBZ and_CC >_JJR #_# ._.
Since_IN N_NN is_VBZ an_DT open_JJ subset_NN of_IN compact_JJ S_NN ,_, it_PRP follows_VBZ that_IN S_NN \_CD N_NN is_VBZ compact_JJ ._.
As_IN we_PRP had_VBD also_RB proved_VBN in_IN Lemma_NNP #_# that_WDT -LRB-_-LRB- s_NNS -RRB-_-RRB- is_VBZ continuous_JJ ,_, existence_NN follows_VBZ from_IN the_DT Weierstrass_NNP theorem_NN ._.
That_DT >_JJR #_# is_VBZ clear_JJ since_IN -LRB-_-LRB- s_NNS -RRB-_-RRB- =_JJ #_# if_IN and_CC only_RB if_IN s_NNS is_VBZ a_DT Nash_NNP equilibrium_NN of_IN ._.
Now_RB ,_, by_IN Theorem_NNP #_# ,_, for_IN any_DT >_JJR #_# there_EX is_VBZ M_NN such_JJ that_IN Pr_NN -LCB-_-LRB- sup_NN nM_NN sup_NN sS_NN |_CD n_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- |_VBP <_JJR -RCB-_-RRB- #_# ._.
Consequently_RB ,_, for_IN any_DT >_JJR #_# ,_, Pr_NN -LCB-_-LRB- sup_NN nM_NN h_NN -LRB-_-LRB- Nn_NN ,_, N_NN -RRB-_-RRB- <_JJR -RCB-_-RRB- Pr_NN -LCB-_-LRB- n_NN M_NN Nn_NN N_NN -RCB-_-RRB- Pr_NN -LCB-_-LRB- sup_NN nM_NN sup_NN sN_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- <_JJR -RCB-_-RRB- Pr_NNP -LCB-_-LRB- sup_NN nM_NN sup_NN sS_NN |_CD n_NN -LRB-_-LRB- s_NNS -RRB-_-RRB- -LRB-_-LRB- s_NNS -RRB-_-RRB- |_VBP <_JJR -RCB-_-RRB- #_# ._.
Since_IN this_DT holds_VBZ for_IN an_DT arbitrary_JJ >_JJR #_# and_CC >_JJR #_# ,_, the_DT desired_VBN result_NN follows_VBZ ._.
A_DT ._.
#_# Proof_NNP of_IN Theorem_NNP #_# Fix_VB and_CC choose_VB >_JJR #_# ._.
Since_IN W_NN -LRB-_-LRB- s_NNS ,_, -RRB-_-RRB- is_VBZ continuous_JJ at_IN s_NNS -LRB-_-LRB- -RRB-_-RRB- ,_, given_VBN >_JJR #_# there_EX is_VBZ >_JJR #_# such_PDT that_IN for_IN every_DT s_NNS that_WDT is_VBZ within_IN of_IN s_NNS -LRB-_-LRB- -RRB-_-RRB- ,_, |_NN W_NN -LRB-_-LRB- s_NNS ,_, -RRB-_-RRB- W_NN -LRB-_-LRB- s_NNS -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- |_NN <_JJR ._.
By_IN Theorem_NNP #_# ,_, we_PRP can_MD find_VB M_NN -LRB-_-LRB- -RRB-_-RRB- large_JJ enough_RB such_JJ that_IN all_DT s_NNS Nn_NN are_VBP within_IN of_IN s_NNS -LRB-_-LRB- -RRB-_-RRB- for_IN all_DT n_NN M_NN -LRB-_-LRB- -RRB-_-RRB- with_IN probability_NN #_# ._.
Consequently_RB ,_, for_IN any_DT >_JJR #_# we_PRP can_MD find_VB M_NN -LRB-_-LRB- -RRB-_-RRB- large_JJ enough_RB such_JJ that_IN with_IN probability_NN #_# we_PRP have_VBP supnM_NN -LRB-_-LRB- -RRB-_-RRB- sups_VBZ Nn_NNP |_NNP W_NNP -LRB-_-LRB- s_NNS ,_, -RRB-_-RRB- W_NN -LRB-_-LRB- s_NNS -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- |_NN <_JJR ._.
Let_VB us_PRP assume_VB without_IN loss_NN of_IN generality_NN that_IN there_EX is_VBZ a_DT unique_JJ optimal_JJ choice_NN of_IN ._.
Now_RB ,_, since_IN the_DT set_NN is_VBZ finite_JJ ,_, there_EX is_VBZ also_RB the_DT second-best_JJS choice_NN of_IN -LRB-_-LRB- if_IN there_EX is_VBZ only_RB one_CD this_DT discussion_NN is_VBZ moot_JJ anyway_RB -RRB-_-RRB- :_: =_JJ arg_NN max_NN \_CD W_NN -LRB-_-LRB- s_NNS -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- ._.
Suppose_VB w_NN ._.
l_NN ._.
o_NN ._.
g_NN ._.
that_DT is_VBZ also_RB unique_JJ and_CC let_VB =_JJ W_NN -LRB-_-LRB- s_NNS -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- W_NN -LRB-_-LRB- s_NNS -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- ._.
Then_RB if_IN we_PRP let_VBP <_JJR /_: #_# and_CC let_VB M_NN =_JJ max_NN M_NN -LRB-_-LRB- -RRB-_-RRB- ,_, where_WRB each_DT M_NN -LRB-_-LRB- -RRB-_-RRB- is_VBZ large_JJ enough_RB such_JJ that_IN supnM_NN -LRB-_-LRB- -RRB-_-RRB- sups_VBZ Nn_NNP |_NNP W_NNP -LRB-_-LRB- s_NNS ,_, -RRB-_-RRB- W_NN -LRB-_-LRB- s_NNS -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- |_NN <_JJR a_DT ._.
s_NNS ._.
,_, the_DT optimal_JJ choice_NN of_IN based_VBN on_IN any_DT empirical_JJ equilibrium_NN will_MD be_VB with_IN probability_NN #_# ._.
Thus_RB ,_, in_IN particular_JJ ,_, given_VBN any_DT probability_NN distribution_NN over_IN empirical_JJ equilibria_NNS ,_, the_DT best_JJS choice_NN of_IN will_MD be_VB with_IN probability_NN #_# -LRB-_-LRB- similarly_RB ,_, if_IN we_PRP take_VBP supremum_NN or_CC infimum_NN of_IN W_NN -LRB-_-LRB- Nn_NN -LRB-_-LRB- -RRB-_-RRB- ,_, -RRB-_-RRB- over_IN the_DT set_NN of_IN empirical_JJ equilibria_NNS in_IN constructing_VBG the_DT objective_JJ function_NN -RRB-_-RRB- ._.
315_CD
